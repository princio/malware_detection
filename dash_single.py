
import dash
import dash_core_components as dcc
import dash_html_components as html
import dash_table
from dash.dependencies import Input, Output
from plotly.subplots import make_subplots
import sqlite3
import pandas as pd
import os

dirs = {
    'malware': '/media/princio/ssd512/stratosphere/pcap/csv/malware/',
    'normal': '/media/princio/ssd512/stratosphere/pcap/csv/normal/'
}


try:
    pcap_dict
except NameError:
    pcap_dict = {'normal':{}, 'botnet':{}}
    
try:
    pcap_names
except NameError:
    pcap_names = {'normal':{}, 'botnet':{}}

def get_type(pcapname):
    bot_path = os.path.join(dirs['malware'], pcapname)
    nor_path = os.path.join(dirs['normal'], pcapname)
    if os.path.exists(bot_path):
        type_='botnet'
        df_path = bot_path
    elif os.path.exists(nor_path):
        type_='normal'
        df_path = nor_path
    else:
        return None
    return type_, df_path
    
def get_df(pcapname, reload=False):
    if reload:
        type_, df_path = get_type(pcapname)
        pcap_dict[type_][pcapname] = pd.read_csv(df_path, usecols=list(range(0,12)))
        return pcap_dict[type_][pcapname]
    
    if pcapname in pcap_dict['botnet']:
        return pcap_dict['botnet'][pcapname]
    if pcapname in pcap_dict['normal']:
        return pcap_dict['normal'][pcapname]
    
    type_, df_path = get_type(pcapname)
    pcap_dict[type_][pcapname] = pd.read_csv(df_path, usecols=list(range(0,12)))
    return pcap_dict[type_][pcapname].copy()

def file_list(_dir):
    files = []
    for walker in os.walk(_dir):
        for filenames in walker[2]:
            files.append(os.path.join(_dir, filenames))
    return files

def walkk(dfs, dir_):
    for type_ in ['malware', 'normal']:
        files = file_list(dir_)
        for file in files:
            fname = os.path.basename(file)
            if fname[-4:] != '.csv': continue
            if fname in dfs: continue
            dfs[fname] = pd.read_csv(file, usecols=list(range(0,12)))
        return dfs


df = get_df('42_botnet-capture-20110810-neris.pcap.csv')


#### RESAMPLING ####
df.index = pd.DatetimeIndex(df['frame.time_epoch_req']*1_000_000_000)
df_res = df.copy()
df_res = df_res.drop(columns=['frame.number_req', 'frame.time_epoch_req', 'frame.time_epoch_res', 'dns_server_ip', 'dns.qry.name', 'dns.qry.type'])
sum_columns = [ 'no-response', 'response-ok', 'no-such-name', 'legit_list' ]
average_columns = [ 'dns.time', 'nosfx_0.1', 'domain_0.1' ]
df_res['no-response'] = df_res['frame.number_res'].isna().astype(int)
df_res['response-ok'] = df_res['dns.flags.rcode'].apply(lambda x: x == 0).astype(int)
df_res['no-such-name'] = df_res['dns.flags.rcode'].apply(lambda x: x == 3).astype(int)
df_res = df_res.resample('3T')
df_res = pd.concat([df_res[sum_columns].sum(), df_res[average_columns].mean()], axis=1)
#### RESAMPLING ####


if __name__ == '__main__':
    app.run_server(debug=False)
