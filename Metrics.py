from datetime import datetime
import numpy as np
from Metric import Metric

class Metrics:
    def __init__(self, labels, dga, confusion_matrix = None):
        self.labels = labels
        self.confusion_matrix = confusion_matrix
        self.dga = dga
        
        self.classes = None
        self.recall = None
        self.f1_score = None
        self.supports = None

        self.normals = []
        for label in labels:
            self.normals.append(Metric(label))
        self.macro = Metric("macro")
        self.weighted = Metric("weighted")
        self.accuracy = 0

    @staticmethod
    def create(labels, dga, confusion_matrix):
        metrics = Metrics(labels, dga, confusion_matrix)
        metrics.calc()
        return metrics

    @staticmethod
    def fromlist(labels, dga, values):
        metrics = Metrics(labels, dga)

        for i in range(len(labels)):
            metrics.normals[i] = Metric.fromlist(labels[i], values[i*4:(i+1)*4])

        i = len(labels) * 4
        metrics.macro = Metric.fromlist('macro', values[i:i+4])
        i += 4
        metrics.weighted = Metric.fromlist('weighted', values[i:i+4])
        metrics.accuracy = values[-1]
        
        return metrics

    def calc(self):
        """Cij: i=actual, j=predicted.
        if legit=0, dga=1:
            C00: true legit
            C10: false legit
            C01: false dga
            C11: true dga
                L?   D?
            L!| TL | FD |
            D!| FL | TD |
        """
        tot = self.confusion_matrix.sum()
        tp_s = np.diag(self.confusion_matrix)
        tp_plus_fp_s = self.confusion_matrix.sum(axis=0)          
        supports = self.confusion_matrix.sum(axis=1)

        precision = tp_s / tp_plus_fp_s
        recall = tp_s / supports
        f1_score = 2 * precision * recall / (precision + recall)

        accuracy = tp_s.sum() / tot

        macro_precision = np.average(precision)
        macro_recall = np.average(recall)
        macro_f1_score = np.average(f1_score)

        weighted_precision = np.average(precision, weights=supports)
        weighted_recall = np.average(recall, weights=supports)
        weighted_f1_score = np.average(f1_score, weights=supports)

        self.precision = [ precision, macro_precision, weighted_precision ]
        self.recall = [ recall, macro_recall, weighted_recall ]
        self.f1_score = [ f1_score, macro_f1_score, weighted_f1_score ]
        self.supports = supports
        self.accuracy = accuracy

        for i in range(len(self.labels)):
            self.normals[i] = Metric(self.labels[i], precision[i], recall[i], f1_score[i], supports[i])

        self.macro = Metric('macro', macro_precision, macro_recall, macro_f1_score)
        self.weighted = Metric('weighted', weighted_precision, weighted_recall, weighted_f1_score)
        
        pass

    def sum(self, metrics):
        if len(metrics.labels) != len(self.labels):
            raise 'Metrics with different class number'

        for i in range(len(self.labels)):
            self.normals[i].sum(metrics.normals[i])
        
        self.macro.sum(metrics.macro)
        self.weighted.sum(metrics.weighted)
        self.accuracy = self.accuracy + metrics.accuracy

    def div(self, scalar):
        for i in range(len(self.normals)):
            self.normals[i].div(scalar)
        
        self.macro.div(scalar)
        self.weighted.div(scalar)
        self.accuracy = self.accuracy / scalar

    def tolist(self):
        metrics = []
        for normal in self.normals:
            metrics += normal.tolist()
        
        metrics += self.macro.tolist()
        metrics += self.weighted.tolist()
        metrics += [ self.accuracy ]

        return metrics

    def str_row(self, separator = ' '):
        row = ""
        for v in self.tolist():
            row = row + "%10.6f%s" % (v, separator)
        return row

    def str_confusionmatrix(self, name = ''):
        row =  "%5s   | %5s | %5s | %s\n" % (name, 'L?', 'D?', f'{list(self.dga.keys())[0]}:{list(self.dga.values())[0]}')
        row += "%5s L!| %5d | %5d |\n" % ('', self.confusion_matrix[0,0], self.confusion_matrix[0,1])
        row += "%5s D!| %5d | %5d |" % ('', self.confusion_matrix[1,0], self.confusion_matrix[1,1])
        return row

    def str2(self, name = '', print_dga=True):

        row0 = ''
        row1 = ''
        row2 = ''
        row3 = ''
        row4 = ''

        row1 += "%-30s" % ("%5s" % (self.dga if print_dga else ''))
        row2 += "%-30s" % ("%5s   | %5s | %5s |" % (name, 'L?', 'D?'))
        row3 += "%-30s" % ("%5s L!| %5d | %5d |" % ('', self.confusion_matrix[0,0], self.confusion_matrix[0,1]))
        row4 += "%-30s" % ("%5s D!| %5d | %5d |" % ('', self.confusion_matrix[1,0], self.confusion_matrix[1,1]))

        row0 += "%10s "  % ""
        row1 += "%10s " % "precision"
        row2 += "%10s " % "recall"
        row3 += "%10s " % "f1_score"
        row4 += "%10s " % "support"

        for i in range(len(self.labels)):
            row0 += "%10s "  % self.labels[i]
            row1 += "%10.6f " % self.normals[i].precision
            row2 += "%10.6f " % self.normals[i].recall
            row3 += "%10.6f " % self.normals[i].f1_score
            row4 += "%10d " % self.normals[i].support

        row0 += "%10s " % "macro"
        row1 += "%10.6f " % self.macro.precision
        row2 += "%10.6f " % self.macro.recall
        row3 += "%10.6f " % self.macro.f1_score
        row4 += "%10d " % self.macro.support

        row0 += "%10s " % "weighted"
        row1 += "%10.6f " % self.weighted.precision
        row2 += "%10.6f " % self.weighted.recall
        row3 += "%10.6f " % self.weighted.f1_score
        row4 += "%10d " % self.weighted.support
        
        row0 += "%20s " % "confusion matrix"


        return "%s\n%s\n%s\n%s" % (row1, row2, row3, row4)

    def __str__(self):

        row0 = "%10s "  % ""
        row1 = "%10s " % "precision"
        row2 = "%10s " % "recall"
        row3 = "%10s " % "f1_score"
        row4 = "%10s " % "support"

        for i in range(len(self.labels)):
            row0 = row0 + "%10s "  % self.labels[i]
            row1 = row1 + "%10.6f " % self.normals[i].precision
            row2 = row2 + "%10.6f " % self.normals[i].recall
            row3 = row3 + "%10.6f " % self.normals[i].f1_score
            row4 = row4 + "%10d " % self.normals[i].support

        row0 = row0 + "%10s " % "macro"
        row1 = row1 + "%10.6f " % self.macro.precision
        row2 = row2 + "%10.6f " % self.macro.recall
        row3 = row3 + "%10.6f " % self.macro.f1_score
        row4 = row4 + "%10d " % self.macro.support

        row0 = row0 + "%10s " % "weighted"
        row1 = row1 + "%10.6f " % self.weighted.precision
        row2 = row2 + "%10.6f " % self.weighted.recall
        row3 = row3 + "%10.6f " % self.weighted.f1_score
        row4 = row4 + "%10d " % self.weighted.support
        
        row0 = row0 + "%20s " % "confusion matrix"

        return "%s\n%s\n%s\n%s\n%s\n\n" % (row0, row1, row2, row3, row4)

        
