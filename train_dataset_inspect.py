import os
from DomainLevel import DomainLevel, extractor
import csv
import numpy as np
import Capture as cp
import pandas as pd
import Model
from IOview import InputView, OutputView
from keras.preprocessing.sequence import pad_sequences

def count_domain_level():

    path = 'datasets/setAtrain_h_t_domins.csv'

    dga = []
    legit = []

    domains_num = {
        'legit': np.zeros(10),
        'dga': np.zeros(6)
    }
    domains_level_num = {
        'legit': {0: {}, 1: {}, 2: {}, 3: {}, 4: {}, 5: {}},
        'dga': {0: {}, 1: {}, 2: {}, 3: {}, 4: {}, 5: {}}
    }
    domains_by_level_num = {
        'legit': {1: [], 2: [], 3: [], 4: [], 5: []},
        'dga': {1: [], 2: [], 3: [], 4: [], 5: []}
    }
    with open(path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            domain_levels = row[3].split('.')
            row.append(domain_levels)
            t = row[0]
            if t == 'legit':
                legit.append(row)
            else:
                dga.append(row)

            l_d_l = len(domain_levels)
            domains_by_level_num[t][l_d_l].append(row)

            domains_num[t][l_d_l] += 1

            domain_levels.reverse()
            for idx, l in enumerate(domain_levels):
                if l not in domains_level_num[t][idx]:
                    domains_level_num[t][idx][l] = 0
                domains_level_num[t][idx][l] += 1

    
    for t  in ['legit', 'dga']:
        # for l_n  in domains_level_num[t]:
        #     with open(f'{path}_domains_{l_n}_{t}.csv', "w") as f:
        #         writer = csv.writer(f)
        #         for domain_name in domains_level_num[t][l_n]:
        #             writer.writerow([domain_name, domains_level_num[t][l_n][domain_name]])
        for level_num in domains_by_level_num[t]:
            with open(f'{path}_rows_w_{level_num}_level_{t}.csv', "w") as f:
                writer = csv.writer(f)
                for r in domains_by_level_num[t][level_num]:
                    writer.writerow(r)
    pass


def inspect_alexa_domain_with_least_2_level():
    path = 'datasets/setAtrain_h_t_domins.csv'

    legit = []

    third_level = []
    with open(f'{path}_third_level_legit.csv', "w") as f:
        writer = csv.writer(f)
        with open(path, "r") as f:
            reader = csv.reader(f)
            for row in reader:
                domain_levels = row[3].split('.')
                row.append(domain_levels)
                t = row[0]
                if t == 'legit' and len(domain_levels) > 3:
                    third_level.append(row + domain_levels)
                    writer.writerow(row + domain_levels)

if __name__ == "__main__":

    # translate in captures
    # df = pd.read_csv('datasets/training.csv')
    # df2 = pd.DataFrame()
    # df2['domain'] = df['dns']
    # df2['label'] = df['class']
    # df2['class'] = df['dga']
    # df2.index = df.index
    # df2.sort_index().to_csv('/tmp/training.csv')

    # exit(0)



    # df = pd.DataFrame()
    # df.insert(0, 'domain', training.domain)
    # df.insert(1, 'label', training.label)
    # df.insert(2, 'level', df['domain'].apply(lambda x: x.count('.'))
    # df.set_index('domain')
    # df.sort_index()
    # df.to_csv('/tmp/training.csv')

    # training = cp.training
    # df = pd.DataFrame()
    # df.insert(0, 'domain', training.domain)
    # df.insert(1, 'label', training.label)
    # df.insert(2, 'level', training.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1))
    # df = df.sort_values('level', ascending=False)
    # df.groupby(['label', 'level']).describe().to_csv('/tmp/training.side.csv')

    # df = pd.DataFrame()
    # df.insert(0, 'domain', training.domain)
    # df.insert(1, 'label', training.label)
    # df.insert(2, 'level', training.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1))
    # df = df.sort_values('level', ascending=False)
    # df.to_csv('/tmp/training.bo.csv')
    # df.groupby(['label', 'level']).describe().to_csv('/tmp/training.describe.csv')

    # import os
    # if not os.path.exists('/tmp/all.csv'):
    #     dfs = []
    #     for idx, c in enumerate(cp.all_):
    #         df = pd.DataFrame(columns=['domain', 'level', 'type'])
    #         df['domain'] = c.domain
    #         df['level'] = c.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1)
    #         df['type'] = [c.type] * df.shape[0]
    #         dfs.append(df)
    #         print(f'Made {idx}/{len(cp.all_)}')
    #     df = pd.concat(dfs, axis=0)
    #     df.to_csv('/tmp/all.csv')
    # else:
    #     df = pd.read_csv('/tmp/all.csv')

    # df.groupby(['level', 'type']).describe(include=['O']).to_csv(f'/tmp/all.describe.level_type.csv')
    # df.groupby(['type', 'level']).describe(include=['O']).to_csv(f'/tmp/all.describe.type_level.csv')
    # df.drop(columns='type').groupby(['level']).describe(include=['O']).to_csv(f'/tmp/all.describe.level.csv')



    # training describe for getting level domain distrubtion
    # c = cp.training
    # df = pd.DataFrame(columns=['domain', 'level', 'type'])
    # df['domain'] = c.domain
    # df['level'] = c.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1)
    # df['type'] = c.label
    # df.groupby(['level', 'type']).describe(include=['O']).to_csv(f'/tmp/training.describe.level_type.csv')
    # df.groupby(['type', 'level']).describe(include=['O']).to_csv(f'/tmp/training.describe.type_level.csv')
    # df.drop(columns='type').groupby(['level']).describe(include=['O']).to_csv(f'/tmp/training.describe.level.csv')
    # df = df.loc[df['type'] == 'legit']
    # df.groupby(['level', 'type']).describe(include=['O']).to_csv(f'/tmp/training.LEGIT.describe.level_type.csv')
    # df.groupby(['type', 'level']).describe(include=['O']).to_csv(f'/tmp/training.LEGIT.describe.type_level.csv')
    # df.drop(columns='type').groupby(['level']).describe(include=['O']).to_csv(f'/tmp/training.LEGIT.describe.level.csv')

    # tld distribution
    # c = cp.training
    # df = pd.DataFrame(columns=['tld', 'level', 'type'])
    # df['domain'] = c.domain
    # df['tld'] = c.domain.apply(lambda x: extractor(x).suffix)
    # df['level'] = c.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1)
    # df['type'] = c.label
    # df = df.groupby(['tld', 'type', 'level']).describe(include=['O'])
    # # df.to_csv(f'/tmp/training.tld.describe.level_type.csv')
    # df = df.reset_index(level='type')
    # legit = df.loc[df['type'] == 'legit']
    # dga = df.loc[df['type'] == 'dga']
    # legit.join(dga, lsuffix='_legit', rsuffix='_dga').to_csv('/tmp/training.tld.joined.describe.level_type.csv')

    # tld distribution without level
    # c = cp.training
    # df = pd.DataFrame(columns=['domian', 'tld', 'type'])
    # df['domain'] = c.domain
    # df['tld'] = c.domain.apply(lambda x: extractor(x).suffix)
    # df['type'] = c.label
    # df = df.groupby(['tld', 'type']).describe(include=['O'])
    # # df.to_csv(f'/tmp/training.tld.describe.level_type.csv')
    # df = df.reset_index(level='type')
    # legit = df.loc[df['type'] == 'legit']
    # dga = df.loc[df['type'] == 'dga']
    # legit.join(dga, lsuffix='_legit', rsuffix='_dga').to_csv('/tmp/training.tld.joined.describe.wo_level.csv')
    
    # df.groupby(['type', 'level']).describe(include=['O']).to_csv(f'/tmp/training.tld.describe.type_level.csv')
    # df.drop(columns='type').groupby(['level']).describe(include=['O']).to_csv(f'/tmp/training.tld.describe.level.csv')



    # normal-captures: domain-levels distribution
    # dfs = []
    # for idx, c in enumerate(list(cp.normal.values())):
    #     df = pd.DataFrame(columns=['domain', 'level', 'type'])
    #     df['domain'] = c.domain
    #     df['level'] = c.domain.apply(lambda x: 0 if extractor(x).subdomain == '' else extractor(x).subdomain.count('.') + 1)
    #     df['type'] = [c.type] * df.shape[0]
    #     dfs.append(df)
    # df = pd.concat(dfs, axis=0)
    # # df.groupby(['level', 'type']).describe(include=['O']).to_csv(f'/tmp/normal.describe.level_type.csv')
    # # df.groupby(['type', 'level']).describe(include=['O']).to_csv(f'/tmp/normal.describe.type_level.csv')
    # # df.drop(columns='type').groupby(['level']).describe(include=['O']).to_csv(f'/tmp/normal.describe.level.csv')

    # # df.groupby(['level', 'type']).describe(include='domain').to_csv(f'/tmp/all.describe.level_type.csv')
    # # df.groupby(['type', 'level']).describe(include='domain').to_csv(f'/tmp/all.describe.type_level.csv')
    # # df['domain'].apply(lambda x: extractor(x).domain).value_counts(normalize=True).to_csv(f'/tmp/all.unique.domain.csv')
    # # df['domain'].apply(lambda x: extractor(x).subdomain).value_counts(normalize=True).to_csv(f'/tmp/all.unique.subdomain.csv')
    # # df['domain'].value_counts(normalize=True).to_csv(f'/tmp/all.value_counts.csv')

    ## normal-captures: tld distribution
    # dfs = []
    # for idx, c in enumerate(list(cp.normal.values())):
    #     df = pd.DataFrame(columns=['domain', 'level', 'type'])
    #     df['domain'] = c.domain
    #     df['tld'] = c.domain.apply(lambda x: extractor(x).suffix.lower())
    #     df['type'] = [c.type] * df.shape[0]
    #     dfs.append(df)
    # df = pd.concat(dfs, axis=0)
    # # df = df.groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/normals.tld.joined.describe.wo_level.csv')
    # df = df.drop_duplicates().groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/normals.tld.no_dup.describe.wo_level.csv')

    ## botnet-captures: tld distribution
    # dfs = []
    # for idx, c in enumerate(list(cp.botnet.values())):
    #     df = pd.DataFrame(columns=['domain', 'level', 'type'])
    #     df['domain'] = c.domain
    #     df['tld'] = c.domain.apply(lambda x: extractor(x).suffix.lower())
    #     df['type'] = [c.type] * df.shape[0]
    #     dfs.append(df)
    # df = pd.concat(dfs, axis=0)
    # df = df.groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/botnets.tld.joined.describe.wo_level.csv')
    # df = df.drop_duplicates().groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/botnets.tld.no_dup.describe.wo_level.csv')

    # normal-outputs: tld distribution
    # dfs = []
    # model = Model.Model.load(DomainLevel.SIDE)
    # for idx, c in enumerate(list(cp.botnet.values())):
    #     input = Input
    #     df = pd.DataFrame(columns=['domain', 'level', 'type'])
    #     df['domain'] = c.domain
    #     df['tld'] = c.domain.apply(lambda x: extractor(x).suffix.lower())
    #     df['type'] = [c.type] * df.shape[0]
    #     dfs.append(df)
    # df = pd.concat(dfs, axis=0)
    # df = df.groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/botnets.tld.joined.describe.wo_level.csv')
    # df = df.drop_duplicates().groupby(['tld', 'type']).describe(include=['O']).to_csv('/tmp/botnets.tld.no_dup.describe.wo_level.csv')

    # normal-outputs: tld distribution
    # model_side = Model.Model.load(DomainLevel.SIDE)
    # model_lower = Model.Model.load(DomainLevel.LOWER)
    # models = [Model.Model.load(DomainLevel.SIDE), Model.Model.load(DomainLevel.LOWER)]
    # dfs = []
    # for idx, c in enumerate(list(cp.normal.values())):
    #     input_view_s = InputView(c, model_side.dl)
    #     input_view_l = InputView(c, model_lower.dl)
    #     output_view_ss = OutputView(input_view_s, model_side)
    #     output_view_ll = OutputView(input_view_l, model_lower)
    #     df = pd.DataFrame(columns=['domain', 'tld'])
    #     df['domain'] = c.domain
    #     df['tld'] = c.domain.apply(lambda x: extractor(x).suffix.lower())
    #     df['legit_ss'] = output_view_ss.legit
    #     df['legit_ll'] = output_view_ll.legit
    #     df['dga_ss'] = output_view_ss.dga
    #     df['dga_ll'] = output_view_ll.dga
    #     dfs.append(df)
    # df = pd.concat(dfs, axis=0, ignore_index=True)
    # df = df.drop_duplicates()
    # df = df.groupby(['tld']).agg(['sum'])
    # df.drop(columns='domain', inplace=True)
    # df.columns = df.columns.droplevel(level=1)
    # df['tot'] = df.loc[:, ['legit_ss', 'dga_ss']].sum(axis=1)
    # df['legit_ss_p'] = df['legit_ss'].divide(df['tot'])
    # df['dga_ss_p'] = df['dga_ss'].divide(df['tot'])
    # df['legit_ll_p'] = df['legit_ll'].divide(df['tot'])
    # df['dga_ll_p'] = df['dga_ll'].divide(df['tot'])
    # df.reindex(['tot', 'legit_ss', 'dga_ss', 'legit_ll', 'dga_ll', 'legit_ss_p', 'dga_ss_p', 'legit_ll_p', 'dga_ll_p'], axis=1).to_csv('/tmp/predicted.normal.2.tld.csv')


    # normal-outputs: tld distribution
    # model_side = Model.Model.load(DomainLevel.SIDE)
    # model_lower = Model.Model.load(DomainLevel.LOWER)
    # models = [Model.Model.load(DomainLevel.SIDE), Model.Model.load(DomainLevel.LOWER)]
    # dfs = []
    # for idx, c in enumerate(list(cp.normal.values())):
    #     input_view_s = InputView(c, model_side.dl)
    #     input_view_l = InputView(c, DomainLevel.DOMAIN)
    #     output_view_ss = OutputView(input_view_s, model_side)
    #     output_view_ll = OutputView(input_view_l, model_lower)
    #     df = pd.DataFrame(columns=['domain', 'tld'])
    #     df['domain'] = c.domain
    #     df['tld'] = c.domain.apply(lambda x: extractor(x).suffix.lower())
    #     df['input_ss'] = c.domain.apply(DomainLevel.SIDE.translate)
    #     df['len_ss'] = df['input_ss'].apply(len)
    #     df['dga_ss'] = output_view_ss.dga
    #     df['input_ll'] = c.domain.apply(DomainLevel.DOMAIN.translate)
    #     df['len_ll'] = df['input_ll'].apply(len)
    #     df['dga_ll'] = output_view_ll.dga
    #     dfs.append(df)

    # tld distribution without level
    def boo(x):
        dom = x['domain']
        p = dom.rfind('.')
        doms = {sfx: ('%s.%s' % (dom[:p], sfx)) for sfx in sfxs}
        return {**x, **doms}

    sfxs = ['net','org','ru','info','eu','de', 'in']

    if not os.path.exists('/tmp/training_sampled.only_com.csv'):
        c = cp.training
        df = pd.DataFrame()
        df = c.readable
        df['tld'] = c.tld
        df = df.loc[df['tld'] == 'com'].sample(n=10000, axis=0)
        df = df.apply(boo, axis=1)
        df = pd.DataFrame.from_records(df.values)
        df.to_csv('/tmp/training_sampled.only_com.csv')
    else:
        df = pd.read_csv('/tmp/training_sampled.only_com.csv')

    model = Model.Model.load(DomainLevel.LOWER)
    df = df.drop('class', axis=1)
    for dl in [DomainLevel.LOWERT, DomainLevel.DOMAINT, DomainLevel.WHOLE]:
        _df = df.copy()
        for l in ['domain'] + sfxs:
            X_str = df[l].apply(dl.translate)
            X_num = X_str.apply(model.domain2input).to_numpy()
            X = pad_sequences(X_num, maxlen=model.MAXLEN, truncating='post')
            _df[l], _ = model.predict(X)
        # _df.groupby(['label', 'class']).agg(['count', 'mean']).to_csv('/tmp/training_sampled.%s_%s.tld.csv' % (dl.name, model.dl.name))
        _df.groupby(['label']).agg(['count', 'mean']).to_csv('/tmp/training_sampled.%s_%s.tld.csv' % (dl.name, model.dl.name))

    pass