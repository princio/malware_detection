#! /usr/bin/env python
import argparse, time, os
from .pcap2csv import Pcap2Csv

def main():
    parser = argparse.ArgumentParser(description='Add some integers.')
    parser.add_argument('path', metavar='/somewhere/capture.pcap', type=str, nargs='+',
                        help='one or more pcap file paths (if -R is passed, these should be directories.')
    parser.add_argument('-R',
                        action='store_true',
                        help='Recursive search, PATH is one or more directories.')
    parser.add_argument('--no-fast',
                        action='store_true',
                        default=False,
                        help='Avoid fast pcap parsing to include much more parsed information.')
    parser.add_argument('--no-domain',
                        action='store_true',
                        default=False,
                        help='Use model DOMAIN')
    parser.add_argument('--redo',
                        default=False,
                        action='store_true',
                        help='Force re-doing processing if output file already exists')
    parser.add_argument('--no-nosfx',
                        default=False,
                        action='store_true',
                        help='Use model NOSFX')
    parser.add_argument('--no-legitness',
                        action='store_true',
                        default=False,
                        help='Avoid adding a column to csv file with the indication that the domain belongs to the top10milion domain list.')
    parser.add_argument('--buffer',
                        metavar='SIZE',
                        default=0,
                        help='Buffer size filled of parsed DNS packets. When SIZE is reached, it flushs to disk.')
    parser.add_argument('--num',
                        metavar='NUM',
                        default=0,
                        help='The maxinum packets to be parsed.')
    parser.add_argument('--timeout',
                        metavar='SECONDS',
                        default=0,
                        help='The timeout in seconds after that the parsing will be stopped.')
    parser.add_argument('--outdir',
                        metavar='/somewhere/',
                        default=None,
                        help='The output dir where to save the resulting csv files.')


    args = vars(parser.parse_args())

    if args['outdir'] and not os.path.isdir(args['outdir']):
        print('Output dir not exists: %s' % args['outdir'])
        exit(1)

    files = []
    sizes = []
    if args['R']:
        for folder in args['path']:
            if not os.path.isdir(folder):
                print(f'Argument <{folder}> is not a folder.')
                continue
            for walker in os.walk(folder):
                for filename in walker[2]:
                    if filename[filename.rfind('.'):] != '.pcap': continue
                    files.append(os.path.join(folder, filename))
                    sizes.append(os.stat(os.path.join(folder, filename)).st_size)
                    print(f'Added to list <{filename}> of size {int(sizes[-1]/1_000_000)} MB.')
    else:
        for path in args['path']:
            if not os.path.isfile(path):
                print(f'Argument <{path}> is not a file.')
                continue
            if path[path.rfind('.'):] != '.pcap':
                print(f'Argument <{path}> is not a PCAP file.')
                continue
            files.append(path)
            sizes.append(os.stat(path).st_size)
            print(f'Added to list <{path}> of size {int(sizes[-1]/1_000_000)} MB.')

    domain=(not args['no_domain'])
    nosfx=(not args['no_nosfx'])
    fast_mode=(not args['no_fast'])
    redo=args['redo']
    legit_dsfx=(not args['no_legitness'])
    buffer_size = int(args['buffer']) if int(args['buffer']) > 0 else 0
    pkt_num = args['num'] if args['num'] > 0 else 0
    timeout = args['timeout'] if args['timeout'] > 0 else 0

    pcap_2_csv = Pcap2Csv(outdir=args['outdir'], domain=domain, nosfx=nosfx, fast_mode=fast_mode, legit_dsfx=legit_dsfx, buffer_size=buffer_size, pkt_num=pkt_num, timeout=timeout)

    files = {files[i[0]]: i[1] for i in sorted(enumerate(sizes), key=lambda x:x[1])}
    for file in files:
        print('Processing file: %9dMB\t\t%s' % (int(files[file]/1_000_000), file))
        df = pcap_2_csv.convert(file, redo=redo)
        if type(df) == bool:
            if df:
                print('Already parsed, skipping')
            else:
                print('Error during parsing, skipping')
        else:
            print('Retrieved dns packet: %9d' % df.shape[0])