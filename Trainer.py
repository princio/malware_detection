from datetime import datetime
import csv, time
from json import dump as json_dump
from collections import OrderedDict, Counter as collection_counter
import numpy as np
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM
from sklearn.model_selection import StratifiedShuffleSplit

class Trainer:

    def __init__(self, output_folder, training_dataset_path, max_epoch, nfolds, test_size=0.1, batch_size=128, date=datetime.now().date(), name=''):
        self.output_folder = output_folder
        self.training_dataset_path = training_dataset_path
        self.max_epoch = max_epoch
        self.nfolds = nfolds
        self.test_size = test_size
        self.batch_size = batch_size
        self.date = date
        self.name = name

        data= []
        with open("datasets/%s.csv" % self.training_dataset_path, "r") as f:
            reader = csv.reader(f)
            for row in reader:
                data.append(row)
        
        self.binary_labels = [x[0] for x in data]
        self.X = [x[2] for x in data]
        self.labels = [x[1] for x in data]
        self.alphabet = {x:idx+1 for idx, x in enumerate(OrderedDict.fromkeys(''.join(self.X)))}
        with open("%s/alphabet.json" % self.output_folder, "w") as json_file:
            json_dump(self.alphabet, json_file)

        confusion_matricies = {}

    def train(self):
        X = self.X

        max_features = len(self.alphabet) + 1
        maxlen = np.max([len(x) for x in X])

        # wlength = [len(x) for x in X]
        # wl_dist = [0 for i in range(maxlen + 1)]
        # for wl in wlength:
        #     wl_dist[wl] += 1

        maxlen = 48

        X = [[self.alphabet[y] for y in x] for x in X]
        X = sequence.pad_sequences(X, maxlen=maxlen, truncating='post')
    
        y_binary = np.array([0 if x == 'legit' else 1 for x in self.binary_labels])
        # Convert labels to 0-37 for multi class
        valid_class = {i:indx for indx, i in enumerate(set(self.labels))}
        y = np.array([valid_class[x] for x in self.labels])
        white = valid_class['alexa']

        start = time.time()

        sss = StratifiedShuffleSplit(n_splits=self.nfolds, test_size=self.test_size, random_state=0)
        fold =0
        for train, test in sss.split(X, y):
            print("fold %u/%u" % (fold + 1, self.nfolds))
            fold = fold + 1
            
            X_train, X_test, y_train, y_test = X[train], X[test], y_binary[train], y_binary[test]

            model = self.__build_binary_model(max_features, maxlen)
            
            sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=0)
            # one time for-cycle
            for train, test in sss1.split(X_train, y_train):
                X_train, X_holdout, y_train, y_holdout =  X_train[train], X_train[test], y_train[train], y_train[test]
            
            # Create weight for two-class classification stage
            labels_dict = collection_counter(y_train)
            class_weight = self.__create_class_weight(labels_dict, 0.1)
            best_auc = 0.0
            best_epoch = -1
            
            print("Training the model for two-class classification stage...")
            for n_epoch in range(self.max_epoch):
                print("Training epoch %d..." % n_epoch)
                model.fit(X_train, y_train, batch_size=self.batch_size, epochs=1, class_weight=class_weight)
                t_probs = model.predict(X_holdout)
                t_result = [0 if (x <= 0.5) else 1 for x in t_probs]
                t_acc = accuracy_score(y_holdout, t_result)
                confusion_m = confusion_matrix(y_holdout, t_result)
                confusion_matricies[f"{fold}_{n_epoch}"] = confusion_m.ravel().tolist()
                if t_acc > best_auc:
                    best_model = model
                    best_auc = t_acc
                    best_epoch = n_epoch
                save_model(model, "fold_%d/binary_model_epoch_%d" % (fold, n_epoch))
            
            with open("%s/accuracies.json" % (output_folder), 'w') as fp:
                json.dump(confusion_matricies, fp)
                
            # save_model(best_model, "fold_%d/best_binary_model_epoch_%d" % (fold, best_epoch))

            # y_pred = best_model.predict(X_test)
            # y_bin_result = [0 if(x <= 0.5) else 1 for x in y_pred]
            # y_binary_true = y_test
            # with open("%s/report_binary_fold_%d.txt" % (output_folder, fold), 'a') as f_report_binary:
            #     class_binary={'white':0 , 'black':1}
            #     evaluate(y_binary_true, y_bin_result, f_report_binary, start, time.time(), fold, class_binary)

            # End of two-class classification stage



    def __build_binary_model(self, max_features, maxlen):
        """Build LSTM model for two-class classification"""
        model = Sequential()
        model.add(Embedding(max_features, 128, input_length = maxlen))
        model.add(LSTM(128))
        model.add(Dropout(0.5))
        model.add(Dense(1))
        model.add(Activation('sigmoid'))

        model.compile(loss='binary_crossentropy', optimizer='rmsprop')

        return model


    def __get_data(self, datasetname): 
        data= []
        with open("datasets/%s.csv" % datasetname, "r") as f:
            reader = csv.reader(f)
            for row in reader:
                data.append(row)
        return data


    def __get_and_save_alphabet(self, X): 
        alphabet = {x:idx+1 for idx, x in enumerate(OrderedDict.fromkeys(''.join(X)))}

        with open("%s/alphabet.json" % self.output_folder, "w") as json_file:
            json.dump(alphabet, json_file)

        return alphabet

    def __create_class_weight(self, labels_dict, mu):
        """Create weight based on the number of domain name in the dataset"""
        total = np.sum(list(labels_dict.values()))
        keys = labels_dict.keys()
        class_weight = dict()

        for key in keys:
            score = math.pow(total / float(labels_dict[key]), mu)
            class_weight[key] = score	

        return class_weight