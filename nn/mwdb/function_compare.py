from function_f import function_f
from function_l import function_l
from function_p import function_p
from function_s import function_s
import pickle
from utils import ApplyConfiguration

import os, json
import pandas as pd



if __name__ == "__main__":
    with open('functions_output/configs.json', 'r') as fp:
        configs = json.load(fp)

    nth = configs['nth']

    th2s = configs['th2s']
    
    configs = [
        ApplyConfiguration.from_dict(configs[hash])
        for hash in configs if hash not in [ 'nth', 'th2s'] 
    ]

    metrics_path = './functions_output/metrics.csv'

    df_metrics = pd.DataFrame()
    if os.path.exists(metrics_path):
        df_metrics = pd.read_csv(metrics_path, header=[ 0, 1 ], index_col=0)

    hashes = df_metrics.index.to_numpy().tolist()
    new_hashes = []
    new_metrics = []
    for i, config in enumerate(configs):
        config_hash = config.__hash__()

        if config_hash in hashes:
            continue

        # if config_hash not in metricss:
        path_f = f'./functions_output/f/{config_hash}.pickle'
        with open(path_f, 'rb') as f:
            cms_ths = pickle.load(f)
        new_metrics.append(function_p(cms_ths, th2s))
        new_hashes.append(config_hash)

        pass

    if len(new_metrics) > 0:
        metrics_names = [ (k1, k2) for k1, d1 in new_metrics[0].items() for k2, d2 in d1.items() ]
        metrics_values = [[ d2 for k1, d1 in metrics.items() for k2, d2 in d1.items() ] for metrics in new_metrics ]

        df_metrics_new = pd.DataFrame(metrics_values, columns=pd.MultiIndex.from_tuples(metrics_names))
        df_metrics_new['hash'] = new_hashes
        df_metrics_new.set_index('hash', inplace=True)

        df_metrics = pd.concat([ df_metrics, df_metrics_new ], axis=0)

        df_metrics.to_csv(metrics_path)

    # reset hash index
    df_configs = pd.DataFrame([{ ('config', k) : v  for k,v in config.__dict__.items() } for config in configs ])
    df_configs.columns = pd.MultiIndex.from_tuples(df_configs.columns)
    df = pd.concat([df_configs, df_metrics.reset_index(drop=True)], axis=1)

    for fixed_metric in [ 'model_id', 'top10m', 'wsize', 'windowing', 'inf' ]:

        compare = function_s(df, fixed_metric)

        compare.to_csv(f'{metrics_path}.{fixed_metric}.csv')

        idx = pd.IndexSlice

        print(fixed_metric)
        print(compare.loc[idx[:, ['0.25', '0.5', '0.75']], :])
        print()
        
        # print(compare.loc[:, idx[['mean', 'std','best'], :]].reset_index().groupby('level_0').aggregate(['max','min','mean','std']))

        pass

    pass