from re import DEBUG
import psycopg2
import pandas as pd
from sqlalchemy import create_engine
import numpy as np

eng = create_engine("postgresql://postgres:postgres@localhost/dns",)
db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")

dgas = [ 0, 1, 2, 3 ]


TN = 0
FP = 1
FN = 2
TP = 3

#
# this function works with more configs
# input:
#       metrics:     array of metrics, one per each config
#       th2s:        [ 0.25, 0.5, 0.75 ]
# output:
#       cms:        [ cm_th0, cm_th1, ..., cm_thn, ]
def function_s(configs, metricss, dgas, metrics, parameter):
    """
    Input:
        - configs:      array of config
        - metricss:     array of metrics, each corresponding one config
        - dgas:         the dga we want to evaluate (0,1,2,3)
        - metrics:      the metrics we want to evaluate ('tn,tp_max', 'tn2+tp2', 0.25, 0.5, 0.75)
        - parameter:    the config parameter that we want to evaluate, fixing the others config parameters.

    Output:
        - df:           A Dataframe where the rows correspond to each config less the fixed config parameter.
                        The columns illustrate the behaviour of this parameter:
                            - with the mean
                            - with the standard deviation
                            - 
    
    """

    metrics = [ (dga, metric) for dga in dgas for metric in metrics ]

    df_configs = pd.DataFrame([{ ('config', k) : v  for k,v in config.__dict__.items() } for config in configs ])
    df_metricss = pd.DataFrame([{ (k1, k2): d2 for k1, d1 in metrics.items() for k2, d2 in d1.items() } for metrics in metricss ])

    df = pd.concat([df_configs, df_metricss], axis=1)

    df.columns = pd.MultiIndex.from_tuples(df.columns)


    fixed_config = [ col for col in df.columns if col[0] == 'config' and col[1] != parameter ]

    df  = df.sort_values(by=fixed_config + [('config', parameter)])
    df  = df.set_index(fixed_config)

    # calculate the mean and std for each metrix, fixed all the config parameters excpet one.
    # 
    stats = []
    for i in df.index.drop_duplicates():
        stat = {}
        for metric in metrics:
            _df_ = df.loc[i].sort_values(metric, ascending=False)
            stat[( metric, 'mean' )] = _df_[metric].mean()
            stat[( metric, 'std' )] = _df_[metric].std()
            stat[( metric, 'best' )] = _df_[('config', parameter)].iloc[0]
            pass
        stats.append(stat)
        pass
    
    df_s = pd.DataFrame(stats)

    df_s.columns = pd.MultiIndex.from_tuples(df_s.columns)

    df_s = df_s.round(3)

    dbts = []
    for metric in metrics:
        dbt = {}

        dbt[('mean', 'mean')] = df_s[(metric, 'mean')].mean()
        dbt[('mean', 'max')] = df_s[(metric, 'mean')].max()
        dbt[('mean', 'min')] = df_s[(metric, 'mean')].min()

        dbt[('std', 'mean')] = df_s[(metric, 'std')].mean()
        dbt[('std', 'max')] = df_s[(metric, 'std')].max()
        dbt[('std', 'min')] = df_s[(metric, 'std')].min()

        dbt[('std', '%min')] = (100 * (df_s[(metric, 'std')] / df_s[(metric, 'mean')]).min())
        dbt[('std', '%max')] = (100 * (df_s[(metric, 'std')] / df_s[(metric, 'mean')]).max())
        dbt[('std', '%mean')] = (100 * (df_s[(metric, 'std')] / df_s[(metric, 'mean')]).mean())

        dbt[('best', '1')] = ', '.join([ f'{k[0]}' for i, k in enumerate(df_s[(metric, 'best')].value_counts().iteritems()) ])

        dbts.append(dbt)

        pass

    df_compare = pd.DataFrame(dbts, index=metrics)

    df_compare.columns = pd.MultiIndex.from_tuples(df_compare)

    print(df_compare)
    
    return df_compare