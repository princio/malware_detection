"""Train and test LSTM classifier"""
import numpy as np
import os
import random
import csv
import collections
import math
import pandas as pd
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import precision_score, recall_score, classification_report,accuracy_score, f1_score
from datetime import datetime
import enum

class DomainLevel(enum.Enum):
    """
    TOP means: a3.a2.a1.a0 -> a1a0
    SIDE means: a3.a2.a1.a0 -> a3a0
    """
    TOP = 4
    SIDE = 3

    @staticmethod
    def parse(s):
        if s.lower() == 'top':
            return DomainLevel.TOP
        if s.lower() == 'side':
            return DomainLevel.SIDE
        raise 'Undefined domain level'


def build_binary_model(max_features, maxlen):
    """Build LSTM model for two-class classification"""
    model = Sequential()
    model.add(Embedding(max_features, 128, input_length=maxlen))
    model.add(LSTM(128))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))

    model.compile(loss='binary_crossentropy',optimizer='rmsprop')

    return model

def build_multiclass_model(max_features, maxlen):
    """Build multiclass LSTM model for multiclass classification"""
    model = Sequential()
    model.add(Embedding(max_features, 128, input_length=maxlen))
    model.add(LSTM(128))
    model.add(Dropout(0.5))
    model.add(Dense(38))
    model.add(Activation('softmax'))

    model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop')

    return model

def create_class_weight(input_array, mu):
    """Create weight based on the number of domain name in the dataset"""
    counter = collections.Counter(input_array)
    total = sum(counter.values())
    class_weight = {}

    for key in counter:
        class_weight[key] = math.pow(total/float(counter[key]), mu)	

    return class_weight

def classifaction_report_csv(report, precision, recall, f1_score, fold):
    """Generate the report to data processing"""
    with open('classification_report_cost.csv', 'a') as f:
        report_data = []
        lines = report.split('\n')
        row = {}
        row['class'] =  "fold %u" % (fold+1)
        report_data.append(row)
        for line in lines[2:44]:
            row = {}
            line = " ".join(line.split())
            row_data = line.split(' ')
            if(len(row_data)>2):
                if(row_data[0]!='avg'):
                    row['class'] = row_data[0]
                    row['precision'] = float(row_data[1])
                    row['recall'] = float(row_data[2])
                    row['f1_score'] = float(row_data[3])
                    row['support'] = row_data[4]
                    report_data.append(row)
                else:
                    row['class'] = row_data[0]+row_data[1]+row_data[2]
                    row['precision'] = float(row_data[3])
                    row['recall'] = float(row_data[4])
                    row['f1_score'] = float(row_data[5])
                    row['support'] = row_data[6]
                    report_data.append(row)
        row = {}
        row['class'] = 'macro'
        row['precision'] = float(precision)
        row['recall'] = float(recall)
        row['f1_score'] = float(f1_score)
        row['support'] = 0
        report_data.append(row)
        dataframe = pd.DataFrame.from_dict(report_data)
        dataframe.to_csv(f, index = False)

def run(max_epoch, nfolds, domain_level: DomainLevel, column = 2, batch_size=128):
    """Run train/test on logistic regression model"""

    with open('datasets/setAtrain_h_t_domins.2.csv', "r") as f:
        reader = csv.reader(f)
        indata = [row for row in reader]

    print(len(indata))
    
    indata_np = np.asarray(indata)

    binary_labels = [x[0] for x in indata]
    X = [domain_level.translate(x[column]) for x in indata]

    alphabet = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
    alphabet_converter = {letter: idx+1 for idx, letter in enumerate(alphabet)}
    max_features = len(alphabet) + 1
    maxlen = np.max([len(x) for x in X])

    X = [[alphabet_converter[y] for y in x] for x in X]
    X = sequence.pad_sequences(X, maxlen=maxlen)
   
    y_binary = np.array([0 if x == 'legit' else 1 for x in binary_labels])

    sss = StratifiedShuffleSplit(n_splits=nfolds, test_size=0.2, random_state=0)
    fold = 0
    for train, test in sss.split(X, y_binary):
        print("fold %u/%u" % (fold+1, nfolds))
        fold = fold+1
        X_train_epochs, X_test, y_train_epochs, y_test, rows_test = X[train], X[test], y_binary[train], y_binary[test], indata_np[test]

        model = build_binary_model(max_features, maxlen)
        
        print("Training the model for two-class classification stage...")

        sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=0)
        for train, test in sss1.split(X_train_epochs, y_train_epochs):
            X_train, X_holdout, y_train, y_holdout = X_train_epochs[train], X_train_epochs[test], y_train_epochs[train], y_train_epochs[test]
        
        class_weight = create_class_weight(y_train, 0.1)
        print('class weight', class_weight)

        best_auc = 0.0
        for ep in range(max_epoch):
            print(len(X_train))
            model.fit(X_train, y_train, batch_size=batch_size, epochs=1, class_weight=class_weight)
            t_probs = model.predict(X_holdout)
            t_result = [0 if(x<=0.5) else 1 for x in t_probs]
            t_acc = accuracy_score(y_holdout, t_result)
            if t_acc > best_auc:
                best_model = model
                best_auc = t_acc

        model_json = best_model.to_json()
        name_file = f"model_{domain_level.name}_{fold}_{ep}_binary"
        with open(name_file + ".json", "w") as json_file:
            json_file.write(model_json)
            best_model.save_weights(name_file + ".h5")
        print("Saved two-class model to disk")
        #End of two-class classification stage

        threshold = 0.5
        y_pred = best_model.predict(X_test)
        y_result = [0 if(x <= threshold) else 0 for x in y_pred]

        with open(f'{name_file}.csv', 'w', newline='\n') as f:
            writer = csv.writer(f)
            writer.writerows([row + [y_pred[idx]] for idx, row in enumerate(rows_test)])

        #Calculate the final result
        score = f1_score(y_test, y_result, average="macro")
        precision = precision_score(y_test, y_result, average="macro")
        recall = recall_score(y_test, y_result, average="macro")
        report = classification_report(y_test, y_result, digits=12)
        acc = accuracy_score(y_test, y_result)
        print('\n classification report:\n', report)
        print('F1 score:', score)
        print('Recall:', recall)
        print('Precision:', precision)
        print('Acc:', acc)
   
if __name__ == "__main__":
    import sys
    if len(sys.argv) < 4:
        print("Too few arguments:\n\t%nfolds %nepochs %%domain_level[TOP,SIDE]")
    domain_level = DomainLevel.parse(sys.argv[3])
    run(int(sys.argv[1]), int(sys.argv[2]), domain_level)