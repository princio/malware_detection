import re
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
import requests
import pandas as pd
import os, sys
import subprocess
import re
import json


TYPE='Botnet'
FOLDER = {
    'Normal': 'normal',
    'Botnet': 'malware'
}
REGEX = {
    'Normal': r">(CTU-Normal-\d+(?:-\d)?)\/<",
    'Botnet': r">(CTU-Malware-Capture-Botnet-\d+(?:-\d)?)\/<"
}
URL_NAME = {
    'Normal': 'CTU-Normal',
    'Botnet': 'CTU-Malware-Capture-Botnet'
}
CAPTURE_ID_POS = {
    'Normal': 11,
    'Botnet': 27
}
ROOT_DIR = '/media/princio/ssd512/stratosphere'
ROOT_DIRS = {
    'pcap': os.path.join(ROOT_DIR, 'pcap', FOLDER[TYPE])
}

def get_file_to_save_name(name, ext):
    s_num, num = '', 0
    while os.path.exists('%s%s.%s' % (name, s_num, ext)):
        num += 1
        s_num = '_%d' % num
    
    file_name = '%s%s.%s' % (name, s_num, ext)
    print('Saving in <%s>.' % file_name)
    return file_name



def get_last_saved_file(folder_path, name, ext):
    not_found = True
    num = 0
    for walker in os.walk(folder_path):
        for file_name in walker[2]:
            if file_name.find(name) == 0:
                not_found = False
                if file_name.rfind('_') == -1:
                    num = 0
                    s_num = ''
                else:
                    r_idx = 1 + file_name.rfind('_')
                    l_idx = file_name.rfind('.')
                    tmp = int(file_name[r_idx:l_idx])
                    num = num if num > tmp else tmp
                    s_num = '_%d' % num
    if not_found:
        return None
    file_name = '%s%s.%s' % (name, s_num, ext)
    print('Found <%s>.' % file_name)
    return os.path.join(folder_path, file_name)



def retrieve_real_size(file_url):
    out = subprocess.run(['wget', '--spider', file_url], text=True, capture_output=True)
    r_id = out.stderr.find('Length: ') + len('Length: ')
    l_id = out.stderr[r_id:].find(' ')
    if r_id == -1:
        return None
    try:
        size = int(out.stderr[r_id:r_id + l_id])
        print('Retrieved size:', size)
    except:
        print('Broken link for: <%s>' % (file_url))
        return None
    return size



def retrieve_captures_infos(redo = False):
    if not redo:
        file_path = get_last_saved_file('./stratosphere/', 'captures', 'json')
        if file_path:
            with open(file_path, 'r') as fp:
                return json.load(fp)
        else:
            print('Json captures file not exists.')

    print('Fetching from web...')
    
    r = requests.get('https://mcfp.felk.cvut.cz/publicDatasets/', verify=False)

    regex = REGEX[TYPE]

    matches = re.finditer(regex, r.text, re.MULTILINE)

    mw_captures = []
    for match in matches:
        for group in match.groups():
            mw_captures.append(group)

    print('Found %d malware captures.' % len(mw_captures))

    captures = {}
    for mw in mw_captures:
        print(f'https://mcfp.felk.cvut.cz/publicDatasets/{mw}/')
        r = requests.get(f'https://mcfp.felk.cvut.cz/publicDatasets/{mw}/', verify=False)
        regex = r"<td.*?><a.*?>\s*([\w\d\-\._]+)\s*<\/a><\/td><td.*?>\s*([\s\d\-\:]+)\s*<\/td><td.*?>\s*([\d\.]+[KMG]?)\s*<\/td>"
        matches = re.finditer(regex, r.text, re.MULTILINE)
        captures[mw] = []
        for match in matches:
            groups = list(match.groups())
            ext = groups[0][1 + groups[0].rfind('.'):]
            size = None
            if ext == 'pcap':
                size = retrieve_real_size(f'https://mcfp.felk.cvut.cz/publicDatasets/{mw}/{groups[0]}')
            captures[mw].append({
                'capture_id': mw[CAPTURE_ID_POS[TYPE]:],
                'filename': groups[0],
                'name': groups[0][:groups[0].rfind('.')],
                'websize': groups[2],
                'size': size,
                'ext': ext
            })

    captures_filename = get_file_to_save_name('./stratosphere/captures', 'json')

    with open(captures_filename, 'w') as fp:
        json.dump(captures, fp, indent='\t')
    
    return captures


def cmd_download(pcap):
    print(pcap)
    return [
        'wget',
        '--limit-rate', '5m',
        f'https://mcfp.felk.cvut.cz/publicDatasets/{URL_NAME[TYPE]}-{pcap["capture_id"]}/{pcap["filename"]}',
        '-O',
        os.path.join(ROOT_DIRS['pcap'], f'{pcap["id"]}.pcap')
    ]

def check_pcaps_state(dict_captures, dict_files):
    pcaps = []
    dict_pcaps = {}
    not_processed = []
    for capture in dict_captures:
        for dict_element in dict_captures[capture]:
            if 'ext' not in dict_element or not dict_element['ext'] == 'pcap':
                continue
            pcap = dict_element
            pcap['id'] = '%s_%s' % (pcap['capture_id'], pcap['name'])
            pcap['size_mb'] = size2text(pcap['size'])

            if pcap['id'] not in dict_files:
                pcap['not-processed'] = True
                for ext in ROOT_DIRS:
                    pcap[ext] = False
                not_processed.append(pcap)
            else:
                pcap['not-processed'] = False
                for ext in ROOT_DIRS:
                    pcap[ext] = ext in dict_files[pcap['id']]

            pcaps.append(pcap)
            dict_pcaps[pcap['id']] = pcap

    df = pd.DataFrame(pcaps).sort_values(by=['size'], ascending=False)
    df.to_csv(get_file_to_save_name('./stratosphere/pcaps', 'csv'))

    return df, dict_pcaps, not_processed

def filename2id(filename, ext):
    if filename.find(ext) == -1:
        raise Exception(f'File error: {filename} in {ext}')
    if filename.find('.err.') > -1:
        id_ = filename[:- len('.err.') - len(ext)]
    else:
        id_ = filename[:-1 - len(ext)]
    return id_

    
def walk_root_dirs():
    dict_files = {'no-id': {ext: [] for ext in ROOT_DIRS}}
    for ext in ROOT_DIRS:
        root_dir = ROOT_DIRS[ext]
        for walker in os.walk(root_dir):
            for filename in walker[2]:
                capture_id_idx = filename.find('_')
                if capture_id_idx == -1 or capture_id_idx > 5:
                    dict_files['no-id'][ext].append(filename)
                    print(f'No-id for {filename} in {ext}')
                else:
                    filename_id = filename2id(filename, ext)
                    if filename_id not in dict_files:
                        dict_files[filename_id] = {}
                    if ext in dict_files[filename_id]:
                        print(f'Duplicate for {filename} in {ext}')
                    dict_files[filename_id][ext] = filename
    return dict_files

def text2size(size):
    last_char = size[-1]
    exp = 1 + 'KMG'.find(last_char)
    if exp > 0:
        return int(float(size[:-1]) * (1000 ** exp if exp > -1 else 0))

def size2text(size):
    from math import log10, floor
    n_zeros = floor(log10(size))
    unit = ''
    n_zeros -= 6
    size = size / (10 ** 6)
    unit = 'M'
    return '%d%s' % (size, unit)

def yes_or_no(question):
    while "the answer is invalid":
        reply = str(input(question+' (y/n): ')).lower().strip()
        if reply[0] == 'y':
            return True
        if reply[0] == 'n':
            return False

if __name__ == "__main__":
    redo1 = False if len(sys.argv) < 2 else sys.argv[1].lower() == 'true'
    redo2 = False if len(sys.argv) < 3 else sys.argv[2].lower() == 'true'

    dict_captures = retrieve_captures_infos(redo1)

    dict_files = walk_root_dirs()

    df_pcaps, dict_pcaps, not_processed = check_pcaps_state(dict_captures, dict_files)

    for ext in ROOT_DIRS:
        df = df_pcaps[df_pcaps[ext] == False]
        print(f'For ext:{ext} missing {df.shape[0]}/{df_pcaps.shape[0]} files')

    df_to_process = pd.DataFrame(not_processed).sort_values(by='size')

    # dict_to_process = df_to_process.to_dict(orient='index')
    # for index in dict_to_process:
    #     pcap = dict_to_process[index]
    #     cmd = cmd_download(pcap)
    #     print('Downloading %s having size %d bytes...' % (pcap['id'], pcap['size']))
    #     # if pcap['size'] > 500_000_000:
    #     #     if not yes_or_no('Size exceed 500MB, do you want to continue?'):
    #     #         continue
    #     print(subprocess.run(cmd, capture_output=True))

    pass