import re
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
import requests
import pandas as pd

def retrieve_captures_infos():
    import json

    try:
        with open('./tmp/stratosphere_captures.json', 'r') as fp:
            return json.load(fp)
    except:
        print('No file, fetching from web...')
    
    r = requests.get('https://mcfp.felk.cvut.cz/publicDatasets/', verify=False)

    regex = r">(CTU-Malware-Capture-Botnet-\d+(?:-\d)?)\/<"

    matches = re.finditer(regex, r.text, re.MULTILINE)

    mw_captures = []
    for match in matches:
        for group in match.groups():
            mw_captures.append(group)

    print(mw_captures[0:20])

    captures = {}

    for mw in mw_captures:
        print(f'https://mcfp.felk.cvut.cz/publicDatasets/{mw}/')
        r = requests.get(f'https://mcfp.felk.cvut.cz/publicDatasets/{mw}/', verify=False)
        regex = r"<td.*?><a.*?>\s*([\w\d\-\._]+)\s*<\/a><\/td><td.*?>\s*([\s\d\-\:]+)\s*<\/td><td.*?>\s*([\d\.]+[KMG]?)\s*<\/td>"
        matches = re.finditer(regex, r.text, re.MULTILINE)
        captures[mw] = []
        for match in matches:
            groups = list(match.groups())
            extensions = groups[0][groups[0].rfind('.'):]
            captures[mw].append([extensions] + groups)

    with open('./tmp/captures.json', 'w') as fp:
        json.dump(captures, fp, indent='\t')

    pcaps = []
    for capture in captures:
        exts = ''
        passivedns = False
        labeled = False
        for file in captures[capture]:
            if file[0] == '.pcap':
                pcap = file
            else:
                exts += file[0].replace('.', '') + ','
                passivedns |= file[0].find('passivedns') > 0
                labeled |= file[0].find('labeled') >= 0
        size = text2size(pcap[3])
        # print(f'{capture[27:]:10}{pcap[1]:40}{pcap[2]:20}{size:30}')
        pcaps.append({
            'capture': capture[27:],
            'name': pcap[1],
            'date': pcap[2],
            'size': size,
            'labeled': labeled,
            'passivedns': passivedns
        })
    df = pd.DataFrame(pcaps).sort_values(by=['size'], ascending=False)
    df.to_csv('./tmp/file.csv')

    return df

def text2size(size):
    last_char = size[-1]
    exp = 1 + 'KMG'.find(last_char)
    if exp > 0:
        return int(float(size[:-1]) * (1000 ** exp if exp > -1 else 0))

def size2text(size):
    from math import log10, floor
    n_zeros = floor(log10(size))
    unit = ''
    n_zeros -= 6
    size = size / (10 ** 6)
    unit = 'M'
    return '%d%s' % (size, unit)

def print_pcap_infos(df):

    sizes = [5_000_000_000, 1_000_000_000, 100_000_000, 1_000_000]
    dfs = []
    for i, size in enumerate(sizes):
        if i == 0:
            dfs.append(df[df['size'] > size].copy())
        elif i != len(sizes)-1:
            dfs.append(df[df['size'] < size].copy())
        else:
            dfs.append(df[(df['size'] > sizes[i]) & (df['size'] < sizes[i-1])].copy())

    dict_f = {}
    for i, _ in enumerate(dfs):
        if i == 0:
            k = '[%s,inf]' % size2text(sizes[i])
        elif i == len(sizes)-1:
            k = '[0,%s]' % size2text(sizes[i])
        else:
            k = '[%s,%s]' % (size2text(sizes[i]), size2text(sizes[i-1]))
        pdns = dfs[i]['passivedns'].value_counts()
        lb = dfs[i]['labeled'].value_counts()
        dict_f[k] = {'passivedns': pdns.loc[True], 'labeled': lb.loc[True], 'tot': pdns.sum()}
    print(pd.DataFrame(dict_f).to_string())

    pass

def print_pcap_lt_1gb(df_captures):
    df = df_captures.copy()
    df = df[(df['size'] < 1_000_000_000) & (df['passivedns'] == True)]
    print(df.sort_values(by='size', ascending=False).head())
    print(df.dtypes)
    pass

if __name__ == "__main__":
    try:
        df_captures = pd.read_csv('./tmp/stratosphere_captures.csv')
    except:
        print('No file, fetching from web...')
        df_captures = retrieve_captures_infos()
    print_pcap_infos(df_captures)
    print_pcap_lt_1gb(df_captures)
    pass