from datetime import datetime
from PyInquirer import prompt
import csv
import hashlib
import re
import psycopg2
import os, json

from Model import Model
from Report import Report
from Dataset import Dataset
from Repository import DatasetRepository

connection = psycopg2.connect(user = "postgres",
                                  password = "porcodio",
                                  host = "127.0.0.1",
                                  port = "5432",
                                  database = "malware")

cursor = connection.cursor()


def file_hash(path):
    sha256_hash = hashlib.sha256()
    with open(path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def model_hash(path):
    sha256_hash = hashlib.sha256()
    with open(f"{path}.json", "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    with open(f"{path}.h5", "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def pretty(d, indent=0):
   for key, value in d.items():
      print('\t' * indent + str(key))
      if isinstance(value, dict):
         pretty(value, indent+1)
      else:
         print('\t' * (indent+1) + str(value))

def test():
    cursor = connection.cursor()
    cursor.execute("""SELECT id FROM public.models""")
    models = [ Model.fetch(connection, x[0]) for x in cursor.fetchall() ]

    cursor = connection.cursor()
    cursor.execute("""SELECT id FROM public.datasets""")
    datasets = [ Dataset.fetch(connection, x[0]) for x in cursor.fetchall() ]

    for model in models:
        for dataset in datasets:
            if not Report.exists(connection, model.id, dataset.id):
                report = Report()
                report.model = model
                report.dataset = dataset
                report.labels = dataset.labels
                model.test(dataset, report)
                report.metrics()
                report.save(connection)
    pass

if __name__ == "__main__":
    datasets = DatasetRepository.fetch_all(connection)
    
    questions = [
        {
            'type': 'list',
            'name': 'model_root',
            'message': 'Which model do you want to add to database?',
            'choices': [{"value": _dir, "name": _dir}  for _dir in os.listdir('./models')]
        }
    ]
    model_root = prompt(questions)["model_root"]

    m = re.search(r'(\d{8}_\d{6})__epochs_(\d+)_folds_(\d+)', model_root)
    if m is None:
        print('Model ${model} not supported.')
        exit(1)

    epochs = int(m.group(2))
    folds = int(m.group(3))
    datetime_ = datetime.strptime(m.group(1), "%Y%m%d_%H%M%S")

    with open(f'models/{model_root}/accuracies.json', 'r') as fp:
        confusion_matricies = json.load(fp)

    for fold in range(1, folds+1):
        print(fold)
        for epoch in range(epochs):
            path = f"models/{model_root}/fold_{fold}/binary_model_epoch_{epoch}"

            model_ = Model()
            model_.datetime = datetime_
            model_.hash = model_hash(path)
            model_.path = path
            model_.folds = folds
            model_.epochs = epochs
            model_.fold = fold
            model_.epoch = epoch
            model_.test_size = 0.05
            model_.multiclass = False
            model_.training_confusion_matrix = confusion_matricies[f'{fold}_{epoch}']

            try:
                model_.save(connection)
            except psycopg2.errors.UniqueViolation:
                print('Model \'%s\' already inserted.' % path)
                connection.rollback()
    
    connection.close()
