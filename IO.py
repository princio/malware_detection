import csv, os, numpy as np
from enum import Enum
from math import floor
from DomainLevel import Transformer, extractor
import json
import re
import pandas as pd
from keras.preprocessing.sequence import pad_sequences

def is_right(x):
    distance = abs((0 if x['label'] == 'legit' else 1) - x['probability'])
    rightness = 1 if (x['label'] == 'legit' and x['probability'] < 0.5) or (x['label'] == 'dga' and x['probability'] > 0.5) else 0
    return rightness, distance

def normalcapture_wrongness(x):
    rightness = 1 if x > 0.5 else 0
    distance = 0 if x <= 0.5 else x-0.5
    return rightness, distance


class Input:
    """
    Represent the class that take a Capture (pcap) and transform it into
    a list of dn appropriately modified.
    This is useful because if you have to use the same Input more than once
    you don't have to transform the whole Capture each time.
    """
    def __init__(self, capture, transformation):
        self.capture = capture
        self.transformation = transformation
        self.name = self.capture.name + '.' + self.transformation.name
        self.input = self.capture.dn.apply(self.transformation.translator()).rename('input')
        dir = f'predictions/{self.capture.name}/transformation_{self.transformation.name}/'
        path = f'{dir}/{self.name}.csv'
        if not os.path.exists(path):
            os.makedirs(dir, exist_ok=True)
            pd.concat([self.capture.readable, self.input], axis=1).to_csv(path)
        pass

    @property
    def input_np(self):
        return self.input.to_numpy()

    @property
    def labeled(self):
        return self.capture.labeled

    @property
    def dn(self):
        return self.capture.dn

    @property
    def tlds(self):
        return self.capture.transformations

    @property
    def df(self):
        return pd.concat([self.dn, pd.Series(self.input, name='input')], axis=1)

class DF:
    def __init__(self, dn, input, prediction):
        def count(x):
            c = 1 + Transformer.nosfx(x).count('.')
            return str(c) if c <= 2 else '>2'
        self.dn = dn
        self._df = pd.DataFrame(data={'dn': dn, 'X': input, 'Y': prediction})
        self._df['level_dn'] = self._df['dn'].apply(count)
        self._df['level_X'] = self._df['X'].apply(count)
        self._default = self._df.copy()
        self._DF = self._df.copy()
        self.threshold = 0.5
        pass

    def frame(self):
        DF = self._DF.copy()
        self._DF = self._default.copy()
        return DF

    def default(self):
        self._default = self._DF.copy()
        return self

    def reset(self):
        self._default = self._df.copy()
        self._DF = self._default.copy()
        return self

    def unique(self):
        self._DF = self._DF.drop_duplicates(subset=['X'])
        return self

    def unique_dn(self):
        self._DF = self._DF.drop_duplicates(subset=['dn'])
        return self

    def legit(self):
        self._DF = self._DF.loc[self._DF['Y'] < self.threshold]
        return self

    def dga(self):
        self._DF = self._DF.loc[self._DF['Y'] >= self.threshold]
        return self

class Output:
    def __init__(self, input, model, prediction, time_elapsed = None):
        self.input = input
        self.model = model
        self.prediction = prediction
        self.time_elapsed = time_elapsed
        self.name = self.input.name + '.' + self.model.name
        self.df = pd.DataFrame({'X': self.input.input, 'Y': self.prediction })
        self.DF = DF(input.capture.dn, input.input, prediction)
        self.threshold = 0.5
        pass

    # @property
    # def unique(self):
    #     return self.df.drop_duplicates()

    # def dga(self, unique = False):
    #     df = self.df.drop_duplicates() if unique else self.df
    #     return df.loc[df['Y'] >= self.threshold]

    # def legit(self, unique = False):
    #     df = self.df.drop_duplicates() if unique else self.df
    #     return df.loc[df['Y'] < self.threshold]

    # def fractions(self, unique=True):
    #     dgas = self.dga.shape[0]
    #     legits = self.legit.shape[0]
    #     dgas_u = self.dga.drop_duplicates().shape[0]
    #     legits_u = self.legit.drop_duplicates().shape[0]
    #     total = self.df.shape[0]
    #     total_u = self.unique.shape[0]
    #     return {'no-unique': {'dga': dgas/total, 'legit': legits/total},
    #             'unique': {'dga': dgas_u/total_u, 'legit': legits_u/total_u}}
    @staticmethod
    def predict(input, model, redo = False):
        dir = f'predictions/{input.capture.name}/transformation_{input.transformation.name}/'
        path = f'{dir}{input.name}.{model.name}.csv'

        if not redo and os.path.exists(path):
            prediction = pd.read_csv(path)['prediction']
            with open(f'{dir}/{input.name}.{model.name}.time', 'r') as f:
                time_elapsed = json.load(f)
        else:
            os.makedirs(dir, exist_ok=True)
            predictions, time_elapsed = model.predict(input.input_np)
            prediction = pd.Series(predictions, name='prediction')
            prediction.to_csv(path)
            with open(f'{dir}/{input.name}.{model.name}.time', 'w') as f:
                json.dump(time_elapsed, f)

        return Output(input, model, prediction, time_elapsed)

