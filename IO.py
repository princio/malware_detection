import csv, os, numpy as np
from enum import Enum
from math import floor
from DomainLevel import Transformer, extractor
import json
import re
import pandas as pd
from keras.preprocessing.sequence import pad_sequences

def is_right(x):
    distance = abs((0 if x['label'] == 'legit' else 1) - x['probability'])
    rightness = 1 if (x['label'] == 'legit' and x['probability'] < 0.5) or (x['label'] == 'dga' and x['probability'] > 0.5) else 0
    return rightness, distance

def normalcapture_wrongness(x):
    rightness = 1 if x > 0.5 else 0
    distance = 0 if x <= 0.5 else x-0.5
    return rightness, distance


class Input:
    """
    Represent the class that take a Capture (pcap) and transform it into
    a list of domain appropriately modified.
    This is useful because if you have to use the same Input more than once
    you don't have to transform the whole Capture each time.
    """
    def __init__(self, capture, transformation):
        self.capture = capture
        self.transformation = transformation
        self.name = self.capture.name + '.' + self.transformation.name
        self.input = self.capture.domain.apply(self.transformation.translator()).rename('input')
        dir = f'predictions/{self.capture.name}/transformation_{self.transformation.name}/'
        path = f'{dir}/{self.name}.csv'
        if not os.path.exists(path):
            os.makedirs(dir, exist_ok=True)
            pd.concat([self.capture.readable, self.input], axis=1).to_csv(path)
        pass

    @property
    def input_np(self):
        return self.input.to_numpy()

    @property
    def labeled(self):
        return self.capture.labeled

    @property
    def domain(self):
        return self.capture.domain

    @property
    def tlds(self):
        return self.capture.transformations

    @property
    def df(self):
        return pd.concat([self.domain, pd.Series(self.input, name='input')], axis=1)


class DF:
    def __init__(self, dn, input, prediction):
        self.dn = dn
        self._df = pd.DataFrame({'X': input, 'Y': prediction })
        self._unique = self._df.drop_duplicates()
        self.DF = self._df
        self.threshold = 0.5
        pass

    def is_unique(self):
        return self.DF == self._unique

    def unique(self, unique=True):
        self.DF = self._unique if unique else self._df
        return self

    @property
    def dga(self):
        return self.DF.loc[self.DF['Y'] >= self.threshold]

    @property
    def dga_frac(self):
        return self.dga.shape[0] / self.DF.shape[0]

    @property
    def legit_frac(self):
        return self.legit.shape[0] / self.DF.shape[0]

    @property
    def legit(self):
        return self.DF.loc[self.DF['Y'] < self.threshold]

    @property
    def level(self):
        # DN_level = self.DF['DN'].apply(lambda x: Transformer.nosfx(x).count('.'))
        # return pd.DataFrame({'DN': self.DF['DN'], 'level': DN_level})
        DN_level = self.DF['input'].apply(lambda x: Transformer.nosfx(x).count('.'))
        return pd.DataFrame({'input': self.DF['input'], 'level': DN_level})

    @property
    def level_count(self):
        return self.level.value_counts()

    @property
    def fractions(self):
        dgas = self.dga.shape[0]
        legits = self.legit.shape[0]
        total = self.DF.shape[0]
        return {'dga': dgas/total, 'legit': legits/total}

class Output:
    def __init__(self, input, model, prediction, time_elapsed = None):
        self.input = input
        self.model = model
        self.prediction = prediction
        self.time_elapsed = time_elapsed
        self.name = self.input.name + '.' + self.model.name
        self.df = pd.DataFrame({'X': self.input.input, 'Y': self.prediction })
        self.DF = DF(input.capture.domain, input.input, prediction)
        self.threshold = 0.5
        pass

    # @property
    # def unique(self):
    #     return self.df.drop_duplicates()

    # def dga(self, unique = False):
    #     df = self.df.drop_duplicates() if unique else self.df
    #     return df.loc[df['Y'] >= self.threshold]

    # def legit(self, unique = False):
    #     df = self.df.drop_duplicates() if unique else self.df
    #     return df.loc[df['Y'] < self.threshold]

    # def fractions(self, unique=True):
    #     dgas = self.dga.shape[0]
    #     legits = self.legit.shape[0]
    #     dgas_u = self.dga.drop_duplicates().shape[0]
    #     legits_u = self.legit.drop_duplicates().shape[0]
    #     total = self.df.shape[0]
    #     total_u = self.unique.shape[0]
    #     return {'no-unique': {'dga': dgas/total, 'legit': legits/total},
    #             'unique': {'dga': dgas_u/total_u, 'legit': legits_u/total_u}}
    @staticmethod
    def predict(input, model, redo = False):
        dir = f'predictions/{input.capture.name}/transformation_{input.transformation.name}/'
        path = f'{dir}{input.name}.{model.name}.csv'

        if not redo and os.path.exists(path):
            prediction = pd.read_csv(path)['prediction']
            with open(f'{dir}/{input.name}.{model.name}.time', 'r') as f:
                time_elapsed = json.load(f)
        else:
            os.makedirs(dir, exist_ok=True)
            predictions, time_elapsed = model.predict(input.input_np)
            prediction = pd.Series(predictions, name='prediction')
            prediction.to_csv(path)
            with open(f'{dir}/{input.name}.{model.name}.time', 'w') as f:
                json.dump(time_elapsed, f)

        return Output(input, model, prediction, time_elapsed)

