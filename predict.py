import numpy as np
import Paths
import csv, os
from plot_num import plot_num
from DataHandler import Prediction, Predictor, Capture
import tldextract

if __name__ == "__main__":


    from DomainLevel import DomainLevel
    import pandas as pd

    # for dl in DomainLevel.all():
    #     print(dl.name, dl.translate('google.com'))


    # bt = pd.read_csv('datasets/setAtrain_h_t_domins.csv', names=['class', 'dga', 'bo', 'domain'])
    # bt.drop('bo', axis=1)
    # bt['subdomain'] = bt['domain'].apply(lambda domain: len(tldextract.extract(domain).subdomain) > 0)
    # bt.to_csv('datasets/subdomains.csv')
    # bt = bt.groupby(["class", "subdomain"], sort=True).count()
    # bt.to_csv('datasets/subdomains.grouped.csv')


    bt = pd.read_csv('datasets/setAtrain_h_t_domins.csv', names=['class', 'dga', 'bo', 'domain'])
    bt.drop('bo', axis=1)
    bt['domain_len'] = bt['domain'].apply(lambda domain: len(tldextract.extract(domain).domain))
    bt['subdomain_len'] = bt['domain'].apply(lambda domain: len(tldextract.extract(domain).subdomain))
    bt['len'] = bt['domain'].apply(lambda domain: len(domain))
    bt['training_len'] = bt['domain'].apply(lambda domain: len(DomainLevel.LOWERT.translate(domain)))
    bt.to_csv('datasets/len.csv')
    bt = bt.groupby(["class", 'dga'], sort=True).mean()
    bt.to_csv('datasets/len.grouped.csv')

    print('done')
    # bt = pd.read_csv('datasets/domains.csv', names=['class', 'dga', 'domain', 'domain0'])
    # bt = bt.groupby("domain0", sort=True).count()
    # bt.to_csv('datasets/domains.grouped.csv')

    # bt = pd.read_csv('datasets/tlds.csv', names=[ 'class', 'dga', 'bo', 'domain', 'tld' ])
    # bt.drop(['domain', 'bo'], axis=1, inplace=True)

    # dgas = bt.loc[bt['class'] == 'dga']
    # legits = bt.loc[bt['class'] == 'legit']

    # dgas = dgas.groupby("tld", sort=True, squeeze=True).count()
    # legits = legits.groupby("tld", sort=True, squeeze=True).count()
    
    # dgas.drop('class', axis=1, inplace=True)
    # legits.drop('class', axis=1, inplace=True)

    # dgas.columns = ['dga']
    # legits.columns = ['legit']

    # a = pd.concat([dgas, legits], axis=1)
    # # bo = bt.groupby(["class", "tld"]).count()

    # # bo.to_csv('datasets/tlds2.csv')
    # # bo.sort(['dga'  ])

    # print(dgas)
    # print(legits)
    # print(a.to_markdown())
    # a.to_csv('datasets/tlds3.csv')
    # print('pd')

    # for dl in DomainLevel.all():
    #     bt[dl.name] = bt['domain'].apply(dl.translate)

    # bt.to_csv('/tmp/setAtrain_h_t_domins.csv')

    

    # bt.reset_index(inplace=True)
    # bt.sort_values(['count', 'domain', 'input'], axis=0, inplace=True, ignore_index=True, ascending=False)
    # bt.drop(columns='index', inplace=True)
    # bt.to_csv('/tmp/big_table_vertical_sorted.csv')

    from Model import Model
    model_top = Model.from_name('TOP')
    model_side = Model.from_name('SIDE')


    # capture = Capture.from_path('datasets/generic_1.csv')
    # predictor = Predictor(capture)
    # predictor.predict_multi([model_top, model_side], DomainLevel.all())


    capture = Capture.from_path(Paths.normal['27']['path'])
    predictor = Predictor(capture)
    predictor.predict_multi([model_top, model_side], DomainLevel.all())

    # data_out_0 = predictor.predict(model_top, DomainLevel.SUB_TLD, redo=True)
    # data_out_1 = predictor.predict(model_top, DomainLevel.DOM_TLD, redo=True)
    # data_out_2 = predictor.predict(model_side, DomainLevel.SUB_DOM, redo=True)
    # data_out_3 = predictor.predict(model_side, DomainLevel.DOM_SUB, redo=True)


    # with open('/tmp/generic_tot.csv', 'w') as f:
    #     writer = csv.writer(f)
    #     writer.writerow(['#', data_out_0.dl.name, data_out_1.dl.name, data_out_2.dl.name, data_out_3.dl.name ])
    #     writer.writerows([[i, data_out_0.data[idx][DataOut.PREDICTION], data_out_1.data[idx][DataOut.PREDICTION], data_out_2.data[idx][DataOut.PREDICTION], data_out_3.data[idx][DataOut.PREDICTION]] for idx, i in enumerate(inputs)])


    # from CSVInspector import Inspector

    # insp = Inspector()

    # redo = True
    # capture2 = Capture.from_csv(Paths.mixed['1']['path'])
    # predictor2 = Predictor(capture2)

    # data_out_0 = predictor2.predict(model_top, DomainLevel.SUB_TLD, redo=redo)
    # insp.set_data(data.data_out, data.csv_path)
    # insp.group_domains(DomainLevel.SUB_TLD)

    # p1 = data.predict(model_top, DomainLevel.DOM_TLD, redo=redo)
    # insp.set_data(data.data_out, data.csv_path)
    # insp.group_domains(DomainLevel.DOM_TLD)

    # p2 = data.predict(model_side, DomainLevel.SUB_DOM, redo=redo)
    # insp.set_data(data.data_out, data.csv_path)
    # insp.group_domains(DomainLevel.SUB_DOM)

    # p3 = data.predict(model_side, DomainLevel.DOM_SUB, redo=redo)
    # insp.set_data(data.data_out, data.csv_path)
    # insp.group_domains(DomainLevel.DOM_SUB)


    # with open('/tmp/generic_mixed_1_tot.csv', 'w') as f:
    #     writer = csv.writer(f)
    #     writer.writerow(['float', DomainLevel.SUB_TLD.name, DomainLevel.DOM_TLD.name, DomainLevel.SUB_DOM.name, DomainLevel.DOM_SUB.name ])
    #     writer.writerows([[i, p0[idx][0], p1[idx][0], p2[idx][0], p3[idx][0]] for idx, i in enumerate(inputs)])





    pass