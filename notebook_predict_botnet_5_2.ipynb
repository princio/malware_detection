{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test normal capture\n",
    "Successivamente viene analizzato un pcap file relativo ad una traffico di rete generato da un computer non infetto. Questo ci permette di valutare la capacità della rete di predire correttamente i nomi di dominio benigni in un contesto reale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/princio/anaconda3/envs/keras/lib/python3.8/site-packages/tldextract/.tld_set\n",
      "/home/princio/anaconda3/envs/keras/lib/python3.8/site-packages/tldextract/.tld_set\n"
     ]
    }
   ],
   "source": [
    "from Capture import normal, mixed, botnet, training, Capture\n",
    "from IO import Input, Output, DF\n",
    "from Model import Model\n",
    "from DomainLevel import Transformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predizione con più modelli e trasformazioni\n",
    "Vengono effettuate predizioni del pcap con modelli diversi e trasformazioni diverse.\n",
    "I modelli sono i seguenti:\n",
    "- modello NOSFX, ovvero allenato con input privati del suffisso;\n",
    "- modello NOSFX_NP, come NOSFX ma gli input sono senza il carattere punto [.] (NP sta per NoPoint);\n",
    "- modello LAST, allenato con solamente il livello maggiore, o l'ultimo da destra (aaa.bbb.ccc.co.uk -> aaa)\n",
    "\n",
    "Le transformazioni sono le stesse dei modelli, più la trasformazione *DOMAIN*, ovvero quella che estrae solamente il primo livello successivo al suffisso (aaa.bbb.ccc.co.uk -> ccc).\n",
    "Ogni predizione verrà indicata con il nome della trasformazione, *slash*, il nome del modello. Quindi la predizione con trasformazione NOSFX e modello LAST verrà indicata con NOSFX/LAST.\n",
    "\n",
    "Di seguito vengono effettuate tutte le predizioni. Per ognuna si presta particolare attenzione a quei nomi di dominio predetti erroneamente come DGA (essendo il computer non infetto, tutti gli input sono sicuramente legittimi). Inoltre si analizzano anche i vari nomi di dominio sulla base del loro numero di livelli.\n",
    "\n",
    "L'output di questa cella mostra il numero di nomi di dominio aventi numero di livelli (oltre il suffisso) pari a 1, 2 o maggiori di 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level_dn</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>&gt;2</th>\n",
       "      <th>tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187702</td>\n",
       "      <td>118081</td>\n",
       "      <td>162604</td>\n",
       "      <td>468387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level_dn       1       2      >2     tot\n",
       "0         187702  118081  162604  468387"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captures = [botnet['5.2']]\n",
    "\n",
    "models = [Model.load(1), Model.load(2), Model.load(3), Model.load(-3)]\n",
    "trs= [ Transformer.NOSFX, Transformer.ANY, Transformer.NOSFX_NP, Transformer.DOMAIN, Transformer.LAST ]\n",
    "\n",
    "reports = {}\n",
    "dga_df = {}\n",
    "leveldn = {}\n",
    "DF_s = {}\n",
    "dga_leveldn = {}\n",
    "dga_leveldn_count = {}\n",
    "dga_leveldn_norm_count = {}\n",
    "for capture in captures:\n",
    "    for model in models:\n",
    "        tr = model.tr\n",
    "        input  = Input(capture, tr)\n",
    "        output = Output.predict(input, model, False)\n",
    "        output.threshold = 0.5\n",
    "        DF_s[(tr.name, model.name)] = output.DF\n",
    "        Y_pred = [0 if y <= 0.5 else 1 for y in output.prediction.to_numpy()]\n",
    "        Y_true = [0] * len(Y_pred)\n",
    "        reports[(capture.name, tr.name, model.name)] = classification_report(Y_true, Y_pred, digits=6, zero_division=0)\n",
    "        DF = output.DF.unique().default()\n",
    "        leveldn[(capture.name, tr.name, model.name)] = DF.frame().value_counts(subset=['level_dn'], sort=False, normalize=True).T.to_dict()\n",
    "        DF.dga().default()\n",
    "        dga_df[(capture.name, tr.name, model.name)] = DF.frame()\n",
    "        dga_leveldn[(capture.name, tr.name, model.name)] = DF.frame()\n",
    "        dga_leveldn_count[(capture.name, tr.name, model.name)] = DF.frame().value_counts(subset=['level_dn'], sort=False, normalize=False).T.to_dict()\n",
    "        dga_leveldn_norm_count[(capture.name, tr.name, model.name)] = DF.frame().value_counts(subset=['level_dn'], sort=False, normalize=True).T.to_dict()\n",
    "\n",
    "capture_leveldn_count = DF.reset().frame().value_counts(subset='level_dn', normalize=False, sort=False).to_frame()\n",
    "capture_leveldn_count.loc['tot'] = capture_leveldn_count.sum(axis=0)\n",
    "capture_leveldn_count = capture_leveldn_count.T\n",
    "capture_leveldn_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('botnet_5_2', 'NOSFX', 'NOSFX_1-30'), ('botnet_5_2', 'NOSFX', 'NOSFX_NOPUNCT_1-30'), ('botnet_5_2', 'ANY', 'ANY'), ('botnet_5_2', 'LAST', 'LAST')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dga_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_cdab1524_51b9_11eb_9622_21f34e328664\" ><caption>Error relative to inputs</caption><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >legit</th>        <th class=\"col_heading level0 col1\" >dga</th>        <th class=\"col_heading level0 col2\" >tot</th>        <th class=\"col_heading level0 col3\" >dga/tot</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level0_row0\" class=\"row_heading level0 row0\" >ANY</th>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level1_row0\" class=\"row_heading level1 row0\" >ANY</th>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row0_col0\" class=\"data row0 col0\" >3737</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row0_col1\" class=\"data row0 col1\" >1059</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row0_col2\" class=\"data row0 col2\" >4796</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row0_col3\" class=\"data row0 col3\" >0.220809</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level0_row1\" class=\"row_heading level0 row1\" >NOSFX</th>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level1_row1\" class=\"row_heading level1 row1\" >NOSFX_1-30</th>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row1_col0\" class=\"data row1 col0\" >3606</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row1_col1\" class=\"data row1 col1\" >1073</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row1_col2\" class=\"data row1 col2\" >4679</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row1_col3\" class=\"data row1 col3\" >0.229323</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level0_row2\" class=\"row_heading level0 row2\" >LAST</th>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level1_row2\" class=\"row_heading level1 row2\" >LAST</th>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row2_col0\" class=\"data row2 col0\" >2648</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row2_col1\" class=\"data row2 col1\" >1097</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row2_col2\" class=\"data row2 col2\" >3745</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row2_col3\" class=\"data row2 col3\" >0.292924</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level0_row3\" class=\"row_heading level0 row3\" >NOSFX</th>\n",
       "                        <th id=\"T_cdab1524_51b9_11eb_9622_21f34e328664level1_row3\" class=\"row_heading level1 row3\" >NOSFX_NOPUNCT_1-30</th>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row3_col0\" class=\"data row3 col0\" >3273</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row3_col1\" class=\"data row3 col1\" >1406</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row3_col2\" class=\"data row3 col2\" >4679</td>\n",
       "                        <td id=\"T_cdab1524_51b9_11eb_9622_21f34e328664row3_col3\" class=\"data row3 col3\" >0.300492</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f81984a8520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "tr_rows = {}\n",
    "\n",
    "for k in DF_s:\n",
    "    DF_s[k].reset().unique().default()\n",
    "    legit = DF_s[k].legit().frame().shape[0]\n",
    "    dga = DF_s[k].dga().frame().shape[0]\n",
    "    tr_rows[k] = pd.Series([legit, dga, legit + dga, dga/(legit + dga)])\n",
    "#                            keys=[('legit', 'dn'), ('legit', 'X'),\\\n",
    "#                                  ('dga', 'dn'), ('dga', 'X'), \\\n",
    "#                                  ('tot', 'X')])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(tr_rows).T\n",
    "df.columns = ['legit', 'dga', 'tot', 'dga/tot']\n",
    "#df = df\n",
    "df = df.sort_values(by=['dga/tot'])\n",
    "df.convert_dtypes()\\\n",
    ".style\\\n",
    ".set_caption('Error relative to inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain\n",
       "google                            4\n",
       "zzpfqxwtsaqucxdmypvodylfdapv      1\n",
       "ifnjcavyljzcelbafutijamfazg       1\n",
       "ibculvlfuficmxsgmaiusfascrcei     1\n",
       "ibdqwnblvgqmffqgyrdagmgqizwkeu    1\n",
       "                                 ..\n",
       "rnjdyvkaqemkqlbzxhqzhobhy         1\n",
       "rlvofovpmnpjztdizbmkrfqx          1\n",
       "rklvmfdbrhiwcizlmjltozam          1\n",
       "rkeanvksizugeqtqoqchdyornb        1\n",
       "acmbhawhmsogilfmdueqprkfywk       1\n",
       "Length: 1070, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = DF_s[('NOSFX', 'NOSFX_1-30')]\n",
    "\n",
    "DF.reset().unique().default()\n",
    "df = DF.dga().frame().sort_values(by='Y')[['dn', 'Y']]\n",
    "df['domain'] = df['dn'].apply(Transformer.domain)\n",
    "df.value_counts(subset='domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF_s[('NOSFX', 'NOSFX_1-30')]\n",
    "\n",
    "DF.reset().unique().default()\n",
    "df = DF.legit().frame().sort_values(by='Y')[['dn', 'Y']]\n",
    "df['domain'] = df['dn'].apply(Transformer.domain)\n",
    "df.value_counts(subset='domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF_s[('DOMAIN', 'ANY')]\n",
    "\n",
    "DF.reset().unique().default()\n",
    "df = DF.legit().frame().sort_values(by='Y')[['dn', 'Y']]\n",
    "df['domain'] = df['dn'].apply(lambda x: len(Transformer.domain(x)))\n",
    "df.sort_values(by=['domain', 'Y']).tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in best_unique_keys_sorted:\n",
    "    DF_s[k].reset().unique().default()\n",
    "    df = DF_s[k].frame().sort_values(by='Y')[['dn', 'Y']].reset_index().drop(columns='index')\n",
    "    i = df[df['Y'].gt(0.1)].index[0]\n",
    "    print(k)\n",
    "    print(df.iloc[i-10:i+10].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.99999\n",
    "print('Number of dn having prob greather than %0.2f' % th)\n",
    "for k in best_unique_keys_sorted:\n",
    "    DF_s[k].reset().unique().default()\n",
    "    df = DF_s[k].frame().sort_values(by='Y')[['dn', 'X', 'Y']].reset_index().drop(columns='index')\n",
    "    i = df[df['Y'].gt(th)].shape[0]\n",
    "    print(k, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in best_unique_keys_sorted:\n",
    "    DF_s[k].reset().unique().default()\n",
    "    df = DF_s[k].frame().sort_values(by='Y')[['dn', 'Y']].reset_index().drop(columns='index')\n",
    "    df.to_csv('/tmp/%s_%s.csv' % (k[0], k[1]))\n",
    "    print(k,'\\n', df[df['Y'].gt(0.99)].head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondo me il NOSFX e\\` meno probabile che dia falsi negativi, lo vedo molto sicuro sul riconoscere questo tipo di DGA. E` molto meno affidabile per i falsi positivi, dove primeggia DOMAIN/ANY.\n",
    "\n",
    "NOSFX/NOSFX -> no falsi negativi\n",
    "DOMAIN/ANY  -> no falsi positivi\n",
    "\n",
    "parametro sicurezza, ovvero quanto e\\` deciso nei giudizi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k in DF_s:\n",
    "    if k[1] in ['NOSFX_1-30', 'ANY']:\n",
    "        DF_s[k].reset().unique().default()\n",
    "        print(k)\n",
    "        print(DF_s[k].legit().frame().sort_values(by='Y', ascending=False)[['dn', 'Y']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_s[k].legit().frame().sort_values(by='Y', ascending=False)[['dn', 'Y']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuratezza e prestazioni\n",
    "Il parametro di accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rapporto del numero di input unici di ogni trasformazione rispetto al totale\n",
    "\n",
    "\n",
    "A seconda della trasformazione la predizione effettuera\\` la predizione su un numero diverso di dn, ovvero da uno stesso capture ottero\\` due diversi\n",
    "set di input i quali avranno grandezza probabilmente molto diverse.\n",
    "Ad esempio il numero di input *DOMAIN/\\** e\\` minore di **1762** rispetto al numero di DN della capture (totale pari a 2474), ovvero lo **28.78%**.\n",
    "Le trasformazioni NOSFX\\* hanno un numero di input praticamente uguale a quello totale.\n",
    "Per quanto riguarda LAST invece, esso e\\` un monolivello eppure essendo molto piu\\` variabile l'ultimo livello rispetto al primo, ha un numero di input molto maggiore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "dn = list(DF_s.values())[0].reset().unique_dn().frame().shape[0]\n",
    "for tr in trs:\n",
    "    DF = DF_s[(tr.name, 'LAST')]\n",
    "    X = DF.reset().unique().frame().shape[0]\n",
    "    tr_rows[tr.name] = pd.Series([dn, X, dn - X, X/dn*100])\n",
    "\n",
    "df = pd.DataFrame(tr_rows).T\n",
    "df.columns =['DN', 'X', 'DN-X', 'X/dn']\n",
    "df.convert_dtypes()\\\n",
    ".style\\\n",
    ".highlight_max(subset=[('DN-X')], color='gray')\\\n",
    ".highlight_min(subset=[('X/dn')], color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuzione dei dn multilivello\n",
    "\n",
    "Dalla seguente tabella si evince come **considerando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "unique_row = list(DF_s.values())[0].reset().unique_dn().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "unique_row.loc['tot'] = unique_row.sum()\n",
    "tr_rows['ANY'] = pd.concat([unique_row, unique_row.rsub(unique_row), unique_row.div(unique_row).mul(100)], axis=0, keys=['unique dn', 'unique dn-unique X', '%'])\n",
    "for tr in trs:\n",
    "    dn_cols = DF_s[(tr.name, 'LAST')].reset().unique().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dn_cols.loc['tot'] = dn_cols.sum()\n",
    "    diff_cols = dn_cols.rsub(unique_row)\n",
    "    norm_cols = dn_cols.div(unique_row).mul(100)\n",
    "    tr_rows[tr.name] = pd.concat([dn_cols, diff_cols, norm_cols], axis=0, keys=['unique dn', 'unique dn-unique X', '%'])\n",
    "\n",
    "pd.DataFrame(tr_rows).T\\\n",
    ".sort_values(by=('unique dn-unique X', 'tot'))\\\n",
    ".style\\\n",
    ".format({(d, l): \"{:,.0f}\" for d in ['unique dn', 'unique dn-unique X'] for l in ['1','2','>2', 'tot']})\\\n",
    ".format({('%', l): \"{:,.2f}\" for l in ['1','2','>2', 'tot']})\\\n",
    ".highlight_max(subset=[('unique dn-unique X',l) for l in ['1','2','>2']], color='gray')\\\n",
    ".set_caption('Unique dn for each different transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuratezza rispetto al totale\n",
    "La seguente tabella mostra la percentuale di errore commesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "for k in DF_s:\n",
    "    legit = DF_s[k].reset().legit().frame().shape[0]\n",
    "    dga = DF_s[k].reset().dga().frame().shape[0]\n",
    "    tr_rows[k] = pd.Series([legit, dga, legit + dga, dga/(legit + dga)])\n",
    "#                            keys=[('legit', 'dn'), ('legit', 'X'),\\\n",
    "#                                  ('dga', 'dn'), ('dga', 'X'), \\\n",
    "#                                  ('tot', 'X')])\n",
    "\n",
    "df = pd.DataFrame(tr_rows).T\n",
    "df.columns = ['legit', 'dga', 'tot', 'error=dga/tot']\n",
    "df.sort_values(by=['error=dga/tot']).convert_dtypes()\\\n",
    ".style\\\n",
    ".set_caption('Error relative to inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I nomi di dominio duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "DF = list(DF_s.values())[0]\n",
    "dn = DF.reset().frame().shape[0]#.value_counts(subset='level_dn')\n",
    "dn_u = DF.reset().unique().frame().shape[0]#.value_counts(subset='level_dn')\n",
    "print(f'Nomi di dominio: {dn}')\n",
    "print(f'Nomi di dominio unici: {dn_u}')\n",
    "print(f'Nomi di dominio unici/tot: {dn_u/dn:,.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si puo\\` notare come il numero di nomi di dominio si riduca drasticamente se considerassimo solamente i nomi-di-dominio unici.<br>\n",
    "La seguente tabella mostra i nomi-di-dominio piu\\` frequenti. Essi appartengono principalmente a servizi Amazon, Google e Facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(DF_s.values())[0].reset().frame().value_counts(subset='dn').rename('num').head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomi di dominio duplicati predetti erroneamente piu\\` frequenti\n",
    "Qui di seguito vengono mostrati i 10 nomi di dominio piu\\` frequenti predetti erroneamente come DGA per le predizioni *NOSFX/NOSFX_1-30* e *DOMAIN/LAST*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "DF = list(DF_s.values())[0]\n",
    "df1 = DF_s[('NOSFX', 'NOSFX_1-30')].reset().dga().frame()['dn'].value_counts().head(n).reset_index()\n",
    "df2 = DF_s[('DOMAIN', 'LAST')].reset().dga().frame()['dn'].value_counts().head(n).reset_index()\n",
    "df1.columns = ['domain name', 'num']\n",
    "df2.columns = ['domain name', 'num']\n",
    "pd.concat([df1,df2], axis=1, keys=['NOSFX/NOSFX_1-30', 'DOMAIN/LAST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E\\` un probelma non da poco che la rete neurale *NOSFX_1-30* non riconosca i nomi-di-dominio di cloudfront come domini benigni. Questo e\\` un problema dovuto principalmente alla label di livello maggiore, la quale e\\` decisamente una stringa generata automaticamente e per questo tali nomi-di-dominio vengono predetti come DGA.\n",
    "\n",
    "Per vedere se questo sia vero, vediamo quali nomi-di-dominio invece la rete *NOSFX_1-30* sia in grado di predire correttamente, anche se posseggono label automaticamente generate.\n",
    "\n",
    "Si noti come funziona estremamente meglio la rete NOSFX, in quanto i DGA sbagliati sono stringhe molto complesse.\n",
    "Inoltre si noti come i domini \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dga = DF_s[('NOSFX', 'NOSFX_1-30')].reset().unique().dga().frame()\n",
    "dga_cloudfront = dga[dga['X'].str.find('cloudfront') > -1]\n",
    "dga_non_cloudfront = dga[dga['X'].str.find('cloudfront') == -1]\n",
    "print('dga_cloudfront', dga_cloudfront.shape)\n",
    "print('dga_non_cloudfront', dga_non_cloudfront.shape)\n",
    "dga_non_cloudfront['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dga = DF_s[('DOMAIN', 'LAST')].reset().unique().dga().frame()\n",
    "dga_cloudfront = dga[dga['X'].str.find('cloudfront') > -1]\n",
    "dga_non_cloudfront = dga[dga['X'].str.find('cloudfront') == -1]\n",
    "print('dga_cloudfront', dga_cloudfront.shape)\n",
    "print('dga_non_cloudfront', dga_non_cloudfront.shape)\n",
    "dga_non_cloudfront['dn'].apply(lambda x: Transformer.domain(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "dga_tot_1 = DF_s[('DOMAIN', 'LAST')].reset().frame()\n",
    "dga_tot_2 = DF_s[('NOSFX', 'NOSFX_1-30')].reset().frame()\n",
    "dga_1 = DF_s[('DOMAIN', 'LAST')].reset().unique().dga().frame()\n",
    "dga_2 = DF_s[('NOSFX', 'NOSFX_1-30')].reset().unique().dga().frame()\n",
    "print(dga_tot_1.iloc[dga_2.index][['X','Y']].drop_duplicates().to_markdown())\n",
    "print(dga_tot_2.iloc[dga_1.index][['X','Y']].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provato che funziona molto meglio NOSFX del LAST in quanto gli errori del NOSFX sono attribuibili spesso a input molto complessi mentre si comporta egregiamente con i dn predetti erroneamente da LAST, inolte mostrando un livello di decisione maggiore.\n",
    "\n",
    "Combinando i due otterremmo quasi 0 dga predetti erroneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = DF_s[('NOSFX', 'NOSFX_1-30')].reset().unique().legit().frame()\n",
    "legit = legit[legit['X'].str.find('cloudfront') >= 0]\n",
    "dga = DF_s[('NOSFX', 'NOSFX_1-30')].reset().unique().dga().frame()\n",
    "dga = dga[dga['X'].str.find('cloudfront') >= 0]\n",
    "print('legit', legit.shape)\n",
    "print('dga', dga.shape)\n",
    "\n",
    "pd.concat([legit.sort_values(by='Y', ascending=True).reset_index()[['X','Y']],\n",
    "dga.sort_values(by='Y', ascending=False).reset_index()[['X','Y']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "for k in DF_s:\n",
    "    legit = DF_s[k].reset().unique().legit().frame().shape[0]\n",
    "    legit_dn = DF_s[k].reset().unique_dn().legit().frame().shape[0]\n",
    "    dga = DF_s[k].reset().unique().dga().frame().shape[0]\n",
    "    dga_dn = DF_s[k].reset().unique_dn().dga().frame().shape[0]\n",
    "    tr_rows[k] = pd.Series([legit, dga, legit + dga, dga/(legit + dga)])\n",
    "#                            keys=[('legit', 'dn'), ('legit', 'X'),\\\n",
    "#                                  ('dga', 'dn'), ('dga', 'X'), \\\n",
    "#                                  ('tot', 'X')])\n",
    "\n",
    "df = pd.DataFrame(tr_rows).T\n",
    "df.columns = ['legit', 'dga', 'tot', 'error=dga/tot']\n",
    "df.sort_values(by=['error=dga/tot']).convert_dtypes()\\\n",
    ".style\\\n",
    ".set_caption('Error relative to unique inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "for k in DF_s:\n",
    "    legit_cols = DF_s[k].reset().unique().legit().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    legit_dn_cols = DF_s[k].reset().unique_dn().legit().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    legit_cols.loc['tot'] = legit_cols.sum()\n",
    "    legit_dn_cols.loc['tot'] = legit_dn_cols.sum()\n",
    "    dga_cols = DF_s[k].reset().unique().dga().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dga_dn_cols = DF_s[k].reset().unique_dn().dga().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dga_cols.loc['tot'] = dga_cols.sum()\n",
    "    dga_dn_cols.loc['tot'] = dga_dn_cols.sum()\n",
    "    tr_rows[k] = pd.concat([\\\n",
    "                            legit_dn_cols, legit_cols,\\\n",
    "                            dga_dn_cols, dga_cols,\\\n",
    "                            legit_cols.add(dga_cols)], axis=0,\\\n",
    "                           keys=[('legit', 'dn'), ('legit', 'X'),\\\n",
    "                                 ('dga', 'dn'), ('dga', 'X'), \\\n",
    "                                 ('tot', 'X')])\n",
    "\n",
    "pd.DataFrame(tr_rows).T\\\n",
    ".style.set_caption('legit and dga X and DN')\\\n",
    ".highlight_min(subset=[('tot','X','tot')] + [(l,x,'tot') for l in ['legit', 'dga'] for x in ['dn','X']], color='gray')#\\\n",
    "# .sort_values(by=('unique dn-unique X', 'tot'))\\\n",
    "# .style\\\n",
    "# .format({(d, l): \"{:,.0f}\" for d in ['unique dn', 'unique dn-unique X'] for l in ['1','2','>2', 'tot']})\\\n",
    "# .format({('%', l): \"{:,.2f}\" for l in ['1','2','>2', 'tot']})\\\n",
    "# .set_caption('Unique dn for each different transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "for k in DF_s:\n",
    "    legit_cols = DF_s[k].reset().unique().legit().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    legit_dn_cols = DF_s[k].reset().unique_dn().legit().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    legit_cols.loc['tot'] = legit_cols.sum()\n",
    "    legit_dn_cols.loc['tot'] = legit_dn_cols.sum()\n",
    "    dga_cols = DF_s[k].reset().unique().dga().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dga_dn_cols = DF_s[k].reset().unique_dn().dga().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dga_cols.loc['tot'] = dga_cols.sum()\n",
    "    dga_dn_cols.loc['tot'] = dga_dn_cols.sum()\n",
    "    tr_rows[k] = pd.concat([legit_dn_cols, dga_dn_cols, legit_cols, dga_cols], axis=0, keys=[('dn', 'legit'), ('dn', 'dga'), ('X', 'legit'), ('X', 'dga')])\n",
    "\n",
    "pd.DataFrame(tr_rows).T\\\n",
    ".style.set_caption('legit and dga X and DN')#\\\n",
    "# .sort_values(by=('unique dn-unique X', 'tot'))\\\n",
    "# .style\\\n",
    "# .format({(d, l): \"{:,.0f}\" for d in ['unique dn', 'unique dn-unique X'] for l in ['1','2','>2', 'tot']})\\\n",
    "# .format({('%', l): \"{:,.2f}\" for l in ['1','2','>2', 'tot']})\\\n",
    "# .set_caption('Unique dn for each different transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "tr_rows = {}\n",
    "\n",
    "unique_row = list(DF_s.values())[0].reset().unique_dn().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "unique_row.loc['tot'] = unique_row.sum()\n",
    "\n",
    "for k in DF_s:\n",
    "    legit_cols = DF_s[k].reset().unique().legit().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    legit_cols.loc['tot'] = legit_cols.sum()\n",
    "    dga_cols = DF_s[k].reset().unique().dga().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    dga_cols.loc['tot'] = dga_cols.sum()\n",
    "    tot_cols = dga_cols.add(legit_cols)\n",
    "    tr_rows[k] = pd.concat([legit_cols, dga_cols, dga_cols.div(tot_cols), tot_cols], axis=0, keys=['legit', 'dga', 'error=dga/tot', 'tot'])\n",
    "\n",
    "pd.DataFrame(tr_rows).T.sort_values(('error=dga/tot', 'tot')).convert_dtypes()#\\\n",
    "# .sort_values(by=('unique dn-unique X', 'tot'))\\\n",
    "# .style\\\n",
    "# .format({(d, l): \"{:,.0f}\" for d in ['unique dn', 'unique dn-unique X'] for l in ['1','2','>2', 'tot']})\\\n",
    "# .format({('%', l): \"{:,.2f}\" for l in ['1','2','>2', 'tot']})\\\n",
    "# .set_caption('Unique dn for each different transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "unique_level_count = {}\n",
    "unique_dn_level_count = None\n",
    "#b_index = [l for l in ['1', '2', '>2']]\n",
    "for kk in DF_s:\n",
    "    k = kk[0]\n",
    "    if ('diff', k) in unique_level_count: continue\n",
    "    if unique_dn_level_count is None:\n",
    "        unique_dn_level_count = DF_s[kk].reset().unique_dn().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "        unique_level_count[('unique', 'unique DNs')] = unique_dn_level_count\n",
    "        unique_dn_level_count.loc['tot'] = unique_dn_level_count.sum()\n",
    "    tmp = DF_s[kk].reset().unique().frame().value_counts(subset='level_dn', sort=False, normalize=False)\n",
    "    tmp.loc['tot'] = tmp.sum()\n",
    "    unique_level_count[('diff', k)] = tmp.rsub(unique_dn_level_count)\n",
    "    unique_level_count[('unique_dn', k)] = unique_dn_level_count\n",
    "\n",
    "pd.DataFrame(unique_level_count).T.sort_values(by='tot').\\\n",
    "    style.set_caption(\"Difference between unique dns and unique inputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "df_dga_level_count = pd.DataFrame()\n",
    "for k in DF_s:\n",
    "    df_dga_level_count[k] = DF_s[k].unique().dga().frame().value_counts(subset=['level_dn'], sort=False, normalize=True).T()\n",
    "df_dga_leveldn_count['tot'] = df_dga_leveldn_count.sum(axis=1)\n",
    "\n",
    "for k in DF_s:\n",
    "    df_dga_leveldn_count_norm[k] = df_dga_leveldn_count[c].div(df_dga_leveldn_count[('tot',)]).mul(100)\n",
    "\n",
    "#df_dga_leveldn_count = pd.DataFrame(dga_leveldn_count).T\n",
    "\n",
    "#df_dga_leveldn_count.sort_values(by=[('tot',)], axis=0)\n",
    "\n",
    "df_dga_leveldn_count = pd.DataFrame(dga_leveldn_count).T\n",
    "df_dga_leveldn_count['tot'] = df_dga_leveldn_count.sum(axis=1)\n",
    "df_dga_leveldn_count_norm = df_dga_leveldn_count.sort_values(by=[('tot',)], axis=0).copy()\n",
    "for c in df_dga_leveldn_count.columns:\n",
    "    if c != ('tot',):\n",
    "        df_dga_leveldn_count_norm[c[0] + '%'] = df_dga_leveldn_count[c].div(df_dga_leveldn_count[('tot',)]).mul(100)\n",
    "df_dga_leveldn_count_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DGA per nomi di dominio completi unici\n",
    "Dalla tabella seguente si può notare come "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "dga_level_count = {}\n",
    "for k in DF_s:\n",
    "    dga_level_count[k] = DF_s[k].reset().unique_dn().dga().frame().value_counts(subset=['level_dn'], sort=False, normalize=False).T\n",
    "df_dga_level_count = pd.DataFrame(dga_level_count).T\n",
    "df_dga_level_count.columns = df_dga_level_count.columns.get_level_values(0)\n",
    "series_tot = df_dga_level_count.sum(axis=1).rename('tot')\n",
    "for c in df_dga_level_count.columns:\n",
    "        df_dga_level_count['% ' + c] = df_dga_level_count[c].div(series_tot).mul(100)\n",
    "pd.concat([df_dga_level_count, series_tot], axis=1).sort_values(by=['tot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "legit_level_count = {}\n",
    "for k in DF_s:\n",
    "    legit_level_count[k] = DF_s[k].reset().unique().legit().frame().value_counts(subset=['level_dn'], sort=False, normalize=False).T\n",
    "df_legit_level_count = pd.DataFrame(legit_level_count).T\n",
    "df_legit_level_count.columns = df_legit_level_count.columns.get_level_values(0)\n",
    "series_tot = df_legit_level_count.sum(axis=1).rename('tot')\n",
    "for c in df_legit_level_count.columns:\n",
    "        df_legit_level_count['% ' + c] = df_legit_level_count[c].div(series_tot).mul(100)\n",
    "pd.concat([df_legit_level_count, series_tot], axis=1).sort_values(by=['tot'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabella mostra il numero di dga predetti, in numeri assoluti e relativi. \n",
    "\n",
    "**TL,DR;**\n",
    "- Si noti che la predizione su DOMAIN/* e LAST/* non dipende dal numero di subdomains, quelli qui indicati si riferiscono ai dn, non all'input.\n",
    "- I risultati migliori si ottengono nel caso in cui prelevo solo il DOMAIN. (ovvero la situazione più simile al dataset)\n",
    "- Il numero di errori di NOSFX/NOSFX rispetto a DOMAIN/NOSFX è pari a 111/36 ~ 3.\n",
    "- Il numero di errori di NOSFX/NOSFX rispetto a NOSFX_NP/NOSFX è pari a 640/11 ~ 5.8.\n",
    "- Il numero di errori di NOSFX/NOSFX rispetto a NOSFX/NOSFX_NP è pari a 640/11 ~ 5.8.\n",
    "- Il modello NOSDFX_NOPUNCT non funziona mai meglio degli altri, ha un comportamento simile, ma sempre peggiore, agli altri solo in DOMAIN/NOSFX_NP e LAST/NOSFX_NP\n",
    "- Il modello NOSFX* mostra risultati migliori se considero un solo livello come in DOMAIN e LAST, però funziona meglio degli altri con trasformazioni multi-livello. Questo indica che è possibile **ottenere buoni risultati considerando più livelli**.\n",
    "- Anche quei modelli allenati (NOSFX*)su più livelli ottengono risultati migliori se considero un solo livello\n",
    "#### 1) Quali differenze ci sono tra i dga sbagliati per DOMAIN/*?\n",
    "#### 2) Quanti di quelli *sbagliati* possono trarre vantaggio dal livelli >1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeri di livelli nel dataset di training\n",
    "Le prossime celle cercano se vi è una correlazione tra l'incapacità di predire nomi di dominio multilivello ad una mancaza di questi nel dataset di training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IO import DF as DFClass\n",
    "Y = [0.0 if l == 'legit' else 1.0 for l in training.label.to_numpy()]\n",
    "training_DF = DFClass(training.dn, training.dn, Y)\n",
    "df_total = training_DF.frame()\n",
    "df_dga = training_DF.dga().frame()\n",
    "df_legit = training_DF.legit().frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_training_levels = pd.DataFrame()\n",
    "df_training_levels['total'] = df_total.value_counts(subset=['level_dn'], sort=False, normalize=False).convert_dtypes()\n",
    "df_training_levels['legit'] = df_legit.value_counts(subset=['level_dn'], sort=False, normalize=False).convert_dtypes()\n",
    "df_training_levels['dga'] = df_dga.value_counts(subset=['level_dn'], sort=False, normalize=False).convert_dtypes()\n",
    "df_norm_training_levels = pd.DataFrame()\n",
    "df_norm_training_levels['total'] = df_total.value_counts(subset=['level_dn'], sort=False, normalize=True).convert_dtypes()\n",
    "df_norm_training_levels['legit'] = df_legit.value_counts(subset=['level_dn'], sort=False, normalize=True).convert_dtypes()\n",
    "df_norm_training_levels['dga'] = df_dga.value_counts(subset=['level_dn'], sort=False, normalize=True).convert_dtypes()\n",
    "df_training_levels.T.fillna(0).join(df_norm_training_levels.T.fillna(0), rsuffix='%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può notare come il dataset di training sia per un 99% allenato con soli domini mono-livello dimostrando che è normale non ottenere risultati soddisfacenti per predizioni multilivello, ma dimostra anche come quei pochi nomi di dominio multilivello siano stati comunque utili durante l'allenamento del modello NOSFX in quanto esso si comporta meglio degli altri in tali predizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {models[0].name: models[0], models[1].name: models[1], models[2].name: models[2]}\n",
    "b = {}\n",
    "values = []\n",
    "dff = pd.DataFrame(columns=['model','X','Y'])\n",
    "for k in dga_df:\n",
    "    if k[2] == 'NOSFX_NOPUNCT_1-30': continue\n",
    "    if k[1] == 'DOMAIN':\n",
    "        df = dga_df[k]\n",
    "        df = df[df['level_dn'] == '2'].copy()\n",
    "        dff = dff.append(pd.DataFrame({'model': [k[2]]*df.shape[0],'X': df['X'], 'Y': df['Y']}))\n",
    "        #TODO: affianca il secondo livello per capire se può essere utile\n",
    "        continue\n",
    "print(dff.sort_index().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quanti di quelli *sbagliati* possono trarre vantaggio dal livelli >1?\n",
    "Devo prendere i DN dei DGA sbagliati, e predirli con ogni modello come fossero un semplice DOMAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {models[0].name: models[0], models[1].name: models[1], models[2].name: models[2]}\n",
    "b = {}\n",
    "for k in dga_df:\n",
    "    if k[1] == 'LAST':\n",
    "        continue #if LAST then the result'll be the same\n",
    "    df = dga_df[k]\n",
    "    df = df[df['level_dn'] == '2'].copy()\n",
    "    df['l2'] = df['dn'].apply(lambda x: x[0:x.find('.')])\n",
    "    df['Y-l2'],_ = models_dict[k[2]].predict(df['l2'].to_numpy())\n",
    "    b[k]= {'improvement': df[df['Y-l2'] < 0.5].shape[0]/df.shape[0]}\n",
    "pd.DataFrame(b).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato precedente ci fa capire che un analisi con più livelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ddl in dga_dn_levels:\n",
    "    if ddl[1] == 'DOMAIN':\n",
    "        print(ddl)\n",
    "        print(dga_dn_levels[ddl].loc[dga_dn_levels[ddl]['level'] == '1'], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può notare come la distribuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ddl in dga_dn_levels:\n",
    "    if ddl[1] == 'NOSFX':\n",
    "        print(ddl)\n",
    "        print(dga_dn_levels[ddl].loc[dga_dn_levels[ddl]['level'] == '2'].iloc[0:10], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Capture import training\n",
    "from IO import DF\n",
    "\n",
    "training_DF = DF(training.dn, np.zeros(training.dn.shape[0]), np.zeros(training.dn.shape[0]))\n",
    "\n",
    "print(training_DF.level_count_dn().to_frame().T)\n",
    "\n",
    "training_domain = training.readable\n",
    "training_domain['dn_domain'] = training_domain['dn'].apply(Transformer.domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_distribution(training, 'cloudfront')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_distribution(training, 'mozilla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_distribution(training, 'goo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarebbe bello (?) cercare di trovare una correlazione tra i domini sbagliati e quelli che non lo sono rispetto al dataset di training.\n",
    "Ovvero quante volte compare la stringa del d1 nel training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Output.predict(Input(normal['31'], Transformer.DOMAIN), Model.load(1), False)\n",
    "\n",
    "dn = o.DF.unique().with_dn().DF.index.get_level_values(1).to_numpy()\n",
    "Y = o.DF.unique().with_dn().DF['Y'].to_numpy()\n",
    "\n",
    "df = pd.DataFrame({'dn': pd.Series(dn).apply(Transformer.domain), 'Y': Y})\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "legit = df[df['Y'] < 0.5]\n",
    "legit_values=[]\n",
    "c=0\n",
    "for l in legit['dn']:\n",
    "    c+=1\n",
    "    if c % 20 == 0:\n",
    "        print(c)\n",
    "    _, lnum, dnum = string_similarity(training_domain, l)\n",
    "    legit_values.append([l, lnum, dnum])\n",
    "    \n",
    "pd.DataFrame(legit_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0    \n",
    "dga = df[df['Y'] > 0.5]\n",
    "dga_values=[]\n",
    "for l in dga['dn']:\n",
    "    _, lnum, dnum = string_similarity(training_domain, l)\n",
    "    dga_values.append([l, lnum, dnum])\n",
    "print(pd.DataFrame(dga_values).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = df[df['Y'] < 0.5]\n",
    "for l in legit['dn']:\n",
    "    _, lnum, dnum = string_distribution(training, l)\n",
    "    if lnum == 0:\n",
    "        print('%-40s %5d  %5d' % (l, lnum, dnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_similarity(training, 'google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
