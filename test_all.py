import json
import time
from datetime import datetime
from PyInquirer import prompt, Separator
import os, fnmatch
import itertools
from collections import OrderedDict
import numpy as np
import csv
import pandas as pd
from keras.models import model_from_json
from keras.preprocessing import sequence
from sklearn.metrics import precision_score, recall_score, classification_report, accuracy_score, f1_score
import joblib
from sklearn.metrics import confusion_matrix
import uuid

with open('databases/current/datasets.json') as fp_datasets:
    datasets = json.load(fp_datasets)

with open('databases/current/models.json') as fp_models:
    models = json.load(fp_models)

reports = {}
reports_by_model = {}
reports_by_dataset = {}

def evaluate(y_test, y_pred, f_report, time_elapsed, valid_class, flag_bin, model, dataset):
    target_names = list(valid_class.keys())

    y_test = np.array(y_test)
    y_test = y_test.ravel()

    class_report_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)

    class_report_dict["macro"] = {
        "precision": precision_score(y_test, y_pred, average="macro"),
        "f1-score": f1_score(y_test, y_pred, average="macro"),
        "recall": recall_score(y_test, y_pred, average="macro")
    }
    class_report_dict["micro"] = {
        "precision": precision_score(y_test, y_pred, average="micro"),
        "f1-score": f1_score(y_test, y_pred, average="micro"),
        "recall": recall_score(y_test, y_pred, average="micro")
    }

    c_matrix = np.ravel(confusion_matrix(y_test, y_pred).astype('float'))
    class_report_dict["confusion_matrix"] = np.ravel(c_matrix.astype('float'))
    class_report_dict["true_positive"] = np.sum(np.diag(c_matrix))

    if not model['_id'] in reports_by_model:
        reports_by_model[model['_id']] = []
    if not dataset['_id'] in reports_by_dataset:
        reports_by_dataset[dataset['_id']] = []

    class_report_dict['model_id'] = model['_id']
    class_report_dict['dataset_id'] = dataset['_id']
    class_report_dict['inputs_number'] = dataset['inputs_number']
    class_report_dict['inputs_number2'] = len(y_test)

    report_id = str(uuid.uuid4())
    reports[report_id] = class_report_dict
    reports_by_model[model['_id']].append(report_id)
    reports_by_dataset[dataset['_id']].append(report_id)

    return reports[report_id]


def get_data(dataset_path):
    """Read data from file (Traning, testing and validation) to process"""
    data = []
    with open(dataset_path, "r") as f:
        reader = csv.reader(f)
        for row in reader:
            data.append(row)
    return data

def find(pattern, path):
    print(path)
    for root, dirs, files in os.walk(path):
        for name in files:
            if fnmatch.fnmatch(name, pattern):
                return os.path.splitext(os.path.join(root, name))[0]
    raise Exception("Pattern <%s> not found in: %s" % (pattern, path))


class Model:
    def __init__(self, model_fetched):
        self.id = model_fetched[0]
        self.path = model_fetched[1]
        self.hash = model_fetched[2]
        self.date = model_fetched[3]
        self.epochs = model_fetched[4]
        self.folds = model_fetched[5]
        self.epoch = model_fetched[6]
        self.fold = model_fetched[7]
        self.instance = None

class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        print(f"current obj is {obj}")
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            print(f"{obj} is np.floating")
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, uuid.UUID):
            return str(obj)
        else:
            return super(NpEncoder, self).default(obj)

def load_model(model_path):
    with  open("%s.json" % model_path, 'r') as json_file:
        loaded_model_json = json_file.read()

    model = model_from_json(loaded_model_json)
    model.load_weights("%s.h5" % model_path)

    return model


def run(date):
    for model_id in models:
        model = models[model_id]
        model_ai = load_model(model['path'])
        dataset_num = 0
        models[model_id]['average'] = { 'benign': {}, 'malware': {} }
        for dataset_type in [ 'malware', 'benign' ]:
            for dataset_id in datasets[dataset_type]:
                dataset = datasets[dataset_type][dataset_id]
                d = datetime.fromtimestamp(model['date']).strftime('%Y%m%d-%H%M%S')
                print(f"testing model {d}/{model['epochs']}/{model['folds']}, version {model['fold']}/{model['epoch']} with dataset {dataset['name']} of length {dataset['inputs_number']}")
                
                indata = get_data(f"datasets/{dataset_type}_h_t/{dataset['name']}")
                binary_labels = [x[0] for x in indata]  # legit o dns
                X = [x[2] for x in indata]  # DNS
                # labels = [x[1] for x in indata]  # famiglia dga

                valid_chars = {x: idx + 1 for idx, x in enumerate(OrderedDict.fromkeys(''.join(X)))}
                maxlen = np.max([len(x) for x in X])

                X_test = [[valid_chars[y] for y in x] for x in X]
                X_test = sequence.pad_sequences(X_test, maxlen=maxlen)

                y_binary = np.array([0 if x == 'legit' else 1 for x in binary_labels])

                time_elapsed = time.time()
                y_pred = model_ai.predict(X_test)
                time_elapsed = time.time() - time_elapsed

                y_bin_result = [0 if (x <= 0.5) else 1 for x in y_pred]

                with open("%s.txt" % model['path'], 'w') as f_report:
                    report = evaluate(y_binary, y_bin_result, f_report, time_elapsed, {'white': 0, 'black': 1}, True, model, dataset)
                sum(models[model_id], report, dataset_type)
                dataset_num = dataset_num + 1
            avg(models[model_id], dataset_num, dataset_type)

    with open("databases/current/models.json", "w") as fp_datasets:
        json.dump(models, fp_datasets, cls=NpEncoder)

    with open('databases/current/reports.json', 'w') as fp_reports:
        json.dump(reports, fp_reports, cls=NpEncoder)
    with open('databases/current/reports_by_dataset.json', 'w') as fp_reports:
        json.dump(reports_by_dataset, fp_reports, cls=NpEncoder)
    with open('databases/current/reports_by_model.json', 'w') as fp_reports:
        json.dump(reports_by_model, fp_reports, cls=NpEncoder)

def sum(model, report, dataset_type):
    for measure_class in ['white', 'black', 'micro', 'macro', 'macro avg', 'weighted avg']:
        if not measure_class in model['average'][dataset_type]:
            model['average'][dataset_type][measure_class] = {}
        for measure_name in report[measure_class]:
            if not measure_name in model['average'][dataset_type][measure_class]:
                model['average'][dataset_type][measure_class][measure_name] = 0
            model['average'][dataset_type][measure_class][measure_name] = model['average'][dataset_type][measure_class][measure_name] + report[measure_class][measure_name]

def avg(model, n, dataset_type):
    for measure_class in ['white', 'black', 'micro', 'macro', 'macro avg', 'weighted avg']:
        for measure_name in model['average'][dataset_type][measure_class]:
            model['average'][dataset_type][measure_class][measure_name] = model['average'][dataset_type][measure_class][measure_name]/n

date = datetime.now()
if __name__ == "__main__":
    run(date)