import shutil
import copy
import json
import time
from datetime import datetime
from PyInquirer import prompt, Separator
import os, fnmatch
import itertools
from collections import OrderedDict
import csv
from pymongo import MongoClient
import hashlib
import re
import pprint
import uuid
import psycopg2

from Model import Model
from Report import Report
from Dataset import Dataset

connection = psycopg2.connect(user = "postgres",
                                  password = "porcodio",
                                  host = "127.0.0.1",
                                  port = "5432",
                                  database = "malware")

cursor = connection.cursor()

class JSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return int(obj.timestamp())
        if isinstance(obj, uuid.UUID):
            return str(obj)
        else:
            return super(JSONEncoder, self).default(obj)


def file_hash(path):
    sha256_hash = hashlib.sha256()
    with open(path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def model_hash(path):
    sha256_hash = hashlib.sha256()
    with open(f"{path}.json", "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    with open(f"{path}.h5", "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def pretty(d, indent=0):
   for key, value in d.items():
      print('\t' * indent + str(key))
      if isinstance(value, dict):
         pretty(value, indent+1)
      else:
         print('\t' * (indent+1) + str(value))

def save():
    for type_ in ['malware', 'benign']:
        type_files = os.listdir(f"datasets/{type_}_h_t")
        for dataset in type_files:
            with open(f"datasets/{type_}_h_t/{dataset}", "r") as fp:
                reader = csv.reader(fp)
                row_counter = 0
                white_number = 0
                black_number = 0
                for row in reader:
                    if row[0] == 'legit': white_number=white_number+1
                    else: black_number=black_number+1
                    row_counter = row_counter + 1
                if (white_number+black_number) != row_counter: raise Exception("diocaneeeeeeeeee")

            m = re.search(r'(\d+)_(\d{4}-\d{2}-\d{2})_([\w\-]+)\.([\w\-]+).csv__h_t.csv', dataset)
            if m is None:
                print(f'Strange dir: {dataset}')
            else:
                hash_ = file_hash(f"datasets/{type_}_h_t/{dataset}")
                dataset__ = Dataset()
                dataset__.hash = hash_
                dataset__.name = dataset
                dataset__.type = type_
                dataset__.date = datetime.strptime(m.group(2), "%Y-%m-%d").date()
                dataset__.inputs_number = row_counter
                dataset__.inputs_numbers = [ white_number, black_number ]
                dataset__.labels = [ 'legit', 'dga' ]

                try:
                    dataset__.save(connection)
                except psycopg2.errors.UniqueViolation:
                    print('Dataset %s already inserted.' % dataset)
                    connection.rollback()

    for dir_ in  os.listdir("models/"):
        m = re.search(r'(\d{8}_\d{6})__epochs_(\d+)_folds_(\d+)', dir_)
        if m is not None:
            model = Model()
            model.datetime = datetime.strptime(m.group(1), "%Y%m%d_%H%M%S")
            model.epochs = m.group(2)
            model.folds = m.group(3)

            for model_fold_epoch in os.listdir(f"models/{dir_}"):
                if model_fold_epoch[-4:] != "json": continue
                m = re.search(r'(\w+)_model_fold_(\d+)_epoch_(\d+)\.json', model_fold_epoch)
                if m is not None:
                    model_ = copy.copy(model)
                    model_.hash = model_hash(f"models/{dir_}/{model_fold_epoch}"[:-5])
                    model_.path = f"models/{dir_}/{model_fold_epoch}"[:-5]
                    model_.fold = m.group(2)
                    model_.epoch = m.group(3)
                    try:
                        model_.save(connection)
                    except psycopg2.errors.UniqueViolation:
                        print('Model %s already inserted.' % model_fold_epoch)
                        connection.rollback()

def test():
    cursor = connection.cursor()
    cursor.execute("""SELECT id FROM public.models""")
    models = [ Model.fetch(connection, x[0]) for x in cursor.fetchall() ]

    cursor = connection.cursor()
    cursor.execute("""SELECT id FROM public.datasets""")
    datasets = [ Dataset.fetch(connection, x[0]) for x in cursor.fetchall() ]

    for model in models:
        for dataset in datasets:
            report = Report()
            report.model = model
            report.dataset = dataset
            model.test(dataset, report)

            print(report)
    
    pass

if __name__ == "__main__":
    save()
    test()
    connection.close()
