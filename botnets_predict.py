from Model import Model
import pandas as pd
from DomainLevel import Transformer
import os, math

df_10m = pd.read_csv('/media/princio/ssd512/top_10m.dsfx.csv').set_index('dsfx')
REQ_ROOT_DIR='/media/princio/ssd512/req.dns.list/'


def path(type_, filename):
    if type_ == 'req':
        return os.path.join('/media/princio/ssd512/req.y.csv/', filename[:-9] + '.req.y.csv')
    if type_ == 'unique':
        return os.path.join('/media/princio/ssd512/unique.req.y.csv/', filename[:-9] + '.unique.req.y.csv')

def to_uniques(df):
    counts = df.value_counts().rename('counts').to_frame().reset_index()
    df = df.drop_duplicates()
    counts.insert(0, 'num', df.index)
    return counts

def legit_top10m(df):
    if 'dsfx' not in df.columns:
        df['dsfx'] = df['DN'].apply(Transformer.domain_sfx)

    bibo = df.set_index('dsfx').join(df_10m)
    bibo['rank'] = bibo['rank'].fillna(-1).apply(lambda x: 0 if x<0 else 1)
    bibo = bibo.rename(columns={'rank': 'dsfx_legit'})
    bibo = bibo.reset_index()[['DN', 'dsfx', 'dsfx_legit', 'last', 'nosfx']]
    #bibo.to_csv(os.path.join(YREQ_ROOT_DIR, filename), index=False)
    return bibo


models = [ Model.load('last'), Model.load('nosfx')]

files = []
for walker in os.walk(REQ_ROOT_DIR):
    for filename in walker[2]:
        try:
            files.append(filename)
        except pd.errors.EmptyDataError:
            print(f'File <{filename}> is empty.')


errors = []
for num, filename in enumerate(files):
    df = pd.read_csv(os.path.join(REQ_ROOT_DIR, filename), names=['DN'])

    if df.shape[0] == 0:
        print('%5d/%d %s--EMPTY' % (num, len(files), filename))
        continue

    try:
        print('%5d/%d %50s%20d' % (num, len(files), filename, df.shape[0]))

        print('predict...')
        for model in models:
            series_DN = df['DN'].apply(model.tr.translator())
            df[model.name], _ = model.predict_u(series_DN)

        print('legit top10m...')
        df = legit_top10m(df)
        df.to_csv(path('req', filename), index=False)

        print('uniquing...')
        df_uniques = to_uniques(df)
        df_uniques.to_csv(path('unique', filename), index=False)

        print('done')
    except Exception as e:
        print(f'error with {filename}: {e}', e)
        errors.append(f'error with {filename}: {e}')

with open('/tmp/errors.txt', 'w') as fp:
    fp.writelines(errors)

print(errors)


#71/418 12_2013-10-17_capture-win10-from-2013-10-17-to-2013-10-18