from datetime import datetime
from sklearn.metrics import confusion_matrix
from Dataset import Dataset
from Model import Model
import numpy as np

class Report:
    def __init__(self, datetime_ = None):
        self.id = None
        self.model = None
        self.dataset = None
        self.datetime = datetime.now() if datetime_ is None else datetime_
        self.confusion_matrix = None
        self.labels = None
        self.precision = None
        self.recall = None
        self.f1_score = None
        self.supports = None

    @staticmethod
    def fetch(connection, id):
        cursor = connection.cursor()
        cursor.execute("""SELECT id, model_id, dataset_id, datetime, time_elapsed, confusion_matrix, labels
	                        FROM public.reports WHERE id=%s;""", (id, ))
                            
        fetched = list(cursor.fetchone())
        report = Report()
        report.id = fetched.pop(0)
        report.model = Model.fetch(connection, fetched.pop(0))
        report.dataset = Dataset.fetch(connection, fetched.pop(0))
        report.datetime = fetched.pop(0)
        report.time_elapsed = fetched.pop(0)
        report.confusion_matrix = fetched.pop(0)
        report.labels = fetched.pop(0)

        return report

    def save(self, connection):
        cursor = connection.cursor()
        cursor.execute("""INSERT INTO public.reports
                        (model_id, dataset_id, datetime, time_elapsed, confusion_matrix, labels)
                        VALUES ( ?, ?, ?, ?, ?, ?, ?);""",
                        (self.model.id, self.dataset.id, self.datetime, self.confusion_matrix, self.labels))
        connection.commit()

    def metrics(self):
        if self.confusion_matrix is None:
            return
        if self.labels is None:
            return
        
        tot = self.confusion_matrix.sum()
        tp_s = np.diag(self.confusion_matrix)
        tp_plus_fp_s = self.confusion_matrix.sum(axis=0)          
        supports = self.confusion_matrix.sum(axis=1)   

        precision = tp_s / tp_plus_fp_s
        recall = tp_s / supports
        f1_score = 2 * precision * recall / (precision + recall)

        accuracy = tp_s.sum() / tot

        macro_precision = np.average(precision)
        macro_recall = np.average(recall)
        macro_f1_score = np.average(f1_score)

        weighted_precision = np.average(precision, weights=supports)
        weighted_recall = np.average(recall, weights=supports)
        weighted_f1_score = np.average(f1_score, weights=supports)

        self.precision = [ precision, macro_precision, weighted_precision ]
        self.recall = [ recall, macro_recall, weighted_recall ]
        self.f1_score = [ f1_score, macro_f1_score, weighted_f1_score ]
        self.supports = supports
        self.accuracy = accuracy
        
        print("precision", self.precision)
        print("recall", self.recall)
        print("f1_score", self.f1_score)
        print("accuracy", self.accuracy)
        print("support", self.supports)

    def __str__(self):
        return ("model: %s\ndataset: %s\n[ %6d, %6d ]\n[ %6d, %6d ]\n" % (self.model, self.dataset, self.confusion_matrix[3], self.confusion_matrix[2], self.confusion_matrix[1], self.confusion_matrix[0]))