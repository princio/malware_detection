import subprocess
import os
import pandas as pd
from extractor import Extractor
import pickle
from model import Model

def sizeth(file):
    while True:
        if os.path.exists(file):
            print('Size', os.stat(file).st_size)
        time.sleep(5)
    
def pcap2csv(path):
    fields = [
        'frame.number',
        'frame.time_epoch',
        'ip.dst',
        'dns.time',
        'dns.response_in',
        'dns.response_to',
        'dns.qry.name',
        'dns.qry.type',
        'dns.flags.response',
        'dns.flags.rcode',
        'dns.resp.ttl',
        'dns.a'
    ]

    cmd_fields = []
    for f in fields:
        cmd_fields.append('-e')
        cmd_fields.append(f)

    with open(f'{pcap}.csv',"w") as outfile:
        subprocess.run(['tshark', '-r', pcap,
                        '-Y', 'dns && !_ws.malformed && !icmp',
                        '-T', 'fields'] + cmd_fields
                        , stdout=outfile)

    df = pd.read_csv(f'{pcap}.csv', sep='\t', names=fields)
            
    series = df['dns.flags.response'] == 0

    df_query = df[series]
    df_response = df[series == False]

    df_query = df_query.drop(columns=['dns.time', 'dns.flags.response', 'dns.response_to', 'dns.flags.rcode', 'dns.resp.ttl', 'dns.a' ])
    df_response = df_response.drop(columns=['ip.dst', 'dns.qry.name', 'dns.qry.type', 'dns.flags.response', 'dns.response_in' ])

    df = df_query.merge(df_response, how='left', left_on='frame.number', right_on='dns.response_to', suffixes=('_req', '_res'))

    columns = [
        'frame.number_req',
        'frame.number_res',
        'frame.time_epoch_req',
        'frame.time_epoch_res',
        'ip.dst',
        'dns.time',
        'dns.qry.name',
        'dns.qry.type',
        'dns.response_in',
        'dns.response_to',
        'dns.flags.rcode',
        'dns.resp.ttl',
        'dns.a'
    ]

    df = df[columns].rename(columns={'ip.dst': 'dns_server_ip'}).drop(columns=['dns.response_in', 'dns.response_to'])

    return df


if __name__ == '__main__':

    pcap = '/media/princio/ssd512/7_2013-08-20_capture-win1.pcap'

    models = [ Model.load('nosfx'), Model.load('domain') ]
    with open(os.path.join(os.path.dirname(__file__), 'top_10m.dsfx.pkl'), 'rb') as fp:
        df_10m_set = pickle.load(fp)

    def predict(df):
        for model in models:
            series, _ = model.predict_u(df['dns.qry.name'])
            df.insert(len(df.columns)-2, model.name, series)
        return df

    def legitness(df):
        series = df['dns.qry.name'].apply(lambda dn: 1 if Extractor.domain_sfx(dn) in df_10m_set else 0)
        df.insert(len(df.columns)-2, 'legit_list', series)
        return df

    print('Parsing pcap to csv....')
    df = pcap2csv(pcap)

    print('Legit list check....')
    df = legitness(df)

    print('Predicting....')
    df = predict(df)

    #df = df.fillna(-1).astype({'frame.number_req': int, 'frame.number_res': int, 'dns.flags.rcode': int})

    df.to_csv(f'{pcap}.dns.csv', index=False)

    exit(0)