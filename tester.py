from collections import OrderedDict
import numpy as np
import csv
import time
import pandas as pd
from keras.preprocessing import sequence
from sklearn.metrics import precision_score, recall_score, classification_report, accuracy_score, f1_score
import joblib
from sklearn.metrics import confusion_matrix
from datetime import datetime

from keras.models import model_from_json

dataset_path = "datasets/malware_h_t/25_2014-02-10_capture-win3.pcap_table.csv__h_t"
train_dataset_path = "datasets/setAtrain_h_t_domins"
trained_model_dir = "output/20200916_103144__epochs_1_folds_3"


def evaluate(y_test, y_pred, f_report, start, end, valid_class, flag_bin):
    # Take the dga's names
    # labels_names = list(dga_dict.keys())
    target_names = list(valid_class.keys())

    y_test = np.array(y_test)
    y_test = y_test.ravel()

    class_report = classification_report(y_test, y_pred, digits=4, target_names=target_names)

    # Macro and micro f1score, precision and recall all dataset
    score_macro = f1_score(y_test, y_pred, average="macro")
    precision_macro = precision_score(y_test, y_pred, average="macro")
    recall_macro = recall_score(y_test, y_pred, average="macro")
    score_micro = f1_score(y_test, y_pred, average="micro")
    precision_micro = precision_score(y_test, y_pred, average="micro")
    recall_micro = recall_score(y_test, y_pred, average="micro")
    matrix = []
    matrix.append([score_macro, score_micro])
    matrix.append([precision_macro, precision_micro])
    matrix.append([recall_macro, recall_micro])
    matrix = np.array(matrix)
    colonne = ["macro", "micro"]
    indici = ["f1_score", "precision", "recall"]
    df = pd.DataFrame(matrix, index=indici, columns=colonne)
    print("F1_score Precision Recall dataset \n")
    print(df)

    f_report.write("\n\nTesting (minutes)" + str((end - start) / float(60)) + '\n')

    accuracy = accuracy_score(y_test, y_pred)
    f_report.write("\nClass report: \n" + class_report)
    f_report.write("\nF1_score Precision Recall dataset \n" + str(df))
    f_report.write("\n\nOverall accuracy = " + str(accuracy) + '\n\n')
    f_report.write("\nAccuracy for each class:\n")

    # Accuracy for each class
    c_matrix = confusion_matrix(y_test, y_pred)
    cm_acc = c_matrix.astype('float') / c_matrix.sum(axis=1)[:, np.newaxis]
    accuracy_each_class = cm_acc.diagonal()

    # The following cicle is to format and print the accuracy
    count_name = 0
    print("\nAccuracy for each class:\n")
    for acc_cls in accuracy_each_class:
        print('{:>14} {:1}\n'.format(target_names[count_name], round(acc_cls, 3)))
        f_report.write('{:>14} {:1}\n'.format(target_names[count_name], round(acc_cls, 3)))
        count_name += 1

    f_report.write("\n \n")

    print(class_report)

    TP = np.diag(c_matrix)
    TP = np.sum(TP)
    TotalElement = np.asmatrix(c_matrix)
    TotalElement = np.sum(TotalElement)
    f_report.write("\nTrue positive: " + str(TP) + "\n")
    print("\nTrue positive: " + str(TP) + "\n")
    f_report.write("\n \n")

    f_total_report = open("reports/total_report.csv", 'a+')
    if flag_bin == True:
        report_row = "binary" + ";" + dataset_path + ".csv" + ";" + '%.5f' % (precision_micro) + ";" + '%.5f' % (
            precision_macro) + ";" + '%.5f' % (recall_micro) + ";" + '%.5f' % (recall_macro) + ";" + '%.5f' % (
                         score_micro) + ";" + '%.5f' % (score_macro) + ";" + '%.5f' % (accuracy) + ";" + str(
            TP) + ";" + str(TotalElement) + "\n"
    else:
        report_row = "multi" + ";" + dataset_path + ".csv" + ";" + '%.5f' % (precision_micro) + ";" + '%.5f' % (
            precision_macro) + ";" + '%.5f' % (recall_micro) + ";" + '%.5f' % (recall_macro) + ";" + '%.5f' % (
                         score_micro) + ";" + '%.5f' % (score_macro) + ";" + '%.5f' % (accuracy) + ";" + str(
            TP) + ";" + str(TotalElement) + "\n"
    f_total_report.write(report_row)
    print("\nRisultati scritti correttamente nel report.\n")
    f_total_report.close()


def get_data(dataset_path):
    """Read data from file (Traning, testing and validation) to process"""
    data = []
    with open(dataset_path + ".csv", "r") as f:
        reader = csv.reader(f)
        for row in reader:
            data.append(row)
    return data


def run(date):
    """Run train/test on logistic regression model"""
    # Begin preprocessing stage

    # Read data to process
    indata = get_data(dataset_path)
    indata_train = get_data(train_dataset_path)

    # Extract data and labels
    binary_labels = [x[0] for x in indata]  # legit o dns
    X = [x[2] for x in indata]  # DNS
    X_train = [x[2] for x in indata_train]  # DNS_train
    labels = [x[1] for x in indata]  # famiglia dga

    # Generate a dictionary of valid characters
    valid_chars = {x: idx + 1 for idx, x in enumerate(OrderedDict.fromkeys(''.join(X)))}
    maxlen = np.max([len(x) for x in X])

    # Convert characters to int and pad
    X_test = [[valid_chars[y] for y in x] for x in X]
    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)

    # Convert labels to 0-1 for binary class
    y_binary = np.array([0 if x == 'legit' else 1 for x in binary_labels])

    start = time.time()

    print("Carico il modello binario")
    with  open("%s/binary_model.json" % trained_model_dir, 'r') as json_file:
        loaded_model_json = json_file.read()

    binary_model = model_from_json(loaded_model_json)
    binary_model.load_weights("%s/binary_weights.h5" % trained_model_dir)
    
    y_pred = binary_model.predict(X_test)
    y_bin_result = [0 if (x <= 0.5) else 1 for x in y_pred]

    print("Salvataggio probabilitÃ ")
    np.savetxt("%s/probabilities.csv" % trained_model_dir, y_pred, delimiter=',', fmt='%f')
    # Salvataggio variabili per report binary

    # Calculate final result binary
    print("\n\nBinary report: \n")
    with open("%s/report_2.csv" % trained_model_dir, 'a') as f_report_binary:
        class_binary = {'white': 0, 'black': 1}
        evaluate(y_binary, y_bin_result, f_report_binary, start, time.time(), class_binary, True)
    
    # End binary report

    # print "Carico il modello multiclasse"

    # Convert labels to 0-37 for multi class
    # valid_class = {i: indx for indx, i in enumerate(set(labels))}
    # y_dga = [valid_class[x] for x in labels]
    # y_dga = np.array(y_dga)
    # End preprocessing stage

    # model_dga = joblib.load("model/model_multisetAtrain_h_t_domins_originals_2019_10_15-17-34.pkl")

    # X_dga_test =[]
    # y_dga_test_labels =[]
    # for i in range(len(y_result)):
    #     if y_result[i] == 0:
    #         X_dga_test.append(X_test[i])
    #         y_dga_test_labels.append(y_dga[i]) #Valori veri dei dga
    # X_dga_test = np.array(X_dga_test)
    # y_dga_test_labels = np.array(y_dga_test_labels)
    # y_pred_dga = model_dga.predict_proba(X_dga_test)
    # y_result_dga = [np.argmax(x) for x in y_pred_dga]
    # #End of multiclass classification stage

    # j = 0
    # for i in range(len(y_result)):
    #     if y_result[i] != white:
    #         y_result[i] = y_result_dga[j]
    #         j = j+1

    # #Calculate the final result multi class
    # print "\n\nMulticlass report: \n"
    # f_report_multi=open(path_report+"report_multiclass_"+dataset_path+"_"+str(date.year)+"_"+str(date.strftime("%m"))+"_"+str(date.strftime("%d"))+"-"+str(date.strftime("%H"))+"-"+str(date.strftime("%M"))+".txt", 'a')
    # evaluate(y_dga,y_result,f_report_multi,start,end,valid_class,False)
    # f_report_multi.close()
    # #end multiclass report


date = datetime.now()
if __name__ == "__main__":
    run(date)