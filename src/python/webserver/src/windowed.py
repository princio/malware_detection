import pandas as pd
import numpy as np
import base64

from pandas.io import json
from latex_translator import cm_latex, latex
import os, json

df_windows = pd.read_csv("df_windows.csv", index_col=0)[['window', 'infected', 'pcap_id', 'size', 'llr', 'ctr', 'nx', 'dga']]

df = df_windows.copy()

df.llr = df.apply(lambda x: int(x['llr']/x['size']), result_type='reduce', axis=1)
df.nx = df.apply(lambda x: int(x['nx']/x['size']*1000), result_type='reduce', axis=1)
df.ctr = df.apply(lambda x: int(x['ctr']/x['size']*1000), result_type='reduce', axis=1)

DIR_CSV = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'csv')
if not os.path.exists(os.path.join(DIR_CSV, 'llr.csv')):
    df.groupby(['size', 'dga', 'llr']).aggregate({
    'window': 'count',
    'pcap_id': 'nunique',
    }).to_csv(os.path.join(DIR_CSV, 'llr.csv'))

if not os.path.exists(os.path.join(DIR_CSV, 'nx.csv')):
    dfg = df.groupby(['size', 'dga', 'nx']).aggregate({
    'window': 'count',
    'pcap_id': 'nunique',
    }).to_csv(os.path.join(DIR_CSV, 'nx.csv'))

if not os.path.exists(os.path.join(DIR_CSV, 'ctr.csv')):
    dfg = df.groupby(['size', 'dga', 'ctr']).aggregate({
    'window': 'count',
    'pcap_id': 'nunique',
    }).to_csv(os.path.join(DIR_CSV, 'ctr.csv'))

dfb = df.groupby(['size', 'dga']).aggregate({
    'llr': [ 'max', 'mean', 'min' ],
    'nx': [ 'max', 'mean', 'min'  ],
    'ctr': [ 'max', 'mean', 'min' ],
}).astype(int)

def nest(d: dict) -> dict:
    result = {}
    for key, value in d.items():
        target = result
        for k in key[:-1]:  # traverse all keys but the last
            target = target.setdefault(k, {})
        target[key[-1]] = value
    return result

df2 = dfb.rename_axis(['fx', 'measure'], axis=1).stack(0).swaplevel(0,2).swaplevel(1,2)
bounds = nest(df2.to_dict(orient='index'))
with open(os.path.join(DIR_CSV, 'bounds.json'), 'w') as fp: json.dump(nest(df2.to_dict(orient='index')), fp)

df_th_ni = dfb.unstack(0).unstack(1).copy().reset_index(level=1).reset_index().rename(columns={ 'index': 'fx' })
df_th_ni.to_csv(os.path.join(DIR_CSV, 'bounds.csv'), index=False)
dfb = dfb.stack(0)

if os.path.exists(os.path.join(DIR_CSV, 'bests.json')):
    bests = {}
    ths = {}
    for fx in [ 'llr', 'nx', 'ctr' ]:
        bests[fx] = {}
        ths[fx] = {}
        for size in [ 100, 500, 2500 ]:
            bests[fx][size] = {}
            ths[fx][size] = {}
            for dga in [ 1, 2, 3 ]:
                bests[fx][size][dga] = []
                ths[fx][size][dga] = []
                DF = df[(df['size'] == size) & ((df.dga == 0) | (df.dga == dga))].copy()

                th = bounds[fx][size][dga]['min']
                thmax = bounds[fx][size][dga]['max']
                if fx == 'llr':
                    thstep = int((thmax - th) / 30)
                else:
                    thstep = 1
                
                tpr_old = 0
                th_i_max = { 'th': th, 'v': 0}
                th_ni_max = { 'th': th, 'v': 0}
                th_summax = { 'th': th, 'v': 0}
                th_gt08 = { 'th': th, 'v': 0}
                th_gt05 = { 'th': th, 'v': 0}
                while (th < thmax):
                    DF['detected'] = DF[fx] > th

                    tp = ((DF.detected) & (DF.infected)).sum()
                    fp = ((DF.detected) & (~DF.infected)).sum()
                    fn = ((~DF.detected) & (DF.infected)).sum()
                    tn = ((~DF.detected) & (~DF.infected)).sum()

                    tpr_ni = round(tn / (tn + fp), 2)
                    tpr_i = round(tp / (tp + fn), 2)

                    if th_ni_max['v'] < tpr_ni:
                        th_ni_max = { 'v': tpr_ni, 'th': th }
                    if th_i_max['v'] < tpr_i:
                        th_i_max = { 'v': tpr_i, 'th': th }
                    if th_summax['v'] < (tpr_ni + tpr_i):
                        th_summax = { 'v': (tpr_ni + tpr_i), 'th': th }
                    if tpr_ni >= 0.8 and tpr_i >= 0.8:
                        th_gt08['th'] = th
                    if tpr_ni >= 0.5 and tpr_i >= 0.5:
                        th_gt05['th'] = th
                    th += thstep
                bests[fx][size][dga] = {
                    "inf": th_i_max,
                    "ninf": th_ni_max,
                    "sum": th_summax,
                    "gt05": th_gt05,
                    "gt08": th_gt08
                }
    
    with open(os.path.join(DIR_CSV, 'bests.json'), 'w') as fp: json.dump(bests, fp)

def get_bounds(json=False):
    if json:
        d = df_th_ni.drop(columns=['std', 'min']).unstack().to_dict(orient='index')
        json = {}
        for fx in d:
            json[fx] = {}
            for s in [ 100, 500, 2500 ]:
                json[fx][s] = {}
                for m in [ 'max', 'mean' ]:
                    json[fx][s][m] = {}
        for fx in d:
            for t in d[fx]:
                json[fx][t[1]][t[0]] = d[fx][t]
        return json
    df = df_th_ni.copy().unstack(level=0).drop(columns=['std', 'min'], level=0)
    df = df.swaplevel(axis=1)
    cols, t = df.columns.sortlevel(level=0)
    df = df.T.iloc[t].T
    df.columns = pd.MultiIndex.from_tuples(tuple([ (latex(c[0]), latex(c[1])) for c in cols]))

    return df

def tnfntpfp(tn,fn,tp,fp):
    pri = tp / (tp + fp)
    rei = tp / (tp + fn)
    f1i = 2 * (pri * rei) / (pri + rei)
    prni = tn / (tn + fn)
    reni = tn / (tn + fp)
    f1ni = 2 * (prni * reni) / (prni + reni)
    ac = (tp + tn) / (tp + tn + fp + fn)
    prm = (pri + prni)/2
    rem = (rei + reni)/2
    f1m = (f1i + f1ni)/2
    return {
        ('normal', 'pr'): tn / (tn + fn),
        ('normal', 're'): tn / (tn + fp),
        # ('normal', 'f1'): 2 * (prni * reni) / (prni + reni),
        # ('normal', 'tpr'): tn / (tn + fp),
        ('infected', 'pr'): tp / (tp + fp), 
        ('infected', 're'): tp / (tp + fn),
        # ('infected', 'f1'): 2 * (pri * rei) / (pri + rei),
        # ('infected', 'tpr'): tp / (tp + fn),
        #('macro', 'pr'): (pri + prni)/2,
        # ('macro', 're'): (rei + reni)/2, ('macro', 'f1'): (f1i + f1ni)/2,
        ('macro', 'tpr'): ((tp / (tp + fn)) + (tn / (tn + fp))) / 2,
        ('macro', 'f1'): (f1i + f1ni)/2,
        ('', 'accuracy'): (tp + tn) / (tp + tn + fp + fn)
    }

class DetectionConfig(object):


    def __init__(self, DF, vDGA, size, dga_gt, f_win, f_pcap):
        self.DF = DF
        
        self.vDGA = vDGA
        self.size = size
        self.dga_gt = dga_gt
        
        self.f_win = f_win
        self.f_pcap = f_pcap

        self.df_win = None
        self.df_pcap = None


    def windows(self):
        if self.df_win is not None:
            return self.df_win
        
        DF = self.DF
        if self.dga_gt:
            df = DF[(~DF.infected) | (DF.dga >= self.vDGA)].copy()
        else:
            df = DF[(~DF.infected) | (DF.dga == self.vDGA)].copy()
        df["detected"] = self.f_win.apply(df)
        self.df_win = df.copy()
        return df


    def pcaps(self):
        if self.df_pcap is not None:
            return self.df_pcap
    
        df = self.windows().copy()
        
        df["detected_id"] = df.window.mask(df.detected == False)
        
        df_pcap = df.groupby(["pcap_id", "dga", "infected"]).aggregate({
            "window": ["count"],
            "detected": ["sum"],
            "detected_id": ["first"]
        })
        
        df_pcap = df_pcap.reset_index(level=2)
        df_pcap.columns = [ 'infected', 'windows', 'windows_detected', 'first_window_detected']
        df_pcap['ratio'] = df_pcap.windows_detected / df_pcap.windows
        df_pcap['first_window_detected'] = df_pcap.first_window_detected / df_pcap.windows
        
        df_pcap['detected'] = self.f_pcap.apply(df_pcap)
        
        self.df_pcap = df_pcap.copy()
        
        return df_pcap


    def _get_cm(self, DF):
        tp = ((DF.detected) & (DF.infected)).sum()
        fp = ((DF.detected) & (~DF.infected)).sum()
        fn = ((~DF.detected) & (DF.infected)).sum()
        tn = ((~DF.detected) & (~DF.infected)).sum()

        df_cm = pd.DataFrame.from_dict({'NIt': { 'NIp': tn, 'Ip': fp }, 'It': {'NIp': fn, 'Ip': tp } }, orient='index')

        report = tnfntpfp(tn, fn, tp, fp)
        df_report = pd.DataFrame.from_dict(report, orient="index").T
        df_report.columns = pd.MultiIndex.from_tuples(df_report.columns)

        return df_cm, df_report
        
    def get_cm_windows(self):
        return self._get_cm(self.windows())
    
    def get_cm_pcaps(self):
        return self._get_cm(self.pcaps())
    
    def values(self):

        index = [
            ("size", (self.size)),
            ("vDGA", (self.dga_gt, self.vDGA)),
            ("th", (self.f_win._th())),
            ("thp", (self.f_pcap.th)),
            ("fx", self.f_win.symbol()),
        ]
        
        df_cm_w, df_report_w = self.get_cm_windows()
        df_cm_p, df_report_p = self.get_cm_pcaps()
        
        columns = [cm_latex(df_cm_w)] + df_report_w.round(2).to_numpy().tolist()[0]
        columns += [cm_latex(df_cm_p)] + df_report_p.round(2).to_numpy().tolist()[0]
        
        header_w = [ ("", "CM") ] + list(df_report_w.columns)
        header_p = [ ("", "CM") ] + list(df_report_p.columns)

        header = [ latex(h, 'w') for h in header_w ] + [ latex(h, 'p') for h in header_p ]

        return [ latex(i[0], i[1]) for i in index ], columns, header
    
    def row(self, th_ni_measure_symbol):

        index = [
            ("size", (self.size)),
            ("vDGA", (self.dga_gt, self.vDGA)),
            ("th", (self.f_win._th())),
            ("thp", (self.f_pcap.th)),
            ("fx", self.f_win.symbol()),
        ]
        
        df_cm_w, df_report_w = self.get_cm_windows()
        df_cm_p, df_report_p = self.get_cm_pcaps()
        
        columns = [cm_latex(df_cm_w)] + df_report_w.round(2).to_numpy().tolist()[0]
        columns += [cm_latex(df_cm_p)] + df_report_p.round(2).to_numpy().tolist()[0]
        
        header_w = [ ("", "CM") ] + list(df_report_w.columns)
        header_p = [ ("", "CM") ] + list(df_report_p.columns)

        header = [ latex(h, 'w') for h in header_w ] + [ latex(h, 'p') for h in header_p ]

        return [ latex(i[0], i[1]) for i in index ], columns, header

class ThFunction(object):

    def __init__(self, name, function, th = 1.0):
        self.name = name
        self.function = function
        
        self.th = th
        self.cf = 1.0
        pass

    def __copy__(self):
        c = ThFunction(self.name, self.function)
        c.cf = self.cf
        c.th = self.th
        return c
    
    def symbol(self):
        return latex(self.name)
    
    def _th(self):
        return self.th * self.cf if self.name in ['ratio', 'llr' ] else self.th + self.cf
    
    def apply(self, df):
        return self.function(df[self.name], self._th())
    
    def __str__(self):
        return f"{self.name}/{self.th}/{self.cf}"


def process(sizes, dga_gt, dgas, th_measure, cfs, fxs):
    wfunctions = {
        "llr": ThFunction("llr", lambda s, th: s > th),
        "nx": ThFunction("nx", lambda s, th: s > th),
        "ctr": ThFunction("ctr", lambda s, th: s > th)
    }
    wfunctions = [ wfunctions[f] for f in fxs ]

    th_ni_measure_symbol = {
        'mean': "\\bar{\mu}",
        'max': "\\bar{M}",
        'min': "\\bar{m}"
    }[th_measure]

    fpcap = { s: ThFunction("ratio", lambda s_ratio, th: s_ratio > th, cfs["ratio"][str(s)]) for s in sizes }

    detections = []
    for size in sizes:
        for dga in dgas[::-1]:
            for wfunction in wfunctions:

                wf = wfunction.__copy__()
                wf.cf = 1 #cfs[wf.name]
                wf.th = float(cfs[wf.name][str(size)]) #df_th_ni.loc[(wf.name, size)][th_measure]


                detection = DetectionConfig(df_windows[df_windows["size"] == size].copy(), dga, size, dga_gt, wf, fpcap[size])
                
                
                detections.append(detection)
                
    values = {}
    for det in detections:
        index, columns, header = det.row(th_ni_measure_symbol)
        values[tuple(index)] = columns
        

    df = pd.DataFrame.from_dict(values, orient="index")

    df.columns = header

    df.index = pd.MultiIndex.from_tuples(df.index.values, names=["$size$", "$vDGA$", "$th_f$", "$th_p$", "$f$"])

    return df


def _b64(html):
    b_html = bytes(html, 'utf-8')
    b64_html = base64.b64encode(b_html)
    return b64_html.decode('ascii')

def get_html(sizes, dga_gt, dgas, th_measure, cfs, fxs):

    df = process(sizes, dga_gt, dgas, th_measure, cfs, fxs)

    def highlight_lt(s, v, props=''):
        return np.where(s <= v, props, '')
    def highlight_gt(s, v, props=''):
        return np.where(s > v, props, '')
    def all(s,v,props=''):
        return [props] * s.shape[0]

    
    slice_ = [
        ('normal', 'pr'), ('normal', 're'), 
        ('infected', 'pr'), ('infected', 're'), ('macro', 'tpr'),
    ]
    slice_ = [ latex(s, 'w') for s in slice_] + [ latex(s, 'p') for s in slice_]

    html = df.style\
            .apply(highlight_lt,  axis=1, subset=slice_, v=0.5, props='color:orange;')\
            .apply(highlight_lt, axis=1, subset=slice_, v=0.25, props='color:red;',)\
            .apply(highlight_gt, axis=1, subset=slice_, v=0.5, props='color:green;',)\
            .apply(highlight_gt, axis=1, subset=slice_, v=0.75, props='color:lightgreen;',)\
            .apply(all, axis=1, subset=[latex(s, 'w') for s in [('macro', 'tpr'),('macro', 'f1')] ], v=0.75, props='font-weight:800;')\
            .format(precision=2)\
            .to_html()

    return {
        "html": _b64(html),
        "bounds": _b64(get_bounds().to_html(justify='left', border=0))
    }


def generate_json(sizes, dga_gt, dgas, th_measure, cfs, fxs):

    df = process(sizes, dga_gt, dgas, th_measure, cfs, fxs)

    df.to_json(path_or_buf='jsons/file.json')

    return