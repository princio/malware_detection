import pandas as pd
import numpy as np
import base64

import psycopg2

from pandas.io import json
from latex_translator import cm_latex, latex
import os, json, functools

"""
LLR and LLRT in window_qr_3|4 are arrays having three values:
 0 -> both q and r
 1 -> only q
 2 -> only r
"""

def create_df_windows():
    db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")
    gt_id=2
    pd.read_sql(
        """SELECT
        wqr."window", wqr.pcap_id, wqr.size, dga, wqr.nx, wqr.llr[1] as llr, wqr.gt09 as gt09, wqr.llr_t[1] as llrt
        FROM "window_qr_4" as wqr
            JOIN pcap ON pcap_id=pcap.id
            JOIN malware ON malware.id=pcap.malware_id 
        WHERE size=app[2] 
        ORDER BY size, pcap.id, "window" """,
        db).to_csv("df_windows.csv")
    pass

create_df_windows()

df = pd.read_csv("df_windows.csv", index_col=0)

df = df.astype(int) # essenziale perché diminuisce di molto la variabilità nel group by

# df.llr = df.apply(lambda x: int(x['llr']), result_type='reduce', axis=1)
# df.nx = df.apply(lambda x: int(x['nx']), result_type='reduce', axis=1)
# df.gt09 = df.apply(lambda x: int(x['gt09']), result_type='reduce', axis=1)

DIR_CSV = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'csv')

fxs = [ 'nx', 'llr', 'gt09', 'llrt' ]

for fx in fxs:
    if not os.path.exists(os.path.join(DIR_CSV, f'{fx}.csv')):
        df.groupby(['size', 'dga', fx]).aggregate({
        'window': 'count',
        'pcap_id': 'nunique',
        }).to_csv(os.path.join(DIR_CSV, f'{fx}.csv'))


dfnx = pd.read_csv(os.path.join(DIR_CSV, f'nx.csv'))
for fx in fxs:
    for i in range(100):
        a  = (df.nx > i).sum()
        b = dfnx[dfnx.nx > i].window.sum()
        if a != b:
            print(a,b)

dfb = df.groupby(['size', 'dga']).aggregate({
    f'{fx}': [ 'max', 'mean', 'min' ] for fx in fxs
}).astype(int)

bounds = {}
for fx in  fxs:
    bounds[fx] = {}
    for size in [ 100, 500, 2500]:
        bounds[fx][size] = {}
        for dga in [ 0, 1, 2, 3 ]:
            bounds[fx][size][dga] = dfb.loc[( size, fx)].loc[dga].to_dict()

if not os.path.exists(os.path.join(DIR_CSV, 'measures.json')):
    measures = {}
    ths = {}
    for fx in fxs:
        measures[fx] = {}
        ths[fx] = {}
        for size in [ 100, 500, 2500 ]:
            measures[fx][size] = {}
            ths[fx][size] = {}
            for dga in [ 1, 2, 3 ]:
                measures[fx][size][dga] = []
                ths[fx][size][dga] = []
                DF = df[(df['size'] == size) & ((df.dga == 0) | (df.dga == dga))].copy()

                if fx in [ 'llr', 'llrt' ]:
                    thmax = max([ bounds[fx][size][dga]['max'] for dga in [ 0, 1, 2, 3 ] ])
                    thmin = min([ bounds[fx][size][dga]['min'] for dga in [ 0, 1, 2, 3 ] ])
                    thstep = 10 if fx == 'llr' or fx == 'llrt' else 1
                    nsteps = 1000
                    thstep = (thmax - thmin) // nsteps
                else:
                    thmax = size
                    thmin = 1
                    thstep = 1
                    nsteps = size

                tprs = {
                    'ni': np.zeros(nsteps),
                    'i': np.zeros(nsteps),
                    'th': np.zeros(nsteps),
                }

                for i in range(nsteps):
                    th = thmax - thstep*i
                    DF['detected'] = DF[fx] > th
                    s_infected = DF.dga == dga
                    s_not_infected = DF.dga == 0

                    tp = ((DF.detected) & (s_infected)).sum()
                    fp = ((DF.detected) & (s_not_infected)).sum()
                    fn = ((~DF.detected) & (s_infected)).sum()
                    tn = ((~DF.detected) & (s_not_infected)).sum()

                    tpr_ni = round(tn / (tn + fp), 2)
                    tpr_i = round(tp / (tp + fn), 2)

                    tprs['ni'][i] = tpr_ni
                    tprs['i'][i] = tpr_i
                    tprs['th'][i] = th

                th_ni_max = tprs['th'].item(np.argmax(tprs['ni']))
                th_i_max = tprs['th'].item(np.argmax(tprs['i']))
                th_sum_max = tprs['th'].item(np.argmax(tprs['i'] + tprs['ni']))
                measures[fx][size][dga] = {
                    "inf": th_i_max,
                    "ninf": th_ni_max,
                    "sum": th_sum_max,
                }

                # TODO: gt05 not working
                for gt in [ 3, 5, 7, 8, 9 ]:
                    th_gt = tprs['th'][np.logical_and(tprs['ni'] >= gt/10, tprs['i'] >= gt/10)]
                    if len(th_gt) > 0:
                        measures[fx][size][dga]['gt0%d' % gt] = th_gt.item(0)
            measures[fx][size][0] = {}
            for dga in [ 0, 1, 2, 3 ]:
                for m in [ 'max', 'mean', 'min' ]:
                    measures[fx][size][dga][m] = bounds[fx][size][dga][m]
    with open(os.path.join(DIR_CSV, 'measures.json'), 'w') as fp: json.dump(measures, fp)


def tnfntpfp(tn,fn,tp,fp):
    pri = tp / (tp + fp)
    rei = tp / (tp + fn)
    f1i = 2 * (pri * rei) / (pri + rei)
    prni = tn / (tn + fn)
    reni = tn / (tn + fp)
    f1ni = 2 * (prni * reni) / (prni + reni)
    ac = (tp + tn) / (tp + tn + fp + fn)
    prm = (pri + prni)/2
    rem = (rei + reni)/2
    f1m = (f1i + f1ni)/2
    return {
        ('normal', 'pr'): tn / (tn + fn),
        ('normal', 're'): tn / (tn + fp),
        # ('normal', 'f1'): 2 * (prni * reni) / (prni + reni),
        # ('normal', 'tpr'): tn / (tn + fp),
        ('infected', 'pr'): tp / (tp + fp), 
        ('infected', 're'): tp / (tp + fn),
        # ('infected', 'f1'): 2 * (pri * rei) / (pri + rei),
        # ('infected', 'tpr'): tp / (tp + fn),
        #('macro', 'pr'): (pri + prni)/2,
        # ('macro', 're'): (rei + reni)/2, ('macro', 'f1'): (f1i + f1ni)/2,
        ('macro', 'tpr'): ((tp / (tp + fn)) + (tn / (tn + fp))) / 2,
        ('macro', 'f1'): (f1i + f1ni)/2,
        ('', 'accuracy'): (tp + tn) / (tp + tn + fp + fn)
    }

class DetectionConfig(object):


    def __init__(self, DF, vDGA, size, dga_gt, f_win, f_pcap):
        self.DF = DF
        
        self.vDGA = vDGA
        self.size = size
        self.dga_gt = dga_gt
        
        self.f_win = f_win
        self.f_pcap = f_pcap

        self.df_win = None
        self.df_pcap = None


    def windows(self):
        if self.df_win is not None:
            return self.df_win
        
        DF = self.DF
        if self.dga_gt:
            df = DF[(~DF.infected) | (DF.dga >= self.vDGA)].copy()
        else:
            df = DF[(~DF.infected) | (DF.dga == self.vDGA)].copy()
        df["detected"] = self.f_win.apply(df)
        self.df_win = df.copy()
        return df


    def pcaps(self):
        if self.df_pcap is not None:
            return self.df_pcap
    
        df = self.windows().copy()
        
        df["detected_id"] = df.window.mask(df.detected == False)
        
        df_pcap = df.groupby(["pcap_id", "dga", "infected"]).aggregate({
            "window": ["count"],
            "detected": ["sum"],
            "detected_id": ["first"]
        })
        
        df_pcap = df_pcap.reset_index(level=2)
        df_pcap.columns = [ 'infected', 'windows', 'windows_detected', 'first_window_detected']
        df_pcap['ratio'] = df_pcap.windows_detected / df_pcap.windows
        df_pcap['first_window_detected'] = df_pcap.first_window_detected / df_pcap.windows
        
        df_pcap['detected'] = self.f_pcap.apply(df_pcap)
        
        self.df_pcap = df_pcap.copy()
        
        return df_pcap


    def _get_cm(self, DF):
        tp = ((DF.detected) & (DF.infected)).sum()
        fp = ((DF.detected) & (~DF.infected)).sum()
        fn = ((~DF.detected) & (DF.infected)).sum()
        tn = ((~DF.detected) & (~DF.infected)).sum()

        df_cm = pd.DataFrame.from_dict({'NIt': { 'NIp': tn, 'Ip': fp }, 'It': {'NIp': fn, 'Ip': tp } }, orient='index')

        report = tnfntpfp(tn, fn, tp, fp)
        df_report = pd.DataFrame.from_dict(report, orient="index").T
        df_report.columns = pd.MultiIndex.from_tuples(df_report.columns)

        return df_cm, df_report
        
    def get_cm_windows(self):
        return self._get_cm(self.windows())
    
    def get_cm_pcaps(self):
        return self._get_cm(self.pcaps())
    
    def values(self):

        index = [
            ("size", (self.size)),
            ("vDGA", (self.dga_gt, self.vDGA)),
            ("th", (self.f_win._th())),
            ("thp", (self.f_pcap.th)),
            ("fx", self.f_win.symbol()),
        ]
        
        df_cm_w, df_report_w = self.get_cm_windows()
        df_cm_p, df_report_p = self.get_cm_pcaps()
        
        columns = [cm_latex(df_cm_w)] + df_report_w.round(2).to_numpy().tolist()[0]
        columns += [cm_latex(df_cm_p)] + df_report_p.round(2).to_numpy().tolist()[0]
        
        header_w = [ ("", "CM") ] + list(df_report_w.columns)
        header_p = [ ("", "CM") ] + list(df_report_p.columns)

        header = [ latex(h, 'w') for h in header_w ] + [ latex(h, 'p') for h in header_p ]

        return [ latex(i[0], i[1]) for i in index ], columns, header
    
    def row(self, th_ni_measure_symbol):

        index = [
            ("size", (self.size)),
            ("vDGA", (self.dga_gt, self.vDGA)),
            ("th", (self.f_win._th())),
            ("thp", (self.f_pcap.th)),
            ("fx", self.f_win.symbol()),
        ]
        
        df_cm_w, df_report_w = self.get_cm_windows()
        df_cm_p, df_report_p = self.get_cm_pcaps()
        
        columns = [cm_latex(df_cm_w)] + df_report_w.round(2).to_numpy().tolist()[0]
        columns += [cm_latex(df_cm_p)] + df_report_p.round(2).to_numpy().tolist()[0]
        
        header_w = [ ("", "CM") ] + list(df_report_w.columns)
        header_p = [ ("", "CM") ] + list(df_report_p.columns)

        header = [ latex(h, 'w') for h in header_w ] + [ latex(h, 'p') for h in header_p ]

        return [ latex(i[0], i[1]) for i in index ], columns, header

class ThFunction(object):

    def __init__(self, name, function, th = 1.0):
        self.name = name
        self.function = function
        
        self.th = th
        self.cf = 1.0
        pass

    def __copy__(self):
        c = ThFunction(self.name, self.function)
        c.cf = self.cf
        c.th = self.th
        return c
    
    def symbol(self):
        return latex(self.name)
    
    def _th(self):
        return self.th * self.cf if self.name in ['ratio', 'llr' ] else self.th + self.cf
    
    def apply(self, df):
        return self.function(df[self.name], self._th())
    
    def __str__(self):
        return f"{self.name}/{self.th}/{self.cf}"


def process(sizes, dga_gt, dgas, th_measure, cfs, fxs):
    wfunctions = {
        "llr": ThFunction("llr", lambda s, th: s > th),
        "nx": ThFunction("nx", lambda s, th: s > th),
        "gt09": ThFunction("gt09", lambda s, th: s > th)
    }
    wfunctions = [ wfunctions[f] for f in fxs ]

    th_ni_measure_symbol = {
        'mean': "\\bar{\mu}",
        'max': "\\bar{M}",
        'min': "\\bar{m}"
    }[th_measure]

    fpcap = { s: ThFunction("ratio", lambda s_ratio, th: s_ratio > th, cfs["ratio"][str(s)]) for s in sizes }

    detections = []
    for size in sizes:
        for dga in dgas[::-1]:
            for wfunction in wfunctions:

                wf = wfunction.__copy__()
                wf.cf = 1 #cfs[wf.name]
                wf.th = float(cfs[wf.name][str(size)]) #df_th_ni.loc[(wf.name, size)][th_measure]


                detection = DetectionConfig(df_windows[df_windows["size"] == size].copy(), dga, size, dga_gt, wf, fpcap[size])
                
                
                detections.append(detection)
                
    values = {}
    for det in detections:
        index, columns, header = det.row(th_ni_measure_symbol)
        values[tuple(index)] = columns
        

    df = pd.DataFrame.from_dict(values, orient="index")

    df.columns = header

    df.index = pd.MultiIndex.from_tuples(df.index.values, names=["$size$", "$vDGA$", "$th_f$", "$th_p$", "$f$"])

    return df


def _b64(html):
    b_html = bytes(html, 'utf-8')
    b64_html = base64.b64encode(b_html)
    return b64_html.decode('ascii')

def get_html(sizes, dga_gt, dgas, th_measure, cfs, fxs):

    df = process(sizes, dga_gt, dgas, th_measure, cfs, fxs)

    def highlight_lt(s, v, props=''):
        return np.where(s <= v, props, '')
    def highlight_gt(s, v, props=''):
        return np.where(s > v, props, '')
    def all(s,v,props=''):
        return [props] * s.shape[0]

    
    slice_ = [
        ('normal', 'pr'), ('normal', 're'), 
        ('infected', 'pr'), ('infected', 're'), ('macro', 'tpr'),
    ]
    slice_ = [ latex(s, 'w') for s in slice_] + [ latex(s, 'p') for s in slice_]

    html = df.style\
            .apply(highlight_lt,  axis=1, subset=slice_, v=0.5, props='color:orange;')\
            .apply(highlight_lt, axis=1, subset=slice_, v=0.25, props='color:red;',)\
            .apply(highlight_gt, axis=1, subset=slice_, v=0.5, props='color:green;',)\
            .apply(highlight_gt, axis=1, subset=slice_, v=0.75, props='color:lightgreen;',)\
            .apply(all, axis=1, subset=[latex(s, 'w') for s in [('macro', 'tpr'),('macro', 'f1')] ], v=0.75, props='font-weight:800;')\
            .format(precision=2)\
            .to_html()

    return {
        "html": _b64(html)
    }


def generate_json(sizes, dga_gt, dgas, th_measure, cfs, fxs):

    df = process(sizes, dga_gt, dgas, th_measure, cfs, fxs)

    df.to_json(path_or_buf='jsons/file.json')

    return