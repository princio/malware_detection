import subprocess
import os
import pandas as pd
from extractor import Extractor
import pickle
from model import Model
import json

if __name__ == '__main__':

    folder =        '/media/princio/ssd512/stratosphere/pcap/normal/'
    out_directory = '/media/princio/ssd512/stratosphere/pcap/dns_pcap/normal/'

    files = []
    sizes = []
    if not os.path.isdir(folder):
        print(f'Argument <{folder}> is not a folder.')
        exit(1)

    for walker in os.walk(folder):
        for filename in walker[2]:
            if filename[filename.rfind('.'):] != '.pcap': continue
            files.append(os.path.join(folder, filename))
            sizes.append(os.stat(os.path.join(folder, filename)).st_size)
            print(f'Added to list <{filename}> of size {int(sizes[-1]/1_000)} kB.')
        break

    files = {files[i[0]]: i[1] for i in sorted(enumerate(sizes), key=lambda x:x[1])}

    sizes = {}
    for file_path in files:
        out_path = os.path.join(out_directory, os.path.basename(file_path))
        log_path = out_path + '.log'
        prg_path = out_path + '.progress'
        err_path = out_path + '.error'
        if os.path.exists(out_path) or os.path.exists(err_path):
            print('skipping')
            continue
        print('Processing:\nfilepath: %s\n    size: %d kB' % (file_path, int(files[file_path]/1_000)))
        with open(log_path,"w") as errfile:
            ret = subprocess.run([
                'tshark', '-r', file_path,
                '-Y', 'dns && !_ws.malformed && !icmp',
                '-w', prg_path],
                stderr=errfile)

        if os.stat(log_path).st_size == 0:
            os.remove(log_path)

        if ret.returncode == 0:
            os.rename(prg_path, out_path)
            size_new = os.stat(out_path).st_size
        else:
            os.rename(prg_path, err_path)
            size_new = os.stat(err_path).st_size
            print('Error during filtering with tshark [%d].' % ret.returncode)

        sizes[os.path.basename(file_path)] = {
            'full': files[file_path],
            'filtered': size_new,
            'ret_code': ret.returncode
        }

        with open('/media/princio/ssd512/log2.json', 'w') as fp:
            json.dump(sizes, fp)

        print()

    print(sizes)
    exit(0)