from re import DEBUG
import psycopg2
from psycopg2.extras import execute_values
import pandas as pd
import numpy as np
import os
from pandasgui import show
import pprint

pp = pprint.PrettyPrinter(indent=4)

# With LLR2 we intend to set-to-0 (zeroing) the NOSFX values between two thresholds.
#
#
#
#
#
#
#
#


db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")


def f_llr(s_nosfx):
    num = s_nosfx.replace(
        [0, 1], [0.000_000_000_000_000_1, 1 - 0.000_000_000_000_000_1]
    )
    den = np.ones(len(num)) - num
    llr = np.log(num / den)
    return llr


df_pcap = pd.read_sql(
    'SELECT id, "name", "malware_id", "infected", "qr", q, r, "unique", days FROM pcap ORDER BY name',
    db,
)

windows = [
    100,
    500,
    1000,
    2500,
    10000,
]

max_q = np.lcm.reduce(windows) * (1_000_000 // np.lcm.reduce(windows))

print(max_q)

logits = [
    "logit.0",
    "logit.4",
    "logit.7",
    "logit.9",
    "logit.99",
]

logits_labels = [
    "ist",
    "rev-ist",
    "ist_top10m",
    "rev-ist_top10m",
]

logits_cols = [(logit, lb) for logit in logits for lb in logits_labels]

for idx, pcap in df_pcap.iterrows():

    cur = db.cursor()

    print("Processing ", pcap["id"], pcap["name"])

    df_window_done = pd.read_sql(
        'SELECT W2."size", SUM(W2.APP) AS sum FROM "window_q" AS W2 WHERE W2.PCAP_ID = %d GROUP BY W2."size"'
        % pcap["id"],
        db,
    )

    windows_todo = windows.copy()
    if False and not df_window_done.empty:
        for _, row in df_window_done.iterrows():
            if row["size"] in windows_todo:
                if row["sum"] == pcap["q"]:
                    windows_todo.remove(row["size"])
                else:
                    print(
                        "For size=%d Unmatching queries: %d <> %d"
                        % (row["size"], row["sum"], pcap["q"])
                    )
                    cur.execute(
                        """DELETE FROM window_q WHERE "size" = %s AND pcap_id=%s""",
                        (int(row["size"]), int(pcap["id"])),
                    )
                    db.commit()

    if len(windows_todo) == 0:
        print("No window to be done for %d." % pcap["id"])
        continue

    print("Window to do: ", windows_todo)

    for offset in range(0, 1 + pcap.qr // max_q):
        query = (
            """SELECT m3.*, """
            + ",".join([f'"{l}"' for l in logits])
            + """
                FROM message3 as m3 JOIN dn ON m3.dn_id=dn.id
                    WHERE pcap_id=%d AND is_response is FALSE
                        ORDER BY fn
                            LIMIT %d OFFSET %d"""
            % (
                pcap["id"],
                max_q,
                max_q * offset,
            )
        )
        df = pd.read_sql(query, db)

        sum_cols = ["app", "txt"] + logits_cols

        for logit in logits:
            df[[(logit, lb) for lb in logits_labels]] = pd.DataFrame(df[logit].tolist(), index=df.index, columns=[(logit, lb) for lb in logits_labels])
            df.drop(columns=logit, inplace=True)

        if df.empty:
            break

        print(
            "Fetched qr having fn >= %d and fn < %d [%d]"
            % (max_q * offset, max_q * (offset + 1), df.shape[0])
        )

        df["app"] = 1
        df["txt"] = df.qcode.apply(lambda x: 1 if x == 16 else 0)

        aggs = {c: "sum" for c in sum_cols}
        aggs["id"] = ["first", "last"]
        aggs["fn"] = ["first", "last"]
        aggs["time_s"] = ["first", "last"]
        aggs["dn_id"] = "nunique"

        tmp = list(aggs.keys())
        for col in df.columns:
            if col not in tmp:
                df.drop(columns=col, inplace=True)

        for window in windows_todo:
            print("Processing window of size %d" % window)
            df__ = df.copy()
            df__["window"] = df__.index // window + (offset * max_q) / window

            cols = np.array(["id", "fn", "time_s", "dn_id", "window"] + sum_cols, dtype=object)

            df__ = (
                df__[cols]
                .groupby("window")
                .agg(aggs)
                .reset_index()
                .rename(columns={"dn_id": "unique"})
            )
            df__["pcap_id"] = pcap["id"]
            df__["size"] = window

            for logit in logits:
                logit_cols = [((logit, lb), "sum") for lb in logits_labels]#np.array([((logit, lb), "sum") for lb in logits_labels], dtype=object)
                #df__[logit] = df__[logit_cols].astype(str).agg(lambda x: "'{%s}'" % ",".join(x), axis=1)
                df__[logit] = df__[logit_cols].agg(lambda x: x.to_numpy().tolist(), axis=1)
                df__.drop(columns=logit_cols, inplace=True)

            print(df__)

            fields = [
                (("pcap_id", ""), "pcap_id"),
                (("size", ""), "size"),
                (("window", "", ), "window"),
                (("app", "sum"), "app"),
                (("unique", "nunique"), "unique"),
                (("txt", "sum"), "txt"),
                (("time_s", "first"), "begin_time"),
                (("time_s", "last"), "end_time"),
                (("fn", "first"), "begin_fn"),
                (("fn", "last"), "end_fn"),
            ] + [((l, ''), l.replace("logit", "llr")) for l in logits]

            column_names = ",".join([f'"{f[1]}"' for f in fields])
            column_values = df__[[f[0] for f in fields]].to_numpy().tolist()
            print(column_values)
            
            execute_values(
                cur,
                f'INSERT INTO public."window_q"({column_names}) VALUES %s;',
                column_values,
            )
        #db.commit()
    cur.close()
