from re import DEBUG
from numpy.lib.arraysetops import unique
import psycopg2
from psycopg2.extras import execute_values
import pandas as pd
import numpy as np
import os
from pandasgui import show
import pprint

pp = pprint.PrettyPrinter(indent=4)

# With LLR2 we intend to set-to-0 (zeroing) the NOSFX values between two thresholds.
#
#
#
#
#
#
#
#


db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")


def f_llr(s_nosfx):
    num = s_nosfx.replace(
        [0, 1], [0.000_000_000_000_000_1, 1 - 0.000_000_000_000_000_1]
    )
    den = np.ones(len(num)) - num
    llr = np.log(num / den)
    return llr


df_pcap = pd.read_sql(
    'SELECT id, "name", "malware_id", "infected", "qr", q, r, "unique", days FROM pcap WHERE qr > 1000000 ORDER BY name',
    db,
)

windows = [
    2500,
    500,
    100,
]

max_q = np.lcm.reduce(windows) * (1_000_000 // np.lcm.reduce(windows))

query = """
DROP TABLE IF EXISTS public.window_qr_2;

CREATE TABLE IF NOT EXISTS public.window_qr_2
(
    id integer NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 2147483647 CACHE 1 ),
    pcap_id integer NOT NULL,
    size integer NOT NULL,
    "window" integer NOT NULL,

    "first" integer[] DEFAULT '{0,0,0}'::integer[],
    "last" integer[] DEFAULT '{0,0,0}'::integer[],

    "begin_time" real[] DEFAULT '{0,0,0}'::real[],
    "end_time" real[] DEFAULT '{0,0,0}'::real[],

    "app" integer[] DEFAULT '{0,0,0}'::integer[],
    "unique" integer[] DEFAULT '{0,0,0}'::integer[],

    "txt" integer[] DEFAULT '{0,0,0}'::integer[],

    "ok" integer[] DEFAULT '{0,0,0}'::integer[],
    "nx" integer[] DEFAULT '{0,0,0}'::integer[],
    "oth" integer[] DEFAULT '{0,0,0}'::integer[],

    "llr" double precision[] DEFAULT '{0,0,0}'::double precision[],

    CONSTRAINT window_qr_2_pkey PRIMARY KEY (id)
)

TABLESPACE pg_default;

ALTER TABLE public.window_qr_2
    OWNER to postgres;
"""

cur = db.cursor()

cur.execute(query)

cur.close()

db.commit()

BATCH_SIZE = 1_000_000

pd.options.display.float_format = '{:.2f}'.format

for idx, pcap in df_pcap.iterrows():

    cur = db.cursor()

    query = """SELECT m3.fn, is_response
                    FROM message3 as m3
                    WHERE pcap_id=%d
                            ORDER BY fn""" % pcap.id
    df_fn = pd.read_sql(query, db)

    df_fn_q = df_fn[~df_fn.is_response].fn.to_frame().copy()
    df_fn_r = df_fn[df_fn.is_response].fn.to_frame().copy()

    for s in windows:
        
        nwindows = pcap.qr // s + 1

        df_q = df_fn_q.copy()
        df_q['qnum'] = np.arange(df_q.shape[0])

        # the windows bounds are defined by the number of queries (qnum = s), because I suppose
        # that is better to trigger the intrusion detector whit a threshold dependent on the number of queries.
        df_q['batch'] = df_q['qnum'] // BATCH_SIZE
        df_q['window'] = df_q['qnum'] // s
        df_q = df_q[['window', 'fn']].groupby(by='window').aggregate(['first']).reset_index()

        df_q[('fn', 'last')] = df_q[('fn', 'first')].shift(-1, fill_value=df_fn.fn.max() + 1) - 1

        df_q['batch'] = df_q[('fn', 'last')] // BATCH_SIZE

        df_batch = df_q.groupby(by='batch').aggregate(['first', 'last', ]).reset_index()
        print(df_batch)

        for i in range(df_q.batch.max()+1):
            df_qq = df_q[df_q.batch == i]
            print(df_qq[('fn', 'first')].min(), df_qq[('fn', 'last')].max())
            for (_, s_window) in df_qq.iterrows():
                print(s_window[('fn', 'first')], s_window[('fn', 'last')])

        # fn first rows indicates the first query of each window.
        df_firsts = df_q[('fn', 'first')]
        firsts = df_q[('fn', 'first')].values

        df_batch = pd.DataFrame(df_q[[('fn', 'first')]].values, columns=['first_fn'])

        df_batch['last_fn'] = df_batch['first_fn'].shift(-1) - 1
        df_batch.at[df_batch.shape[0] - 1, 'last_fn'] = df_q[('fn', 'first')].max()
        df_batch = df_batch.astype(int)
        df_batch['batch'] = df_batch['last_fn'] // BATCH_SIZE

        
        print(df_batch.to_markdown())
        
        first_splus1_q = [ firsts[i] for i in range(len(firsts))].fillna()

        n_windows = len(first_splus1_q)
        
        firsts_sliced = first_splus1_q[::(BATCH_SIZE // s)] + [first_splus1_q[-1]]

        limits_slices = [ (firsts_sliced[i], firsts_sliced[i+1]) for i in range(-1 + len(firsts_sliced)) ]

        limits_slices[-1] = (limits_slices[-1][0], limits_slices[-1][1] * 2)
        
        offset = -1
        for limits_slice in limits_slices:
            query = (
                    """SELECT m3.*, dn."logit.0"[1] as logit
                        FROM message3 as m3 JOIN dn ON m3.dn_id=dn.id
                            WHERE pcap_id=%d AND fn >= %d AND fn < %d
                                ORDER BY fn"""
                    % (
                        pcap.id,
                        limits_slice[0],
                        limits_slice[1],
                    )
                )
            df_slice = pd.read_sql(query, db)
            print("Fetching from %d <= fn < %d" % limits_slice, len(firsts))

            df_firsts_slice = df_firsts[(df_firsts >= limits_slice[0]) & (df_firsts <= limits_slice[1])]
            df_limits = df_firsts_slice.to_frame()
            df_limits['1'] = df_firsts_slice.shift(-1)

            values = []
            for limits in df_limits.iloc[0:-1].astype(int).values:
                offset += 1
                
                df = df_slice[(df_slice.fn >= limits[0]) & (df_slice.fn <= limits[1])].copy()
                df_q = df[~df.is_response]
                df_r = df[df.is_response]
                if df_r.shape[0] == 0:
                    df_r = df_r.append(pd.Series(0, index=df_r.columns), ignore_index=True)

                print(
                    "Pcap %6d, size %6d, window %d/%d (s=%d): \t\tq: [%d] %6d <= fn <= %6d\tr: [%d] %6d <= fn <= %6d"
                    % (pcap.id, pcap.qr, offset+1, nwindows, s,
                        df_q.shape[0], df_q.fn.min(), df_q.fn.max(),
                        df_r.shape[0], df_r.fn.min(), df_r.fn.max(),
                    )
                )

                df = pd.concat([df_q, df_r], axis=0).sort_values(by="fn", ascending=True)

                dfs = [df, df_q, df_r]

                sum_cols = ["app", "ok", "txt", "nx", "no", "other", "llr"]

                app = [ _df.shape[0] for _df in dfs ]

                first = [ _df.iloc[0].fn for _df in dfs ]
                last = [ _df.iloc[-1].fn for _df in dfs ]

                begin_time = df.iloc[0].time_s
                end_time = df.iloc[-1].time_s

                nunique = [ _df.dn_id.drop_duplicates().shape[0] for _df in dfs ]

                txt = [ _df.qcode.apply(lambda x: 1 if x == 16 else 0).sum()  for _df in dfs ]

                ok = df_r.rcode.apply(lambda x: 1 if x == 0 else 0).sum()
                nx = df_r.rcode.apply(lambda x: 1 if x == 3 else 0).sum()
                oth = df_r.shape[0] - ok - nx

                llr = [ _df.logit.sum() for _df in dfs ]

                def cv(v):
                    if type(v).__module__ == np.__name__:
                        return v.item()
                    if type(v).__name__ == "list":
                        return ( vv.item() if type(vv).__module__ == np.__name__ else vv for vv in v )
                    return v

                values += ( cv(v) for v in [pcap.id, s, offset, first, last, begin_time, end_time, app, nunique,  txt, ok, nx, oth, llr ] )
                pass
            execute_values(
                cur,
                """INSERT INTO public.window_qr_2(
                    pcap_id, size, "window", first, last, begin_time, end_time, app, "unique", txt, ok, nx, oth, llr)
                    VALUES  %s;""",
                [values]
            )
            pass #end slice
        db.commit()
        pass #end window
    pass #end pcap
    cur.close()
