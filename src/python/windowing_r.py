from re import DEBUG
from numpy.lib.arraysetops import unique
import psycopg2
from psycopg2.extras import execute_values
import pandas as pd
import numpy as np
import os
from pandasgui import show
import pprint

pp = pprint.PrettyPrinter(indent=4)

# With LLR2 we intend to set-to-0 (zeroing) the NOSFX values between two thresholds.
#
#
#
#
#
#
#
#


db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")


def f_llr(s_nosfx):
    num = s_nosfx.replace(
        [0, 1], [0.000_000_000_000_000_1, 1 - 0.000_000_000_000_000_1]
    )
    den = np.ones(len(num)) - num
    llr = np.log(num / den)
    return llr


df_pcap = pd.read_sql(
    'SELECT id, "name", "malware_id", "infected", "qr", q, r, "unique", days FROM pcap ORDER BY name',
    db,
)

windows = [
    2500,
    500,
    100,
]

max_q = np.lcm.reduce(windows) * (1_000_000 // np.lcm.reduce(windows))

query = """
DROP TABLE IF EXISTS public.window_qr_3;

CREATE TABLE IF NOT EXISTS public.window_qr_3
(
    id integer NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 2147483647 CACHE 1 ),
    pcap_id integer NOT NULL,
    size integer NOT NULL,
    "window" integer NOT NULL,

    "first" integer[] DEFAULT '{0,0,0}'::integer[],
    "last" integer[] DEFAULT '{0,0,0}'::integer[],

    "begin_time" real DEFAULT 0.0,
    "end_time" real DEFAULT 0.0,

    "app" integer[] DEFAULT '{0,0,0}'::integer[],
    "unique" integer[] DEFAULT '{0,0,0}'::integer[],

    "txt" integer[] DEFAULT '{0,0,0}'::integer[],

    "ok" integer DEFAULT 0,
    "nx" integer DEFAULT 0,
    "oth" integer DEFAULT 0,

    "gt" double precision[],

    "llr" double precision[] DEFAULT '{0,0,0}'::double precision[],

    CONSTRAINT window_qr_3_pkey PRIMARY KEY (id)
)

TABLESPACE pg_default;

ALTER TABLE public.window_qr_3
    OWNER to postgres;
"""

cur = db.cursor()

cur.execute(query)

cur.close()

db.commit()

BATCH_SIZE = 1_000_000

pd.options.display.float_format = '{:.2f}'.format

for idx, pcap in df_pcap.iterrows():

    cur = db.cursor()

    query = """SELECT m3.fn, is_response
                    FROM message3 as m3
                    WHERE pcap_id=%d
                            ORDER BY fn""" % pcap.id
    df_fn = pd.read_sql(query, db)

    df_fn_q = df_fn[~df_fn.is_response].fn.to_frame().copy()
    df_fn_r = df_fn[df_fn.is_response].fn.to_frame().copy()

    print("Processing pcap %d [%d/%d]" % (pcap.id, idx, df_pcap.shape[0]))


    for s in windows:
        
        nwindows = pcap.qr // s + 1

        df_qnum = df_fn_q.copy()
        df_qnum['qnum'] = np.arange(df_qnum.shape[0])

        # the windows bounds are defined by the number of queries (qnum = s), because I suppose
        # that is better to trigger the intrusion detector whit a threshold dependent on the number of queries.
        df_qnum['batch'] = df_qnum['qnum'] // BATCH_SIZE
        df_qnum['window'] = df_qnum['qnum'] // s
        df_qnum = df_qnum[['window', 'fn']].groupby(by='window').aggregate(['first']).reset_index()

        df_qnum[('fn', 'last')] = df_qnum[('fn', 'first')].shift(-1, fill_value=df_fn.fn.max() + 1) - 1

        df_qnum['batch'] = df_qnum[('fn', 'last')] // BATCH_SIZE

        df_qnum.columns = [ 'window', 'first_fn', 'last_fn', 'batch']

        df_batch = df_qnum.sort_values(by='window').groupby(by='batch').aggregate(['first', 'last']).reset_index()

        for i in range(df_qnum.batch.max()+1):
            df_qnum_batch = df_qnum[df_qnum.batch == i]

            first_fn_bacth = df_qnum_batch['first_fn'].min()
            last_fn_bacth = df_qnum_batch['last_fn'].max()

            query = (
                    """SELECT m3.*, dn."logit.0"[1] as logit
                        FROM message3 as m3 JOIN dn ON m3.dn_id=dn.id
                            WHERE pcap_id=%d AND fn >= %d AND fn <= %d
                                ORDER BY fn"""
                    % (
                        pcap.id,
                        first_fn_bacth,
                        last_fn_bacth
                    )
                )
            df_fetched = pd.read_sql(query, db)
            print("Fetching from %d <= fn <= %d" % (first_fn_bacth, last_fn_bacth))
            values = []
            for (_, s_window) in df_qnum_batch.iterrows():

                first_fn = s_window['first_fn']
                last_fn = s_window['last_fn']

                #print("Processing window %d:\t%d <= fn <= %d" % (s_window['window'], first_fn, last_fn))

                df_qr = df_fetched[(df_fetched.fn >= first_fn) & (df_fetched.fn <= last_fn)]
                df_q = df_qr[~df_qr.is_response]
                df_r = df_qr[df_qr.is_response]
                if df_r.shape[0] == 0:
                    df_r = df_r.append(pd.Series(0, index=df_r.columns), ignore_index=True)

                dfs = [df_qr, df_q, df_r]

                sum_cols = ["app", "ok", "txt", "nx", "no", "other", "llr"]

                app = [ _df.shape[0] for _df in dfs ]

                first = [ _df.iloc[0].fn for _df in dfs ]
                last = [ _df.iloc[-1].fn for _df in dfs ]

                begin_time = df_qr.iloc[0].time_s
                end_time = df_qr.iloc[-1].time_s

                nunique = [ _df.dn_id.drop_duplicates().shape[0] for _df in dfs ]

                txt = [ _df.qcode.apply(lambda x: 1 if x == 16 else 0).sum()  for _df in dfs ]

                ok = df_r.rcode.apply(lambda x: 1 if x == 0 else 0).sum()
                nx = df_r.rcode.apply(lambda x: 1 if x == 3 else 0).sum()
                oth = df_r.shape[0] - ok - nx

                gt = [ (dfs[1].logit > th).sum() for th in [ 0.5, 0.75, 0.9, 0.999, 0.999999 ] ]

                llr = [ _df.logit.sum() for _df in dfs ]

                def cv(v):
                    if type(v).__module__ == np.__name__:
                        return v.item()
                    if type(v).__name__ == "list":
                        return [ vv.item() if type(vv).__module__ == np.__name__ else vv for vv in v ]
                    return v

                values.append([ cv(v) for v in [pcap.id, s, s_window['window'], first, last, begin_time, end_time, app, nunique,  txt, ok, nx, oth, gt, llr ] ])
                pass #end window
            # print("\n".join([v.__str__() for v in values]))
            # print()
            execute_values(
                cur,
                """INSERT INTO public.window_qr_3(
                    pcap_id, size, "window", first, last, begin_time, end_time, app, "unique", txt, ok, nx, oth, gt, llr)
                    VALUES  %s;""",
                values
            )
            pass #end batch
        db.commit()
        pass #end batches
    pass #end pcap
    cur.close()
