import psycopg2
from psycopg2.extras import execute_values
import pandas as pd
import numpy as np
import os

db = psycopg2.connect("host=localhost dbname=dns user=postgres password=postgres")


def f_llr(s_nosfx):
    num = s_nosfx.replace(
        [0, 1], [0.000_000_000_000_000_1, 1 - 0.000_000_000_000_000_1]
    )
    den = np.ones(len(num)) - num
    llr = np.log(num / den)
    return llr


df_pcap = pd.read_sql(
    'SELECT id, "name", "malware_id", "infected", "qr", q, r, "unique", days FROM pcap ORDER BY name',
    db,
)

windows = [
    100,
    500,
    1000,
    2000,
    3000,
    4000,
    5000,
    7500,
    10000,
]  # [100, 500, 1000, 2000]

batch_size = 500 #np.lcm.reduce(windows)

for idx, pcap in df_pcap.iterrows():

    cur = db.cursor()

    print('Processing ', pcap['id'], pcap['name'])

    df_window = pd.read_sql(
        'SELECT DISTINCT "size" FROM "window" WHERE pcap_id=%d ORDER BY "size"'
        % pcap["id"],
        db,
    )

    window_todo = df_window.merge(pd.Series(windows, name='size'), on='size', how='outer', indicator=True)
    window_todo = window_todo[window_todo['_merge'] == 'right_only']

    if window_todo.shape[0] == 0:
        print('No window to be done.')
        continue

    print('Window to do: ', window_todo['size'].values)

    for offset in range(0, pcap.qr // batch_size):
        query = (
            "SELECT * FROM qr_grouped_view WHERE pcap_id=%d ORDER BY q_time LIMIT %d OFFSET %d" % (pcap["id"], batch_size, batch_size*offset)
        )
        print(query)
        df = pd.read_sql(query, db)

        print('Fetched qr from %d to %d [%d]' % (batch_size*offset, batch_size*offset + batch_size, df.shape[0]))

        df["app"] = 1
        df["ok"] = df.rcode.apply(lambda x: 1 if x == 0 else 0)
        df["nx"] = df.rcode.apply(lambda x: 1 if x == 3 else 0)
        df["no"] = df.rcode.fillna(value=-1).apply(lambda x: 1 if x == -1 else 0)
        df["txt"] = df.qcode.apply(lambda x: 1 if x == 16 else 0)
        df["top10m"] = (
            df["top10m"].astype(np.single).fillna(500_001).apply(lambda x: x < 500_000)
        )
        df = df.rename(columns={"top10m": "top500k"})

        f_l = lambda x: 1 if (x[0] == 1) and np.isnan(x[1]) else 0
        df["ok_top500k"] = df[["ok", "top500k"]].apply(f_l, axis=1)
        df["nx_top500k"] = df[["nx", "top500k"]].apply(f_l, axis=1)
        df["no_top500k"] = df[["no", "top500k"]].apply(f_l, axis=1)
        df["txt_top500k"] = df[["txt", "top500k"]].apply(f_l, axis=1)

        sum_cols = [
            "llr",
            "app",
            "ok",
            "nx",
            "no",
            "txt",
            "ok_top500k",
            "nx_top500k",
            "no_top500k",
            "txt_top500k",
        ]
        aggs = {c: "sum" for c in sum_cols}
        aggs["dn"] = "nunique"
        aggs["q_time"] = ["first", "last"]
        aggs["mq_id"] = ["first", "last"]

        for window in window_todo['size'].values:
            print('Processing window of size %d' % window)
            df__ = df.copy()
            df__["llr"] = f_llr(df__["nosfx"])
            df__["window"] = df__.index // window + offset*batch_size/window
            df__ = (
                df__[["mq_id", "dn", "window", "q_time"] + sum_cols]
                .groupby("window")
                .agg(aggs)
                .reset_index()
                .rename(columns={"dn": "unique"})
            )
            df__["pcap_id"] = pcap["id"]
            df__["size"] = window

            print(df__)

            fields = [
                "pcap_id",
                "size",
                "window",
                ("llr", "sum"),
                ("app", "sum"),
                ("unique", "nunique"),
                ("ok", "sum"),
                ("nx", "sum"),
                ("no", "sum"),
                ("txt", "sum"),
                ("ok_top500k", "sum"),
                ("nx_top500k", "sum"),
                ("no_top500k", "sum"),
                ("txt_top500k", "sum"),
                ("q_time", "first"),
                ("q_time", "last"),
                ("mq_id", "first"),
                ("mq_id", "last"),
            ]

            print(df__[fields])

            execute_values(
                cur,
                """INSERT INTO public."window"(pcap_id, "size", "window", llr, app, "unique", ok, nx, no, txt, ok_top500k, nx_top500k, no_top500k, txt_top500k, begin_time, end_time, begin_id, end_id)
                VALUES %s;""",
                df__[fields].to_numpy().tolist(),
            )
        #db.commit()
    cur.close()
