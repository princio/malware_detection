import numpy as np
from collections import OrderedDict, Counter as collection_counter
from keras.preprocessing import sequence
import time
from keras.models import model_from_json, Sequential
from sklearn.metrics import classification_report, confusion_matrix
from json import load as json_load
from Dataset import Dataset
from Pcap import Pcap

with open("models/alphabet.json", "r") as json_file:
    ALPHABET = json_load(json_file)

class Model:

    SELECT = """SELECT id, hash, path, training_set, test_size_folds, test_size_epochs, datetime,
                classes, epochs, folds, epoch, fold, dataset_train, dataset_test, average
                FROM public.models """

    def __init__(self):
        self.id = None
        self.hash = None
        self.path = None
        self.training_set = None
        self.test_size_folds = 0.05
        self.test_size_epochs = 0.05
        self.training_dataset = "setAtrain_h_t_domins"
        self.datetime = None
        self.classes = []
        self.epochs = None
        self.folds = None
        self.epoch = None
        self.fold = None
        self.dataset_train = None
        self.dataset_test = None
        self.average = []

        self.nn: Sequential = None

    @staticmethod
    def fetch(connection, id):
        cursor = connection.cursor()
        cursor.execute("""SELECT id, hash, path, training_set, test_size_folds, test_size_epochs, datetime, classes, epochs, folds, epoch, fold, dataset_train, dataset_test, average
                            FROM public.models WHERE id = %s;""", (id, ))
                            
        return Model.fill(connection, cursor.fetchone())

    @staticmethod
    def fill(connection, fetched):
        fetched = list(fetched)

        model = Model()
        model.id = fetched.pop(0)
        model.hash = fetched.pop(0)
        model.path = fetched.pop(0)
        model.training_set = fetched.pop(0)
        model.test_size_folds = fetched.pop(0)
        model.test_size_epochs = fetched.pop(0)
        model.datetime = fetched.pop(0)
        model.classes = fetched.pop(0)
        model.epochs = fetched.pop(0)
        model.folds = fetched.pop(0)
        model.epoch = fetched.pop(0)
        model.fold = fetched.pop(0)
        model.dataset_train = fetched.pop(0)
        model.dataset_test = fetched.pop(0)
        model.average = fetched.pop(0)

        if model.dataset_train is not None:
            model.dataset_train = Dataset.fetch(connection, model.dataset_train)
        if model.dataset_test is not None:
            model.dataset_test = Dataset.fetch(connection, model.dataset_test)

        return model

    def save(self, connection):
        cursor = connection.cursor()
        cursor.execute("""INSERT INTO public.models
	                        (hash, path, training_set, test_size_folds, test_size_epochs, datetime, classes, epochs, folds, epoch, fold, dataset_train, dataset_test)
	                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) RETURNING id;""",
                        (self.hash, self.path, self.training_set, self.test_size_folds, self.test_size_epochs, 
                        self.datetime, self.classes, self.epochs, self.folds, self.epoch, self.fold, self.dataset_train.id, self.dataset_test.id))
        self.id = cursor.fetchone()[0]
        connection.commit()

    def save_average(self, connection):
        cursor = connection.cursor()
        cursor.execute("""UPDATE public.models SET average=%s WHERE id=%s;""",
                        (self.average, self.id))
        connection.commit()

    def load_model(self):
        if self.nn is not None: return
        with  open("%s.json" % self.path, 'r') as json_file:
            loaded_model_json = json_file.read()
        self.nn = model_from_json(loaded_model_json)
        self.nn.load_weights("%s.h5" % self.path)

    def test(self, dataset):
        self.load_model()
        indata = dataset.data()
        binary_labels = [x[0] for x in indata]
        X = [x[2] for x in indata]


        maxlen = self.nn.get_layer(index=0).input_shape[1]

        X_test = [[ALPHABET[y] for y in x] for x in X]
        X_test = sequence.pad_sequences(X_test, maxlen=maxlen, truncating='post')
        y_test = np.array([0 if x == 'legit' else 1 for x in binary_labels])
        

        time_elapsed = time.time()
        y_pred_float = self.nn.predict(X_test)
        time_elapsed = time.time() - time_elapsed

        y_pred = [0 if (x <= 0.5) else 1 for x in y_pred_float]

        y_test = np.array(y_test).ravel()

        confusion_matrix_ = confusion_matrix(y_test, y_pred)

        rr = [ '%s, %f, %s\n' % (indata[idx][3], y_pred_float[idx], indata[idx][0]) for idx, v in enumerate(indata)]

        with open(f'output/bibo_{self.name()}_{dataset.name}.csv', 'w') as fp:
            fp.writelines(rr)

        return confusion_matrix_, time_elapsed

    def predict_pcap(self, pcap: Pcap, format, csv_path=''):
        self.load_model()
        indata = pcap.data

        maxlen = self.nn.get_layer(index=0).input_shape[1]

        domains = [format(x[3]).replace('.','').lower() for x in indata]

        X = [[ALPHABET[y] for y in domain] for domain in domains]
        X = sequence.pad_sequences(X, maxlen=maxlen, truncating='post')

        time_elapsed = time.time()
        Y = self.nn.predict(X)
        time_elapsed = time.time() - time_elapsed

        rr = [ '%s,%s,%f\n' % (indata[idx][3], domains[idx], Y[idx]) for idx, v in enumerate(indata)]
        with open(csv_path, 'w') as fp:
            fp.writelines(rr)

        return Y, time_elapsed
 
    def predict(self, indata, csv_path, format):
        self.load_model()

        maxlen = self.nn.get_layer(index=0).input_shape[1]

        domains = [format(x).replace('.','').lower() for x in indata]

        X = [[ALPHABET[y] for y in domain] for domain in domains]
        X = sequence.pad_sequences(X, maxlen=maxlen, truncating='post')

        time_elapsed = time.time()
        Y = self.nn.predict(X)
        time_elapsed = time.time() - time_elapsed

        rr = [ '%s,%s,%f\n' % (indata[idx], domains[idx], Y[idx]) for idx, v in enumerate(indata)]
        with open(csv_path, 'w') as fp:
            fp.writelines(rr)
        return Y, rr, time_elapsed
 
    def name(self):
        return "%d_%d" % (self.folds, self.epoch)

    def __str__(self):
        return self.path.split('/')[-1]
