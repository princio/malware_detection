import numpy as np
from collections import OrderedDict, Counter as collection_counter
from keras.preprocessing import sequence
import time
from keras.models import model_from_json, Sequential
from sklearn.metrics import classification_report, confusion_matrix
from json import load as json_load
import csv
import math

with open("models/alphabet.json", "r") as json_file:
    ALPHABET = json_load(json_file)
ALPHABET_REV = {ALPHABET[l]: l for l in ALPHABET}

def domain2input(x):
    x = x.replace('www.','').lower().split('.')
    return x[0] + x[-1]

def input2domain(x):
    return ''.join([ALPHABET_REV[n] for n in x if n != 0])

class Model:

    SELECT = """SELECT id, hash, path, training_set, test_size_folds, test_size_epochs, datetime,
                classes, epochs, folds, epoch, fold, dataset_train, dataset_test, average
                FROM public.models """

    def __init__(self):
        self.id = None
        self.hash = None
        self.path = None
        self.training_set = None
        self.test_size_folds = 0.05
        self.test_size_epochs = 0.05
        self.training_dataset = "setAtrain_h_t_domins"
        self.datetime = None
        self.classes = []
        self.epochs = None
        self.folds = None
        self.epoch = None
        self.fold = None
        self.average = []

        self.nn: Sequential = None
        self.maxlen = None

    @staticmethod
    def fetch(connection, id):
        cursor = connection.cursor()
        cursor.execute("""SELECT id, hash, path, training_set, test_size_folds, test_size_epochs, datetime, classes, epochs, folds, epoch, fold, dataset_train, dataset_test, average
                            FROM public.models WHERE id = %s;""", (id, ))
                            
        return Model.fill(connection, cursor.fetchone())

    @staticmethod
    def fill(connection, fetched):
        fetched = list(fetched)

        model = Model()
        model.id = fetched.pop(0)
        model.hash = fetched.pop(0)
        model.path = fetched.pop(0)
        model.training_set = fetched.pop(0)
        model.test_size_folds = fetched.pop(0)
        model.test_size_epochs = fetched.pop(0)
        model.datetime = fetched.pop(0)
        model.classes = fetched.pop(0)
        model.epochs = fetched.pop(0)
        model.folds = fetched.pop(0)
        model.epoch = fetched.pop(0)
        model.fold = fetched.pop(0)
        model.average = fetched.pop(0)

        return model

    def save(self, connection):
        cursor = connection.cursor()
        cursor.execute("""INSERT INTO public.models
	                        (hash, path, training_set, test_size_folds, test_size_epochs, datetime, classes, epochs, folds, epoch, fold)
	                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) RETURNING id;""",
                        (self.hash, self.path, self.training_set, self.test_size_folds, self.test_size_epochs, 
                        self.datetime, self.classes, self.epochs, self.folds, self.epoch, self.fold))
        self.id = cursor.fetchone()[0]
        connection.commit()

    def save_average(self, connection):
        cursor = connection.cursor()
        cursor.execute("""UPDATE public.models SET average=%s WHERE id=%s;""",
                        (self.average, self.id))
        connection.commit()

    def load_model(self):
        if self.nn is not None: return
        with  open("%s.json" % self.path, 'r') as json_file:
            loaded_model_json = json_file.read()
        self.nn = model_from_json(loaded_model_json)
        self.nn.load_weights("%s.h5" % self.path)
        self.maxlen = self.nn.get_layer(index=0).input_shape[1]

    def predict_csv(self, csv_in_path, column, csv_out_path):
        with open(csv_in_path, "r") as f:
            reader = csv.reader(f)
            data = [row for row in reader]

        return self.predict(data, column, csv_out_path)

    def predict(self, data, column, csv_out_path):
        self.load_model()

        batch_size = 100*1000
        ranges = [len(data)]
        if len(data) > batch_size:
            splices = math.floor(len(data)/(batch_size))
            last_splice = len(data) - splices*batch_size
            ranges = [batch_size] * splices + [last_splice]

        X_not_padded = [[ALPHABET[l] for l in domain2input(row[column])] for row in data]
        X = sequence.pad_sequences(X_not_padded, maxlen=self.maxlen, truncating='post')
        begin = 0
        Y = []
        for incr in ranges:
            print(begin, incr)
            time_elapsed = time.time()
            Y.append(self.nn.predict(X[begin:begin+incr]))
            time_elapsed = time.time() - time_elapsed
            begin += incr

        Y = np.concatenate(Y)

        rr = [ '%s,%s,%.15f\n' % (data[idx][column], input2domain(X[idx]), Y[idx]) for idx, v in enumerate(data)]
        with open(csv_out_path, 'w') as fp:
            fp.writelines(rr)

        return Y, rr, time_elapsed

    def name(self):
        return "%d_%d" % (self.folds, self.epoch)

    def __str__(self):
        return self.path.split('/')[-1]
