import numpy as np
from collections import OrderedDict, Counter as collection_counter
from keras.preprocessing import sequence
import time
from keras.models import model_from_json, Sequential
from sklearn.metrics import classification_report, confusion_matrix
from json import load as json_load
import csv
import math
from DomainLevel import DomainLevel
import tldextract

valid_chars = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alphabet = {letter: idx+1 for idx, letter in enumerate(valid_chars)}

def domain2input(x, domain_level: DomainLevel):
    extracted = tldextract.extract(x.lower())
    if domain_level == DomainLevel.TOP:
        return extracted.domain.replace('.', '') + extracted.suffix.replace('.', '')
    if domain_level == DomainLevel.SIDE:
        return extracted.subdomain.replace('.', '') + extracted.suffix.replace('.', '')
    raise f'Domain level {domain_level} not defined'

def input2domain(x):
    return ''.join([valid_chars[n-1] for n in x if n != 0])

class Model:

    def __init__(self, path):
        self.path = path
        self.nn: Sequential = None
        self.maxlen = None

    def load_model(self):
        if self.nn is not None: return
        with  open("%s.json" % self.path, 'r') as json_file:
            loaded_model_json = json_file.read()
        self.nn = model_from_json(loaded_model_json)
        self.nn.load_weights("%s.h5" % self.path)
        self.maxlen = self.nn.get_layer(index=0).input_shape[1]

    def predict_csv(self, csv_in_path, csv_out_path, column, domain_level):
        with open(csv_in_path, "r") as f:
            reader = csv.reader(f)
            data = [row[column] for row in reader]

        return self.predict(data, csv_out_path, domain_level)

    def predict(self, data, csv_out_path, domain_level):
        self.load_model()

        batch_size = 100*1000
        ranges = [len(data)]
        if len(data) > batch_size:
            splices = math.floor(len(data)/(batch_size))
            last_splice = len(data) - splices*batch_size
            ranges = [batch_size] * splices + [last_splice]

        X_not_padded = [[alphabet[l] for l in domain2input(row, domain_level)] for row in data]
        X = sequence.pad_sequences(X_not_padded, maxlen=self.maxlen, truncating='post')
        begin = 0
        Y = []
        for incr in ranges:
            print(begin, incr)
            time_elapsed = time.time()
            Y.append(self.nn.predict(X[begin:begin + incr]))
            time_elapsed = time.time() - time_elapsed
            begin += incr

        Y = np.concatenate(Y)

        rr = [ '%s,%s,%.15f\n' % (data[idx], input2domain(X[idx]), Y[idx]) for idx, v in enumerate(data)]
        with open(csv_out_path, 'w') as fp:
            fp.writelines(rr)

        return Y, rr, time_elapsed


    def __str__(self):
        return self.path.split('/')[-1]
