from datetime import datetime
import csv
import hashlib
import re
import psycopg2
import os, copy

from Dataset import Dataset
from Repository import DatasetRepository

connection = psycopg2.connect(user = "postgres",
                                  password = "porcodio",
                                  host = "127.0.0.1",
                                  port = "5432",
                                  database = "malware")

cursor = connection.cursor()


def file_hash(path):
    sha256_hash = hashlib.sha256()
    with open(path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def save():
    for type_ in ['malware', 'benign']:
        type_files = os.listdir(f"datasets/{type_}_h_t")
        for dataset_filename in type_files:
            hash_ = file_hash(f"datasets/{type_}_h_t/{dataset_filename}")
            dataset = DatasetRepository.fetch_by_hash(connection, hash_)

            if dataset is None:
                with open(f"datasets/{type_}_h_t/{dataset_filename}", "r") as fp:
                    reader = csv.reader(fp)
                    row_counter = 0
                    label_number = { 'legit': 0 }

                m = re.search(r'(\d+)_(\d{4}-\d{2}-\d{2})_([\w\-]+)\.([\w\-]+).csv__h_t.csv', dataset)
                if m is None:
                    print(f'Strange dir: {dataset}')
                else:
                    dataset__ = Dataset()
                    dataset__.hash = hash_
                    dataset__.name = dataset
                    dataset__.type = type_
                    dataset__.date = datetime.strptime(m.group(2), "%Y-%m-%d").date()
                    dataset__.inputs_number = row_counter

                    legit_number = label_number.pop('legit')
                    dataset__.supports = [ 'legit' ] + list(label_number.keys())
                    dataset__.labels = [ legit_number ] + list(label_number.values())

                    try:
                        dataset__.save(connection)
                    except psycopg2.errors.UniqueViolation:
                        print('Dataset %s already inserted.' % dataset)
                        connection.rollback()

def handle_dataset(file_path):
    hash_ = file_hash(file_path)
    dataset = DatasetRepository.fetch_by_hash(connection, hash_)
    with open(file_path, "r") as fp:
        reader = csv.reader(fp)
        row_counter = 0
        label_number = { 'legit': 0, 'dga': 0 }
        dga = { }
        for row in reader:
            row_counter = row_counter + 1
            label_number[row[0]] += 1
            if row[0] != 'legit':
                dga_name = 'unknown' if row[1] == ' ' else row[1]
                if dga_name not in dga:
                    dga[dga_name] = 0
                dga[dga_name] += 1
    if dataset is None:
        dataset = Dataset()
        dataset.labels = list(label_number.keys())
        dataset.supports = list(label_number.values())
        dataset.date = datetime.now()
        dataset.dga = dga
        dataset.hash = hash_
        dataset.name = file_path.split('/')[-1]
        dataset.inputs_number = dataset.supports[0] + dataset.supports[1]
        dataset.type = 'benign' if dataset.supports[0] > dataset.supports[1] else 'malware'
        dataset.save(connection)
    else:
        dataset.labels = list(label_number.keys())
        dataset.supports = list(label_number.values())
        dataset.dga = dga
        dataset.update(connection)

def update_labels():
    for type_ in ['malware', 'benign']:
        type_files = os.listdir(f"datasets/{type_}_h_t")
        for dataset_filename in type_files:
            handle_dataset(f"datasets/{type_}_h_t/{dataset_filename}")
    
    handle_dataset(f"datasets/setAtrain_h_t_domins.csv")


def update_labels_legit_dga():
    for type_ in ['malware', 'benign']:
        type_files = os.listdir(f"datasets/{type_}_h_t")
        for dataset_filename in type_files:
            hash_ = file_hash(f"datasets/{type_}_h_t/{dataset_filename}")
            dataset = DatasetRepository.fetch_by_hash(connection, hash_)

            with open(f"datasets/{type_}_h_t/{dataset_filename}", "r") as fp:
                reader = csv.reader(fp)
                label_number = { 'legit': 0, 'dga': 0 }
                for row in reader:
                    label_number[row[0]] += 1
            dataset.labels = list(label_number.keys())
            dataset.supports = list(label_number.values())

            try:
                dataset.update(connection)
            except psycopg2.errors.UniqueViolation:
                print('Dataset %s already inserted.' % dataset)
                connection.rollback()

if __name__ == "__main__":
    update_labels()
    connection.close()
