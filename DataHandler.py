import csv, os, numpy as np
from enum import Enum
from Model import Model
from math import floor
from DomainLevel import DomainLevel
import re
import pandas


valid_chars = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alphabet = {letter: idx+1 for idx, letter in enumerate(valid_chars)}
alphabet_rev = {idx+1: letter  for idx, letter in enumerate(valid_chars)}

def letter2number(value):
    return [alphabet[l] for l in value]

def number2letter(value):
    return ''.join([alphabet_rev[n] for n in value])

class Capture():
    """
    A class that identify predict-input dataset, not suited for training.
    """
    NUM = 0
    TIME = 1
    DOMAIN = 2

    def __init__(self, domains, name = 'generic', dir_path = '/tmp/'):
        self.domains = domains
        self.name = name
        self.dir_path = dir_path
        self.grouped = None

    def group(self):
        self.grouped = pandas.DataFrame(self.domains).groupby([0])
        pass
        
    @staticmethod
    def from_path(path):
        """
        Load a csv input having the format NUM,TIME,DOMAIN
        from the disk
        """
        dir_path = path[path.rindex('/') + 1:]
        name = path[: path.rindex('/') + 1]
        with open(path, "r") as f:
            reader = csv.reader(f)
            domains = np.asarray([row[Capture.DOMAIN] for row in reader])

        return Capture(domains, name, dir_path)
    

class DataOut():
    """
    A class that identify predicted-output of dataset having the form:
    DOMAIN,INPUT,PREDICTION
    It can load the data from the disk or save it.
    It fills important fields like the model, the domain levels used, the capture.
    It is useful because every output depends on these fields:
        model, domain-levels, capture.
    """
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2

    def __init__(self, model, dl, capture):
        self.model = model
        self.dl = dl
        self.capture = capture
        self.id = "%s__%s__%s" % (model.name, dl.name, capture.name)
        self.predictions = []
    
    def table(self):
        return [[domain, letter2number(self.dl.translate(domain)), self.predictions[idx][0]] for idx, domain in enumerate(self.capture.domains)]

    def save(self):
        with open(self.path(), "w") as f:
            csv_data = [ '%s,%s,%.15f\n' % (row[0], row[1], row[2]) for row in enumerate(self.table())]
            f.writelines(csv_data)
        pass

    def path(self):
        return "%s%s__%s.%s.out.csv" % (self.capture.dir_path, self.capture.name, self.model.name, self.dl.name)

    def load(self):
        if os.path.exists(self.path()):
            with open(self.path(), "r") as f:
                reader = csv.reader(f)
                self.predictions = [row[2] for row in reader]
        return False

    @staticmethod
    def from_path(path):
        dir_path = path[path.rindex('/') + 1:]
        csv_filename = path[: path.rindex('/') + 1]
        matches = re.search('(.*?)__(.*?)__(.*?).out.csv', csv_filename)
        if len(matches) != 4:
            print(f'DataOut path {csv_filename} not match')
            return False
        capture = Capture.from_path(dir_path + matches[0] + '.csv')
        model = Model.from_name(matches[1])
        dl = DomainLevel.parse(matches[2])

        return DataOut(model, dl, capture)


class DataOutGrouped():
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2
    COUNT = 3

    def __init__(self, dataout: DataOut):
        self.data = []
        self.counts = []
        
        self.dataout = dataout
        self.id = "%s__grouped" % (dataout.id)

    def group(self):
        self.data = {}
        for idx, domain in enumerate(self.dataout.capture.domains):
            if domain not in self.data:
                self.data[domain] = [self.dataout.dl.translate(domain), 0, 0]
            self.data[domain][DataOutGrouped.PREDICTION] += self.dataout.predictions[idx]
            self.data[domain][DataOutGrouped.COUNT] += 1
    
    def table(self):
        return [ [ row[DataOutGrouped.DOMAIN], row[DataOutGrouped.INPUT], row[DataOutGrouped.PREDICTION] / row[DataOutGrouped.COUNT], row[DataOutGrouped.COUNT] ] for row in self.data.values() ]


class Merger():
    def __init__(self, capture):
        self.capture = capture
        self.dataouts = []

    def add_dataout(self, dataout):
        if dataout.capture.name == self.capture.name:
            self.dataouts.append(dataout)
        else:
            raise 'Different capture for merging: %s instead of %s' % (dataout.capture.name, self.capture.name)
    
    def merge(self):
        rows = [[ 'domain', 'input' ] + [ dataout.id for dataout in self.dataouts ] + [ dataout.id for dataout in self.dataouts ]]
        rows += [
                [row[DataOut.DOMAIN]] +
                [dataout.data[idx][dataout.INPUT] for dataout in self.dataouts] +       #input
                [dataout.data[idx][dataout.PREDICTION] for dataout in self.dataouts]    #prediction
                for idx, row in enumerate(self.dataouts[0].data)
            ]
        self.data = rows

            
    def merge(self):
        rows = [[ 'domain', 'input' ] + [ dataout.id for dataout in self.dataouts ] + [ dataout.id for dataout in self.dataouts ]]
        rows += [
                [row[DataOut.DOMAIN]] +
                [dataout.data[idx][dataout.INPUT] for dataout in self.dataouts] +       #input
                [dataout.data[idx][dataout.PREDICTION] for dataout in self.dataouts]    #prediction
                for idx, row in enumerate(self.dataouts[0].data)
            ]
        self.data = rows


    def write(self):
        with open("%s%s.merged.%d.csv" % (self.capture.dir_path, self.capture.name, len(self.dataouts)), 'w') as f:
            writer = csv.writer(f)
            writer.writerows(self.data)
        pass

class Predictor:
    def __init__(self, capture: Capture):
        self.capture = capture
        self.time_elapsed = None
        self.data_out = None


    def predict(self, model: Model, dl: DomainLevel, batch_size = 100*1000, redo = False):
        data_out = False if redo else DataOut.load(model, dl, self.capture)
        if data_out is False:
            domains_translated = [letter2number(dl.translate(domain)) for domain in self.capture.domains]
            predictions, self.time_elapsed = model.predict(domains_translated, batch_size)
            data_out = DataOut(domains_translated, predictions, model, dl, self.capture)
        return data_out
    

    def predict_multi(self, models: Model, dls, batch_size = 100*1000, redo = False):
        dls = DomainLevel.all()

        merger = Merger(self.capture)
        merger_grp = Merger(self.capture)
        for model in models:
            for dl in dls:
                dataout = self.predict(model, dl, batch_size=batch_size, redo=redo)
                merger.add_dataout(dataout)
                merger_grp.add_dataout(dataout)
        merger.merge()
        merger_grp.merge()
        merger.write()
        merger_grp.write()
        pass


            