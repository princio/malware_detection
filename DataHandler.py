import csv, os, numpy as np
from enum import Enum
from Model import Model
from math import floor
from DomainLevel import DomainLevel
import re


valid_chars = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alphabet = {letter: idx+1 for idx, letter in enumerate(valid_chars)}
alphabet_rev = {idx+1: letter  for idx, letter in enumerate(valid_chars)}

def letter2number(value):
    return [alphabet[l] for l in value]

def number2letter(value):
    return ''.join([alphabet_rev[n] for n in value])

class Capture():
    """
    A class that identify predict-input dataset, not suited for training.
    """
    NUM = 0
    TIME = 1
    DOMAIN = 2

    def __init__(self, domains, name = 'generic', dir_path = '/tmp/'):
        self.domains = domains
        self.name = name
        self.dir_path = dir_path
        
    @staticmethod
    def from_csv(csv_path):
        """
        Load a csv input having the format NUM,TIME,DOMAIN
        from the disk
        """
        dir_path = csv_path[csv_path.rindex('/') + 1:]
        name = csv_path[: csv_path.rindex('/') + 1]
        with open(csv_path, "r") as f:
            reader = csv.reader(f)
            domains = [row[Capture.DOMAIN] for row in reader]
        return Capture(domains, name, dir_path)
    

class DataOut():
    """
    A class that identify predicted-output of dataset having the form:
    DOMAIN,INPUT,PREDICTION
    It can load the data from the disk or save it.
    It fills important fields like the model, the domain levels used, the capture.
    It is useful because every output depends on these fields:
        model, domain-levels, capture.
    """
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2

    def __init__(self, data, model, dl, capture, out_type = 'normal'):
        self.data = data
        self.model = model
        self.id = "%s__%s__%s" % (model.name, dl.name, capture.name)
        self.dl = dl
        self.capture = capture
        self.out_type = out_type
    
    def predictions(self):
        return [row[DataOut.PREDICTION] for row in self.data]

    def path(self):
        return "%s%s__%s.%s.%s.out.csv" % (self.capture.dir_path, self.capture.name, self.model.name, self.dl.name, self.out_type)

    @staticmethod
    def from_data(inputs, predictions, model, dl, capture: Capture, out_type='normal'):
        data = [[domain, number2letter(inputs[idx]), predictions[idx][0]] for idx, domain in enumerate(capture.domains)]
        data_out = DataOut(data, model, dl, capture, out_type)
        with open(data_out.path(), "w") as f:
            csv_data = [ '%s,%s,%.15f\n' % (domain, dl.translate(domain), predictions[idx]) for idx, domain in enumerate(capture.domains)]
            f.writelines(csv_data)
        return data_out

    @staticmethod
    def get_path(model, dl, capture, out_type):
        return "%s%s__%s__%s.%s.out.csv" % (capture.dir_path, capture.name, model.name, dl.name, out_type)

    @staticmethod
    def load(model, dl, capture: Capture, out_type='normal'):
        path = DataOut.get_path(model, dl, capture, out_type)
        if not os.path.exists(path):
            return False
        with open(path, "r") as f:
            reader = csv.reader(f)
            data_out = [row for row in reader]
        return DataOut(data_out, model.name, dl, capture, 'normal')

    @staticmethod
    def parse_path(path):
        dir_path = path[path.rindex('/') + 1:]
        csv_filename = path[: path.rindex('/') + 1]
        matches = re.search('(.*?)__(.*?)__(.*?).(.*?).out.csv', csv_filename)
        if len(matches) != 4:
            print(f'DataOut path {csv_filename} not match')
            return False
        capture = Capture.from_csv(dir_path + matches[0] + '.csv')
        model = Model.from_name(matches[1])
        dl = DomainLevel.parse(matches[2])
        out_type = matches[3]
        return capture, model, dl, out_type


class DataOutGrouped():
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2
    COUNT = 3

    def __init__(self, dataout: DataOut):
        self.dataout = dataout
        self.id = "%s__grouped" % (dataout.id)

        self.data = {}
        for row in self.data:
            domain = row[DataOut.DOMAIN]
            if domain not in dataout.data:
                self.data[domain] = [domain, row[DataOut.INPUT], 0, 0]
            self.data[domain][DataOutGrouped.PREDICTION] += row[DataOutGrouped.PREDICTION]
            self.data[domain][DataOutGrouped.COUNT] += 1
        self.data = [ [ row[DataOutGrouped.DOMAIN], row[DataOutGrouped.INPUT], row[DataOutGrouped.PREDICTION] / row[DataOutGrouped.COUNT], row[DataOutGrouped.COUNT] ] for row in self.data.values() ]


class Merger():
    def __init__(self, capture):
        self.capture = capture
        self.dataouts = []

    def add_dataout(self, dataout):
        if dataout.capture.name == self.capture.name:
            self.dataouts.append(dataout)
        else:
            raise 'Different capture for merging: %s instead of %s' % (dataout.capture.name, self.capture.name)
    
    def merge(self):
        rows = [[ 'domain', 'input' ] + [ dataout.id for dataout in self.dataouts ] + [ dataout.id for dataout in self.dataouts ]]
        rows += [
                [row[DataOut.DOMAIN]] +
                [dataout.data[idx][dataout.INPUT] for dataout in self.dataouts] +       #input
                [dataout.data[idx][dataout.PREDICTION] for dataout in self.dataouts]    #prediction
                for idx, row in enumerate(self.dataouts[0].data)
            ]
        self.data = rows

            
    def merge(self):
        rows = [[ 'domain', 'input' ] + [ dataout.id for dataout in self.dataouts ] + [ dataout.id for dataout in self.dataouts ]]
        rows += [
                [row[DataOut.DOMAIN]] +
                [dataout.data[idx][dataout.INPUT] for dataout in self.dataouts] +       #input
                [dataout.data[idx][dataout.PREDICTION] for dataout in self.dataouts]    #prediction
                for idx, row in enumerate(self.dataouts[0].data)
            ]
        self.data = rows


    def write(self):
        with open("%s%s.merged.%d.csv" % (self.capture.dir_path, self.capture.name, len(self.dataouts)), 'w') as f:
            writer = csv.writer(f)
            writer.writerows(self.data)
        pass

class Predictor:
    def __init__(self, capture: Capture):
        self.capture = capture
        self.time_elapsed = None
        self.data_out = None


    def predict(self, model: Model, dl: DomainLevel, batch_size = 100*1000, redo = False):
        data_out = False if redo else DataOut.load(model, dl, self.capture)
        if data_out is False:
            domains_translated = [letter2number(dl.translate(domain)) for domain in self.capture.domains]
            predictions, self.time_elapsed = model.predict(domains_translated, batch_size)
            data_out = DataOut.from_data(domains_translated, predictions, model, dl, self.capture)
        return data_out
    

    def predict_multi(self, models: Model, dls, batch_size = 100*1000, redo = False):
        dls = DomainLevel.all()

        merger = Merger(self.capture)
        merger_grp = Merger(self.capture)
        for model in models:
            for dl in dls:
                dataout = self.predict(model, dl, batch_size=batch_size, redo=redo)
                merger.add_dataout(dataout)
                merger_grp.add_dataout(dataout)
        merger.merge()
        merger_grp.merge()
        merger.write()
        merger_grp.write()
        pass


            