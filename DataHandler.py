import csv, os, numpy as np
from enum import Enum
from Model import Model
from math import floor
from DomainLevel import DomainLevel
import re


valid_chars = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alphabet = {letter: idx+1 for idx, letter in enumerate(valid_chars)}


class Capture():
    """
    A class that identify predict-input dataset, not suited for training.
    """
    NUM = 0
    TIME = 1
    DOMAIN = 2

    def __init__(self, domains, name = 'generic', dir_path = '/tmp/'):
        self.domains = domains
        self.name = name
        self.dir_path = dir_path
        
    @staticmethod
    def from_csv(csv_path):
        """
        Load a csv input having the format NUM,TIME,DOMAIN
        from the disk
        """
        dir_path = csv_path[csv_path.rindex('/') + 1:]
        name = csv_path[: csv_path.rindex('/') + 1]
        with open(csv_path, "r") as f:
            reader = csv.reader(f)
            domains = [row[Capture.DOMAIN] for row in reader]
        return Capture(domains, name, dir_path)

class DataOut():
    """
    A class that identify predicted-output of dataset having the form:
    DOMAIN,INPUT,PREDICTION
    It can load the data from the disk or save it.
    It fills important fields like the model, the domain levels used, the capture.
    It is useful because every output depends on these fields:
        model, domain-levels, capture.
    """
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2

    def __init__(self, data, model, dl, capture, out_type = 'normal'):
        self.data = data
        self.model = model
        self.dl = dl
        self.capture = capture
        self.out_type = out_type

    def group(self):
        data_grouped = {}
        for row in self.data:
            input_ = row[DataOut.INPUT]
            if row[DataOut.INPUT] not in data_grouped:
                data_grouped[input_] = [input_, 0, 1]
            else:
                data_grouped[input_][1] += float(row[DataOut.PREDICTION])
                data_grouped[input_][2] += 1
        data_grouped = [ [ row[0], row[1] / row[2], row[2] ] for row in data_grouped ]
        return data_grouped

    def predictions(self):
        return [row[DataOut.PREDICTION] for row in self.data]

    def path(self):
        return "%s%s__%s.%s.%s.out.csv" % (self.capture.dir_path, self.capture.name, self.model.name, self.dl.name, self.out_type)

    @staticmethod
    def from_data(inputs, predictions, model, dl, capture: Capture, out_type='normal'):
        data = [[domain, inputs[idx], predictions[idx]] for idx, domain in enumerate(capture.domains)]
        data_out = DataOut(data, model, dl, capture, out_type)
        with open(data_out.path(), "w") as f:
            csv_data = [ '%s,%s,%.15f\n' % (domain, dl.translate(domain), predictions[idx]) for idx, domain in enumerate(capture.domains)]
            f.writelines(csv_data)
        return data_out

    @staticmethod
    def get_path(model, dl, capture, out_type):
        return "%s%s__%s__%s.%s.out.csv" % (capture.dir_path, capture.name, model.name, dl.name, out_type)

    @staticmethod
    def load(model, dl, capture: Capture, out_type='normal'):
        path = DataOut.get_path(model, dl, capture, out_type)
        if not os.path.exists(path):
            return False
        with open(path, "r") as f:
            reader = csv.reader(f)
            data_out = [row for row in reader]
        return DataOut(data_out, model.name, dl, capture, 'normal')

    @staticmethod
    def parse_path(path):
        dir_path = path[path.rindex('/') + 1:]
        csv_filename = path[: path.rindex('/') + 1]
        matches = re.search('(.*?)__(.*?)__(.*?).(.*?).out.csv', csv_filename)
        if len(matches) != 4:
            print(f'DataOut path {csv_filename} not match')
            return False
        capture = Capture.from_csv(dir_path + matches[0] + '.csv')
        model = Model.from_name(matches[1])
        dl = DomainLevel.parse(matches[2])
        out_type = matches[3]
        return capture, model, dl, out_type



class Predictor:
    def __init__(self, capture):
        self.capture = capture
        self.time_elapsed = None
        self.data_out = None


    def predict(self, model: Model, dl: DomainLevel, batch_size = 100*1000, redo = False):
        data_out = False if redo else DataOut.load(model, dl, self.capture)
        if data_out is False:
            domains_translated = [[alphabet[l] for l in dl.translate(domain)] for domain in self.capture.domains]
            predictions, self.time_elapsed = model.predict(domains_translated, batch_size)
            data_out = DataOut.from_data(domains_translated, predictions, model, dl, self.capture)
        return data_out
    

    def predict_multi(self, models: Model, dls, batch_size = 100*1000, redo = False):
        dls = DomainLevel.all()
        data_outs = {}
        data_outs_grouped = {}
        ids = []
        for model in models:
            for dl in dls:
                id = "%s__%s" % (model.name, dl.name)
                ids.append(id)
                data_outs[id] = self.predict(model, dl, batch_size=batch_size, redo=redo)
                data_outs_grouped[id] = data_outs[id].group()
        
        merged1 = merge_outs(data_outs, dls)
        merged2 = merge_outs(data_outs_grouped, dls)
        pass

def merge_outs(data_outs, ids):
    rows = [[ 'domain', 'input' ] + [ dl.name for dl in dls ]]
    rows += [[row[DataOut.DOMAIN], row[DataOut.INPUT]] + [[d for d in data_outs[dl].data[idx][DataOut.PREDICTION]] for dl in dls] for idx, row in enumerate(data_outs[DomainLevel.NORMAL].data)]
    return rows
