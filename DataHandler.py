import csv, os, numpy as np
from enum import Enum
from Model import Model
from math import floor
from DomainLevel import DomainLevel
import re
import pandas as pd


valid_chars = ['_', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alphabet = {letter: idx+1 for idx, letter in enumerate(valid_chars)}
alphabet_rev = {idx+1: letter  for idx, letter in enumerate(valid_chars)}

def domain2input(domain):
    return [alphabet[l] for l in domain.lower().replace('.', '')]

def letter2number(value):
    return [alphabet[l] for l in value]

def number2letter(value):
    return ''.join([alphabet_rev[n] for n in value])

class Capture():
    """
    A class that identify predict-input dataset, not suited for training.
    """
    NUM = 0
    TIME = 1
    DOMAIN = 2

    def __init__(self, domains, name = 'generic', dir_path = '/tmp/'):
        self.domains = domains
        self.name = name
        self.dir_path = dir_path
        self.grouped = None

    @staticmethod
    def from_path(path):
        """
        Load a csv input having the format NUM,TIME,DOMAIN
        from the disk
        """
        dir_path = path[path.rindex('/') + 1:]
        name = path[: path.rindex('/') + 1]
        with open(path, "r") as f:
            reader = csv.reader(f)
            domains = np.asarray([row[Capture.DOMAIN] for row in reader])

        domains = pd.read_csv(path, names=["num", "time", "domain"])

        return Capture(domains, name, dir_path)
    

class Prediction():
    """
    A class that identify predicted-output of dataset having the form:
    DOMAIN,INPUT,PREDICTION
    It can load the data from the disk or save it.
    It fills important fields like the model, the domain levels used, the capture.
    It is useful because every output depends on these fields:
        model, domain-levels, capture.
    """
    DOMAIN = 0
    INPUT = 1
    PREDICTION = 2

    def __init__(self, model, dl, capture):
        self.model = model
        self.dl = dl
        self.capture = capture
        self.id = "%s__%s__%s" % (model.name, dl.name, capture.name)
        self.inputs = pd.DataFrame(columns=['input'])
        self.predictions = pd.DataFrame(columns=['prediction'])
        self.time_elapsed = None

    def predict(self, batch_size = 100*1000, redo = False):
        if self.load() is False:
            self.inputs = self.capture.domains['domain'].apply(self.dl.translate).rename('input')
            self.predictions, self.time_elapsed = self.model.predict(self.inputs.apply(domain2input), batch_size)
            self.predictions = pd.Series(self.predictions[:,0], name='prediction')
        return self.predictions
    
    def table(self):
        return [[domain, letter2number(self.dl.translate(domain)), self.predictions[idx][0]] for idx, domain in enumerate(self.capture.domains)]

    def save(self):
        with open(self.path(), "w") as f:
            csv_data = [ '%s,%s,%.15f\n' % (row[0], row[1], row[2]) for row in enumerate(self.table())]
            f.writelines(csv_data)
        pass

    def path(self):
        return "%s%s__%s.%s.out.csv" % (self.capture.dir_path, self.capture.name, self.model.name, self.dl.name)
    
    def group(self):
        dataout = pd.concat([self.capture.domains['domain'], self.predictions], axis=1, names=['domain', 'prediction']).groupby("domain").agg(['mean', 'count'])
        dataout.insert(loc=0, column='input', value=dataout.index.to_series().apply(self.dl.translate))
        return dataout

    def load(self):
        if os.path.exists(self.path()):
            self.predictions = pd.read_csv(self.path(), names=["domain", "input", "prediction"])
            return True
        return False

    @staticmethod
    def from_path(path):
        dir_path = path[path.rindex('/') + 1:]
        csv_filename = path[: path.rindex('/') + 1]
        matches = re.search('(.*?)__(.*?)__(.*?).out.csv', csv_filename)
        if len(matches) != 4:
            print(f'Prediction path {csv_filename} not match')
            return False
        capture = Capture.from_path(dir_path + matches[0] + '.csv')
        model = Model.from_name(matches[1])
        dl = DomainLevel.parse(matches[2])

        return Prediction(model, dl, capture)

class Predictor:
    def __init__(self, capture: Capture):
        self.capture = capture
        self.time_elapsed = None
        self.data_out = None

    def predict_multi(self, models: Model, dls, batch_size = 100*1000, redo = False):
        dls = DomainLevel.all()
        # columns = list(zip(*[
        #     [t1 for t3 in [[dl.name]*len(models) for dl in dls] for t1 in t3],
        #     [t1 for t1 in len(dls)*[model.name for model in models]]
        # ]))
        mi = pd.MultiIndex.from_product([[m.name for m in models], [dl.name for dl in dls], ['input', 'mean', 'count']], names=['model', 'type', 'value'])

        dataouts = []
        for dl in dls:
            model_dataouts = None
            for model in models:
                dataout = Prediction(model, dl, self.capture)
                dataout.predict()
                if model_dataouts is None:
                    model_dataouts = dataout.group()
                else:
                    model_dataouts.insert(2, model.name, dataout.group()['prediction','mean'])
            model_dataouts.columns = pd.MultiIndex.from_product([[dl.name], ['input'] + [m.name for m in models] + ['count']], names=['dl', 'value'])
            dataouts.append(model_dataouts)
            
        b1 = pd.concat(dataouts, axis=1)
        b1.to_csv('/tmp/big_table.csv')
        pass


            